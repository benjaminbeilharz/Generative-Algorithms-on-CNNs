Generation: 1
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
        AvgPool2d-13           [-1, 64, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]          36,928
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
           Conv2d-32           [-1, 64, 10, 10]         147,520
      BatchNorm2d-33           [-1, 64, 10, 10]             128
             ReLU-34           [-1, 64, 10, 10]               0
      SkipConnect-35           [-1, 64, 10, 10]               0
           Conv2d-36          [-1, 512, 12, 12]         295,424
      BatchNorm2d-37          [-1, 512, 12, 12]           1,024
             ReLU-38          [-1, 512, 12, 12]               0
      SkipConnect-39          [-1, 512, 12, 12]               0
           Conv2d-40          [-1, 256, 14, 14]       1,179,904
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
      SkipConnect-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 16, 16]         590,080
      BatchNorm2d-45          [-1, 256, 16, 16]             512
             ReLU-46          [-1, 256, 16, 16]               0
      SkipConnect-47          [-1, 256, 16, 16]               0
        AvgPool2d-48            [-1, 256, 9, 9]               0
        MaxPool2d-49            [-1, 256, 5, 5]               0
================================================================
Total params: 4,366,560
Trainable params: 4,366,560
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 34.21
Params size (MB): 16.66
Estimated Total Size (MB): 50.88
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 149.0
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 148.07
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5          [-1, 512, 36, 36]          74,240
       BatchNorm2d-6          [-1, 512, 36, 36]           1,024
              ReLU-7          [-1, 512, 36, 36]               0
       SkipConnect-8          [-1, 512, 36, 36]               0
            Conv2d-9          [-1, 128, 38, 38]         589,952
      BatchNorm2d-10          [-1, 128, 38, 38]             256
             ReLU-11          [-1, 128, 38, 38]               0
      SkipConnect-12          [-1, 128, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]          73,792
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 512, 42, 42]         295,424
      BatchNorm2d-18          [-1, 512, 42, 42]           1,024
             ReLU-19          [-1, 512, 42, 42]               0
      SkipConnect-20          [-1, 512, 42, 42]               0
        AvgPool2d-21          [-1, 512, 22, 22]               0
        MaxPool2d-22          [-1, 512, 12, 12]               0
           Conv2d-23          [-1, 256, 14, 14]       1,179,904
      BatchNorm2d-24          [-1, 256, 14, 14]             512
             ReLU-25          [-1, 256, 14, 14]               0
      SkipConnect-26          [-1, 256, 14, 14]               0
           Conv2d-27          [-1, 128, 16, 16]         295,040
      BatchNorm2d-28          [-1, 128, 16, 16]             256
             ReLU-29          [-1, 128, 16, 16]               0
      SkipConnect-30          [-1, 128, 16, 16]               0
           Conv2d-31          [-1, 512, 18, 18]         590,336
      BatchNorm2d-32          [-1, 512, 18, 18]           1,024
             ReLU-33          [-1, 512, 18, 18]               0
      SkipConnect-34          [-1, 512, 18, 18]               0
           Conv2d-35          [-1, 512, 20, 20]       2,359,808
      BatchNorm2d-36          [-1, 512, 20, 20]           1,024
             ReLU-37          [-1, 512, 20, 20]               0
      SkipConnect-38          [-1, 512, 20, 20]               0
           Conv2d-39          [-1, 512, 22, 22]       2,359,808
      BatchNorm2d-40          [-1, 512, 22, 22]           1,024
             ReLU-41          [-1, 512, 22, 22]               0
      SkipConnect-42          [-1, 512, 22, 22]               0
           Conv2d-43          [-1, 128, 24, 24]         589,952
      BatchNorm2d-44          [-1, 128, 24, 24]             256
             ReLU-45          [-1, 128, 24, 24]               0
      SkipConnect-46          [-1, 128, 24, 24]               0
        MaxPool2d-47          [-1, 128, 13, 13]               0
        MaxPool2d-48            [-1, 128, 7, 7]               0
           Conv2d-49             [-1, 64, 9, 9]          73,792
      BatchNorm2d-50             [-1, 64, 9, 9]             128
             ReLU-51             [-1, 64, 9, 9]               0
      SkipConnect-52             [-1, 64, 9, 9]               0
           Conv2d-53          [-1, 256, 11, 11]         147,712
      BatchNorm2d-54          [-1, 256, 11, 11]             512
             ReLU-55          [-1, 256, 11, 11]               0
      SkipConnect-56          [-1, 256, 11, 11]               0
================================================================
Total params: 8,637,408
Trainable params: 8,637,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 84.57
Params size (MB): 32.95
Estimated Total Size (MB): 117.53
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.26
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.71
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 128, 6, 6]         589,952
      BatchNorm2d-33            [-1, 128, 6, 6]             256
             ReLU-34            [-1, 128, 6, 6]               0
      SkipConnect-35            [-1, 128, 6, 6]               0
================================================================
Total params: 4,023,648
Trainable params: 4,023,648
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.93
Params size (MB): 15.35
Estimated Total Size (MB): 21.29
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.53
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.54
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 2,253,408
Trainable params: 2,253,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.85
Params size (MB): 8.60
Estimated Total Size (MB): 17.46
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.48
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.32
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        AvgPool2d-32            [-1, 128, 8, 8]               0
        MaxPool2d-33            [-1, 128, 5, 5]               0
           Conv2d-34            [-1, 512, 7, 7]         590,336
      BatchNorm2d-35            [-1, 512, 7, 7]           1,024
             ReLU-36            [-1, 512, 7, 7]               0
      SkipConnect-37            [-1, 512, 7, 7]               0
           Conv2d-38            [-1, 512, 9, 9]       2,359,808
      BatchNorm2d-39            [-1, 512, 9, 9]           1,024
             ReLU-40            [-1, 512, 9, 9]               0
      SkipConnect-41            [-1, 512, 9, 9]               0
           Conv2d-42          [-1, 128, 11, 11]         589,952
      BatchNorm2d-43          [-1, 128, 11, 11]             256
             ReLU-44          [-1, 128, 11, 11]               0
      SkipConnect-45          [-1, 128, 11, 11]               0
           Conv2d-46           [-1, 64, 13, 13]          73,792
      BatchNorm2d-47           [-1, 64, 13, 13]             128
             ReLU-48           [-1, 64, 13, 13]               0
      SkipConnect-49           [-1, 64, 13, 13]               0
================================================================
Total params: 6,883,872
Trainable params: 6,883,872
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 13.37
Params size (MB): 26.26
Estimated Total Size (MB): 39.64
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 28.125	Loss: 148.11
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.44
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 128, 24, 24]         295,040
      BatchNorm2d-23          [-1, 128, 24, 24]             256
             ReLU-24          [-1, 128, 24, 24]               0
      SkipConnect-25          [-1, 128, 24, 24]               0
           Conv2d-26          [-1, 512, 26, 26]         590,336
      BatchNorm2d-27          [-1, 512, 26, 26]           1,024
             ReLU-28          [-1, 512, 26, 26]               0
      SkipConnect-29          [-1, 512, 26, 26]               0
           Conv2d-30          [-1, 512, 28, 28]       2,359,808
      BatchNorm2d-31          [-1, 512, 28, 28]           1,024
             ReLU-32          [-1, 512, 28, 28]               0
      SkipConnect-33          [-1, 512, 28, 28]               0
           Conv2d-34           [-1, 64, 30, 30]         294,976
      BatchNorm2d-35           [-1, 64, 30, 30]             128
             ReLU-36           [-1, 64, 30, 30]               0
      SkipConnect-37           [-1, 64, 30, 30]               0
        MaxPool2d-38           [-1, 64, 16, 16]               0
           Conv2d-39          [-1, 256, 18, 18]         147,712
      BatchNorm2d-40          [-1, 256, 18, 18]             512
             ReLU-41          [-1, 256, 18, 18]               0
      SkipConnect-42          [-1, 256, 18, 18]               0
           Conv2d-43          [-1, 128, 20, 20]         295,040
      BatchNorm2d-44          [-1, 128, 20, 20]             256
             ReLU-45          [-1, 128, 20, 20]               0
      SkipConnect-46          [-1, 128, 20, 20]               0
           Conv2d-47           [-1, 64, 22, 22]          73,792
      BatchNorm2d-48           [-1, 64, 22, 22]             128
             ReLU-49           [-1, 64, 22, 22]               0
      SkipConnect-50           [-1, 64, 22, 22]               0
           Conv2d-51           [-1, 64, 24, 24]          36,928
      BatchNorm2d-52           [-1, 64, 24, 24]             128
             ReLU-53           [-1, 64, 24, 24]               0
      SkipConnect-54           [-1, 64, 24, 24]               0
           Conv2d-55          [-1, 512, 26, 26]         295,424
      BatchNorm2d-56          [-1, 512, 26, 26]           1,024
             ReLU-57          [-1, 512, 26, 26]               0
      SkipConnect-58          [-1, 512, 26, 26]               0
           Conv2d-59          [-1, 512, 28, 28]       2,359,808
      BatchNorm2d-60          [-1, 512, 28, 28]           1,024
             ReLU-61          [-1, 512, 28, 28]               0
      SkipConnect-62          [-1, 512, 28, 28]               0
           Conv2d-63          [-1, 128, 30, 30]         589,952
      BatchNorm2d-64          [-1, 128, 30, 30]             256
             ReLU-65          [-1, 128, 30, 30]               0
      SkipConnect-66          [-1, 128, 30, 30]               0
           Conv2d-67          [-1, 128, 32, 32]         147,584
      BatchNorm2d-68          [-1, 128, 32, 32]             256
             ReLU-69          [-1, 128, 32, 32]               0
      SkipConnect-70          [-1, 128, 32, 32]               0
================================================================
Total params: 8,242,080
Trainable params: 8,242,080
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 106.95
Params size (MB): 31.44
Estimated Total Size (MB): 138.40
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 28.125	Loss: 148.09
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.62
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
================================================================
Total params: 2,262,048
Trainable params: 2,262,048
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.62
Params size (MB): 8.63
Estimated Total Size (MB): 13.26
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 148.3
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.44
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5          [-1, 256, 36, 36]          37,120
       BatchNorm2d-6          [-1, 256, 36, 36]             512
              ReLU-7          [-1, 256, 36, 36]               0
       SkipConnect-8          [-1, 256, 36, 36]               0
            Conv2d-9          [-1, 128, 38, 38]         295,040
      BatchNorm2d-10          [-1, 128, 38, 38]             256
             ReLU-11          [-1, 128, 38, 38]               0
      SkipConnect-12          [-1, 128, 38, 38]               0
        AvgPool2d-13          [-1, 128, 20, 20]               0
           Conv2d-14          [-1, 256, 22, 22]         295,168
      BatchNorm2d-15          [-1, 256, 22, 22]             512
             ReLU-16          [-1, 256, 22, 22]               0
      SkipConnect-17          [-1, 256, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]       1,180,160
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
        AvgPool2d-22          [-1, 512, 13, 13]               0
        AvgPool2d-23            [-1, 512, 7, 7]               0
           Conv2d-24             [-1, 64, 9, 9]         294,976
      BatchNorm2d-25             [-1, 64, 9, 9]             128
             ReLU-26             [-1, 64, 9, 9]               0
      SkipConnect-27             [-1, 64, 9, 9]               0
           Conv2d-28           [-1, 64, 11, 11]          36,928
      BatchNorm2d-29           [-1, 64, 11, 11]             128
             ReLU-30           [-1, 64, 11, 11]               0
      SkipConnect-31           [-1, 64, 11, 11]               0
           Conv2d-32          [-1, 128, 13, 13]          73,856
      BatchNorm2d-33          [-1, 128, 13, 13]             256
             ReLU-34          [-1, 128, 13, 13]               0
      SkipConnect-35          [-1, 128, 13, 13]               0
           Conv2d-36          [-1, 256, 15, 15]         295,168
      BatchNorm2d-37          [-1, 256, 15, 15]             512
             ReLU-38          [-1, 256, 15, 15]               0
      SkipConnect-39          [-1, 256, 15, 15]               0
           Conv2d-40           [-1, 64, 17, 17]         147,520
      BatchNorm2d-41           [-1, 64, 17, 17]             128
             ReLU-42           [-1, 64, 17, 17]               0
      SkipConnect-43           [-1, 64, 17, 17]               0
           Conv2d-44          [-1, 128, 19, 19]          73,856
      BatchNorm2d-45          [-1, 128, 19, 19]             256
             ReLU-46          [-1, 128, 19, 19]               0
      SkipConnect-47          [-1, 128, 19, 19]               0
        MaxPool2d-48          [-1, 128, 10, 10]               0
           Conv2d-49          [-1, 128, 12, 12]         147,584
      BatchNorm2d-50          [-1, 128, 12, 12]             256
             ReLU-51          [-1, 128, 12, 12]               0
      SkipConnect-52          [-1, 128, 12, 12]               0
           Conv2d-53          [-1, 128, 14, 14]         147,584
      BatchNorm2d-54          [-1, 128, 14, 14]             256
             ReLU-55          [-1, 128, 14, 14]               0
      SkipConnect-56          [-1, 128, 14, 14]               0
================================================================
Total params: 3,029,664
Trainable params: 3,029,664
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 36.57
Params size (MB): 11.56
Estimated Total Size (MB): 48.14
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.17
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.66
Current Fitness:
{'0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.8': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '256-128-0.5-256-512-0.5-0.3-64-64-128-256-64-128-0.6-128-128': 12.5,
 '512-128-64-512-0.5-0.7-256-128-512-512-512-128-0.9-1.0-64-256': 0,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 2
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
           Conv2d-37             [-1, 64, 5, 5]          36,928
      BatchNorm2d-38             [-1, 64, 5, 5]             128
             ReLU-39             [-1, 64, 5, 5]               0
      SkipConnect-40             [-1, 64, 5, 5]               0
           Conv2d-41            [-1, 256, 7, 7]         147,712
      BatchNorm2d-42            [-1, 256, 7, 7]             512
             ReLU-43            [-1, 256, 7, 7]               0
      SkipConnect-44            [-1, 256, 7, 7]               0
================================================================
Total params: 2,447,328
Trainable params: 2,447,328
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.05
Params size (MB): 9.34
Estimated Total Size (MB): 14.40
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 148.51
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.79
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
           Conv2d-24          [-1, 512, 16, 16]       2,359,808
      BatchNorm2d-25          [-1, 512, 16, 16]           1,024
             ReLU-26          [-1, 512, 16, 16]               0
      SkipConnect-27          [-1, 512, 16, 16]               0
           Conv2d-28           [-1, 64, 18, 18]         294,976
      BatchNorm2d-29           [-1, 64, 18, 18]             128
             ReLU-30           [-1, 64, 18, 18]               0
      SkipConnect-31           [-1, 64, 18, 18]               0
        MaxPool2d-32           [-1, 64, 10, 10]               0
           Conv2d-33          [-1, 256, 12, 12]         147,712
      BatchNorm2d-34          [-1, 256, 12, 12]             512
             ReLU-35          [-1, 256, 12, 12]               0
      SkipConnect-36          [-1, 256, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]         295,040
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
           Conv2d-41           [-1, 64, 16, 16]          73,792
      BatchNorm2d-42           [-1, 64, 16, 16]             128
             ReLU-43           [-1, 64, 16, 16]               0
      SkipConnect-44           [-1, 64, 16, 16]               0
           Conv2d-45           [-1, 64, 18, 18]          36,928
      BatchNorm2d-46           [-1, 64, 18, 18]             128
             ReLU-47           [-1, 64, 18, 18]               0
      SkipConnect-48           [-1, 64, 18, 18]               0
           Conv2d-49          [-1, 512, 20, 20]         295,424
      BatchNorm2d-50          [-1, 512, 20, 20]           1,024
             ReLU-51          [-1, 512, 20, 20]               0
      SkipConnect-52          [-1, 512, 20, 20]               0
           Conv2d-53          [-1, 512, 22, 22]       2,359,808
      BatchNorm2d-54          [-1, 512, 22, 22]           1,024
             ReLU-55          [-1, 512, 22, 22]               0
      SkipConnect-56          [-1, 512, 22, 22]               0
           Conv2d-57          [-1, 128, 24, 24]         589,952
      BatchNorm2d-58          [-1, 128, 24, 24]             256
             ReLU-59          [-1, 128, 24, 24]               0
      SkipConnect-60          [-1, 128, 24, 24]               0
           Conv2d-61          [-1, 128, 26, 26]         147,584
      BatchNorm2d-62          [-1, 128, 26, 26]             256
             ReLU-63          [-1, 128, 26, 26]               0
      SkipConnect-64          [-1, 128, 26, 26]               0
================================================================
Total params: 7,678,368
Trainable params: 7,678,368
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 31.54
Params size (MB): 29.29
Estimated Total Size (MB): 60.85
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.34
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.76
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         295,040
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
           Conv2d-23          [-1, 512, 20, 20]         590,336
      BatchNorm2d-24          [-1, 512, 20, 20]           1,024
             ReLU-25          [-1, 512, 20, 20]               0
      SkipConnect-26          [-1, 512, 20, 20]               0
        MaxPool2d-27          [-1, 512, 11, 11]               0
        MaxPool2d-28            [-1, 512, 6, 6]               0
        AvgPool2d-29            [-1, 512, 4, 4]               0
        MaxPool2d-30            [-1, 512, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]       2,359,808
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35            [-1, 128, 7, 7]         589,952
      BatchNorm2d-36            [-1, 128, 7, 7]             256
             ReLU-37            [-1, 128, 7, 7]               0
      SkipConnect-38            [-1, 128, 7, 7]               0
================================================================
Total params: 4,300,512
Trainable params: 4,300,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 12.52
Params size (MB): 16.41
Estimated Total Size (MB): 28.94
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.17
Epoch:  2
Epoch: 2 of 2	Acc: 20.3125	Loss: 147.54
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 256, 24, 24]         590,080
      BatchNorm2d-23          [-1, 256, 24, 24]             512
             ReLU-24          [-1, 256, 24, 24]               0
      SkipConnect-25          [-1, 256, 24, 24]               0
        MaxPool2d-26          [-1, 256, 13, 13]               0
           Conv2d-27          [-1, 512, 15, 15]       1,180,160
      BatchNorm2d-28          [-1, 512, 15, 15]           1,024
             ReLU-29          [-1, 512, 15, 15]               0
      SkipConnect-30          [-1, 512, 15, 15]               0
           Conv2d-31          [-1, 128, 17, 17]         589,952
      BatchNorm2d-32          [-1, 128, 17, 17]             256
             ReLU-33          [-1, 128, 17, 17]               0
      SkipConnect-34          [-1, 128, 17, 17]               0
        AvgPool2d-35            [-1, 128, 9, 9]               0
        MaxPool2d-36            [-1, 128, 5, 5]               0
           Conv2d-37            [-1, 512, 7, 7]         590,336
      BatchNorm2d-38            [-1, 512, 7, 7]           1,024
             ReLU-39            [-1, 512, 7, 7]               0
      SkipConnect-40            [-1, 512, 7, 7]               0
           Conv2d-41            [-1, 512, 9, 9]       2,359,808
      BatchNorm2d-42            [-1, 512, 9, 9]           1,024
             ReLU-43            [-1, 512, 9, 9]               0
      SkipConnect-44            [-1, 512, 9, 9]               0
           Conv2d-45          [-1, 128, 11, 11]         589,952
      BatchNorm2d-46          [-1, 128, 11, 11]             256
             ReLU-47          [-1, 128, 11, 11]               0
      SkipConnect-48          [-1, 128, 11, 11]               0
           Conv2d-49           [-1, 64, 13, 13]          73,792
      BatchNorm2d-50           [-1, 64, 13, 13]             128
             ReLU-51           [-1, 64, 13, 13]               0
      SkipConnect-52           [-1, 64, 13, 13]               0
================================================================
Total params: 6,727,968
Trainable params: 6,727,968
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 55.92
Params size (MB): 25.67
Estimated Total Size (MB): 81.60
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 148.02
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.51
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]         589,952
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 6,607,008
Trainable params: 6,607,008
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.15
Params size (MB): 25.20
Estimated Total Size (MB): 32.36
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 147.93
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.46
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         295,040
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
           Conv2d-23          [-1, 512, 20, 20]         590,336
      BatchNorm2d-24          [-1, 512, 20, 20]           1,024
             ReLU-25          [-1, 512, 20, 20]               0
      SkipConnect-26          [-1, 512, 20, 20]               0
           Conv2d-27          [-1, 512, 22, 22]       2,359,808
      BatchNorm2d-28          [-1, 512, 22, 22]           1,024
             ReLU-29          [-1, 512, 22, 22]               0
      SkipConnect-30          [-1, 512, 22, 22]               0
           Conv2d-31           [-1, 64, 24, 24]         294,976
      BatchNorm2d-32           [-1, 64, 24, 24]             128
             ReLU-33           [-1, 64, 24, 24]               0
      SkipConnect-34           [-1, 64, 24, 24]               0
        MaxPool2d-35           [-1, 64, 13, 13]               0
           Conv2d-36          [-1, 256, 15, 15]         147,712
      BatchNorm2d-37          [-1, 256, 15, 15]             512
             ReLU-38          [-1, 256, 15, 15]               0
      SkipConnect-39          [-1, 256, 15, 15]               0
           Conv2d-40          [-1, 128, 17, 17]         295,040
      BatchNorm2d-41          [-1, 128, 17, 17]             256
             ReLU-42          [-1, 128, 17, 17]               0
      SkipConnect-43          [-1, 128, 17, 17]               0
           Conv2d-44           [-1, 64, 19, 19]          73,792
      BatchNorm2d-45           [-1, 64, 19, 19]             128
             ReLU-46           [-1, 64, 19, 19]               0
      SkipConnect-47           [-1, 64, 19, 19]               0
           Conv2d-48           [-1, 64, 21, 21]          36,928
      BatchNorm2d-49           [-1, 64, 21, 21]             128
             ReLU-50           [-1, 64, 21, 21]               0
      SkipConnect-51           [-1, 64, 21, 21]               0
           Conv2d-52          [-1, 512, 23, 23]         295,424
      BatchNorm2d-53          [-1, 512, 23, 23]           1,024
             ReLU-54          [-1, 512, 23, 23]               0
      SkipConnect-55          [-1, 512, 23, 23]               0
           Conv2d-56          [-1, 512, 25, 25]       2,359,808
      BatchNorm2d-57          [-1, 512, 25, 25]           1,024
             ReLU-58          [-1, 512, 25, 25]               0
      SkipConnect-59          [-1, 512, 25, 25]               0
           Conv2d-60          [-1, 128, 27, 27]         589,952
      BatchNorm2d-61          [-1, 128, 27, 27]             256
             ReLU-62          [-1, 128, 27, 27]               0
      SkipConnect-63          [-1, 128, 27, 27]               0
           Conv2d-64          [-1, 128, 29, 29]         147,584
      BatchNorm2d-65          [-1, 128, 29, 29]             256
             ReLU-66          [-1, 128, 29, 29]               0
      SkipConnect-67          [-1, 128, 29, 29]               0
================================================================
Total params: 8,397,984
Trainable params: 8,397,984
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 49.61
Params size (MB): 32.04
Estimated Total Size (MB): 81.66
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 148.31
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.72
Current Fitness:
{'0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.8-0.6-128-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 0,
 '0.8-0.6-128-256-256-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 3
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
================================================================
Total params: 6,458,400
Trainable params: 6,458,400
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.79
Params size (MB): 24.64
Estimated Total Size (MB): 31.44
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.87
Epoch:  2
Epoch: 2 of 2	Acc: 20.3125	Loss: 147.35
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
           Conv2d-37             [-1, 64, 5, 5]          36,928
      BatchNorm2d-38             [-1, 64, 5, 5]             128
             ReLU-39             [-1, 64, 5, 5]               0
      SkipConnect-40             [-1, 64, 5, 5]               0
================================================================
Total params: 2,299,104
Trainable params: 2,299,104
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.67
Params size (MB): 8.77
Estimated Total Size (MB): 13.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.89
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.28
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
        MaxPool2d-21            [-1, 256, 3, 3]               0
           Conv2d-22             [-1, 64, 5, 5]         147,520
      BatchNorm2d-23             [-1, 64, 5, 5]             128
             ReLU-24             [-1, 64, 5, 5]               0
      SkipConnect-25             [-1, 64, 5, 5]               0
           Conv2d-26            [-1, 128, 7, 7]          73,856
      BatchNorm2d-27            [-1, 128, 7, 7]             256
             ReLU-28            [-1, 128, 7, 7]               0
      SkipConnect-29            [-1, 128, 7, 7]               0
           Conv2d-30             [-1, 64, 9, 9]          73,792
      BatchNorm2d-31             [-1, 64, 9, 9]             128
             ReLU-32             [-1, 64, 9, 9]               0
      SkipConnect-33             [-1, 64, 9, 9]               0
           Conv2d-34          [-1, 128, 11, 11]          73,856
      BatchNorm2d-35          [-1, 128, 11, 11]             256
             ReLU-36          [-1, 128, 11, 11]               0
      SkipConnect-37          [-1, 128, 11, 11]               0
        AvgPool2d-38            [-1, 128, 6, 6]               0
        AvgPool2d-39            [-1, 128, 4, 4]               0
================================================================
Total params: 564,960
Trainable params: 564,960
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.05
Params size (MB): 2.16
Estimated Total Size (MB): 6.21
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.39
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 147.24
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
        MaxPool2d-20            [-1, 128, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]         590,336
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]         589,952
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 5,279,136
Trainable params: 5,279,136
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.15
Params size (MB): 20.14
Estimated Total Size (MB): 26.30
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.81
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.37
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 128, 8, 8]         589,952
      BatchNorm2d-36            [-1, 128, 8, 8]             256
             ReLU-37            [-1, 128, 8, 8]               0
      SkipConnect-38            [-1, 128, 8, 8]               0
================================================================
Total params: 4,172,256
Trainable params: 4,172,256
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.72
Params size (MB): 15.92
Estimated Total Size (MB): 21.65
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 29.6875	Loss: 148.21
Epoch:  2
Epoch: 2 of 2	Acc: 28.125	Loss: 147.63
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39           [-1, 64, 11, 11]          36,928
      BatchNorm2d-40           [-1, 64, 11, 11]             128
             ReLU-41           [-1, 64, 11, 11]               0
      SkipConnect-42           [-1, 64, 11, 11]               0
           Conv2d-43          [-1, 512, 13, 13]         295,424
      BatchNorm2d-44          [-1, 512, 13, 13]           1,024
             ReLU-45          [-1, 512, 13, 13]               0
      SkipConnect-46          [-1, 512, 13, 13]               0
           Conv2d-47          [-1, 512, 15, 15]       2,359,808
      BatchNorm2d-48          [-1, 512, 15, 15]           1,024
             ReLU-49          [-1, 512, 15, 15]               0
      SkipConnect-50          [-1, 512, 15, 15]               0
           Conv2d-51          [-1, 128, 17, 17]         589,952
      BatchNorm2d-52          [-1, 128, 17, 17]             256
             ReLU-53          [-1, 128, 17, 17]               0
      SkipConnect-54          [-1, 128, 17, 17]               0
           Conv2d-55          [-1, 128, 19, 19]         147,584
      BatchNorm2d-56          [-1, 128, 19, 19]             256
             ReLU-57          [-1, 128, 19, 19]               0
      SkipConnect-58          [-1, 128, 19, 19]               0
================================================================
Total params: 6,054,624
Trainable params: 6,054,624
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 15.00
Params size (MB): 23.10
Estimated Total Size (MB): 38.10
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 148.2
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 147.73
Current Fitness:
{'0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.6-512-128-0.1-0.6-512-512-128-64': 0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-128': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 4
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
        MaxPool2d-21            [-1, 256, 3, 3]               0
           Conv2d-22             [-1, 64, 5, 5]         147,520
      BatchNorm2d-23             [-1, 64, 5, 5]             128
             ReLU-24             [-1, 64, 5, 5]               0
      SkipConnect-25             [-1, 64, 5, 5]               0
        AvgPool2d-26             [-1, 64, 3, 3]               0
        MaxPool2d-27             [-1, 64, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]         295,424
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
================================================================
Total params: 3,664,224
Trainable params: 3,664,224
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.44
Params size (MB): 13.98
Estimated Total Size (MB): 18.43
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.94
Epoch:  2
Epoch: 2 of 2	Acc: 28.125	Loss: 147.3
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
        MaxPool2d-20            [-1, 128, 7, 7]               0
        MaxPool2d-21            [-1, 128, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]          73,792
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
           Conv2d-26            [-1, 128, 8, 8]          73,856
      BatchNorm2d-27            [-1, 128, 8, 8]             256
             ReLU-28            [-1, 128, 8, 8]               0
      SkipConnect-29            [-1, 128, 8, 8]               0
           Conv2d-30           [-1, 64, 10, 10]          73,792
      BatchNorm2d-31           [-1, 64, 10, 10]             128
             ReLU-32           [-1, 64, 10, 10]               0
      SkipConnect-33           [-1, 64, 10, 10]               0
           Conv2d-34          [-1, 128, 12, 12]          73,856
      BatchNorm2d-35          [-1, 128, 12, 12]             256
             ReLU-36          [-1, 128, 12, 12]               0
      SkipConnect-37          [-1, 128, 12, 12]               0
        AvgPool2d-38            [-1, 128, 7, 7]               0
        AvgPool2d-39            [-1, 128, 4, 4]               0
================================================================
Total params: 777,312
Trainable params: 777,312
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.28
Params size (MB): 2.97
Estimated Total Size (MB): 6.26
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.46
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.33
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
           Conv2d-26            [-1, 128, 7, 7]         589,952
      BatchNorm2d-27            [-1, 128, 7, 7]             256
             ReLU-28            [-1, 128, 7, 7]               0
      SkipConnect-29            [-1, 128, 7, 7]               0
           Conv2d-30             [-1, 64, 9, 9]          73,792
      BatchNorm2d-31             [-1, 64, 9, 9]             128
             ReLU-32             [-1, 64, 9, 9]               0
      SkipConnect-33             [-1, 64, 9, 9]               0
           Conv2d-34          [-1, 128, 11, 11]          73,856
      BatchNorm2d-35          [-1, 128, 11, 11]             256
             ReLU-36          [-1, 128, 11, 11]               0
      SkipConnect-37          [-1, 128, 11, 11]               0
        AvgPool2d-38            [-1, 128, 6, 6]               0
        AvgPool2d-39            [-1, 128, 4, 4]               0
================================================================
Total params: 1,810,848
Trainable params: 1,810,848
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.36
Params size (MB): 6.91
Estimated Total Size (MB): 13.28
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.41
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 147.31
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
           Conv2d-21            [-1, 512, 7, 7]       1,180,160
      BatchNorm2d-22            [-1, 512, 7, 7]           1,024
             ReLU-23            [-1, 512, 7, 7]               0
      SkipConnect-24            [-1, 512, 7, 7]               0
           Conv2d-25            [-1, 128, 9, 9]         589,952
      BatchNorm2d-26            [-1, 128, 9, 9]             256
             ReLU-27            [-1, 128, 9, 9]               0
      SkipConnect-28            [-1, 128, 9, 9]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-36            [-1, 512, 7, 7]           1,024
             ReLU-37            [-1, 512, 7, 7]               0
      SkipConnect-38            [-1, 512, 7, 7]               0
           Conv2d-39            [-1, 128, 9, 9]         589,952
      BatchNorm2d-40            [-1, 128, 9, 9]             256
             ReLU-41            [-1, 128, 9, 9]               0
      SkipConnect-42            [-1, 128, 9, 9]               0
           Conv2d-43           [-1, 64, 11, 11]          73,792
      BatchNorm2d-44           [-1, 64, 11, 11]             128
             ReLU-45           [-1, 64, 11, 11]               0
      SkipConnect-46           [-1, 64, 11, 11]               0
================================================================
Total params: 5,582,880
Trainable params: 5,582,880
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.93
Params size (MB): 21.30
Estimated Total Size (MB): 27.24
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.05
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.47
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 2,770,272
Trainable params: 2,770,272
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.87
Params size (MB): 10.57
Estimated Total Size (MB): 17.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.87
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.28
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]         589,952
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 6,607,008
Trainable params: 6,607,008
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.15
Params size (MB): 25.20
Estimated Total Size (MB): 32.36
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.04
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.51
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39           [-1, 64, 10, 10]         294,976
      BatchNorm2d-40           [-1, 64, 10, 10]             128
             ReLU-41           [-1, 64, 10, 10]               0
      SkipConnect-42           [-1, 64, 10, 10]               0
           Conv2d-43          [-1, 512, 12, 12]         295,424
      BatchNorm2d-44          [-1, 512, 12, 12]           1,024
             ReLU-45          [-1, 512, 12, 12]               0
      SkipConnect-46          [-1, 512, 12, 12]               0
           Conv2d-47          [-1, 512, 14, 14]       2,359,808
      BatchNorm2d-48          [-1, 512, 14, 14]           1,024
             ReLU-49          [-1, 512, 14, 14]               0
      SkipConnect-50          [-1, 512, 14, 14]               0
           Conv2d-51          [-1, 128, 16, 16]         589,952
      BatchNorm2d-52          [-1, 128, 16, 16]             256
             ReLU-53          [-1, 128, 16, 16]               0
      SkipConnect-54          [-1, 128, 16, 16]               0
           Conv2d-55          [-1, 128, 18, 18]         147,584
      BatchNorm2d-56          [-1, 128, 18, 18]             256
             ReLU-57          [-1, 128, 18, 18]               0
      SkipConnect-58          [-1, 128, 18, 18]               0
================================================================
Total params: 9,633,312
Trainable params: 9,633,312
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 14.25
Params size (MB): 36.75
Estimated Total Size (MB): 51.01
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.26
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.67
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
           Conv2d-23          [-1, 512, 20, 20]         590,336
      BatchNorm2d-24          [-1, 512, 20, 20]           1,024
             ReLU-25          [-1, 512, 20, 20]               0
      SkipConnect-26          [-1, 512, 20, 20]               0
        MaxPool2d-27          [-1, 512, 11, 11]               0
        MaxPool2d-28            [-1, 512, 6, 6]               0
        MaxPool2d-29            [-1, 512, 4, 4]               0
           Conv2d-30            [-1, 256, 6, 6]       1,179,904
      BatchNorm2d-31            [-1, 256, 6, 6]             512
             ReLU-32            [-1, 256, 6, 6]               0
      SkipConnect-33            [-1, 256, 6, 6]               0
           Conv2d-34            [-1, 128, 8, 8]         295,040
      BatchNorm2d-35            [-1, 128, 8, 8]             256
             ReLU-36            [-1, 128, 8, 8]               0
      SkipConnect-37            [-1, 128, 8, 8]               0
           Conv2d-38           [-1, 64, 10, 10]          73,792
      BatchNorm2d-39           [-1, 64, 10, 10]             128
             ReLU-40           [-1, 64, 10, 10]               0
      SkipConnect-41           [-1, 64, 10, 10]               0
           Conv2d-42           [-1, 64, 12, 12]          36,928
      BatchNorm2d-43           [-1, 64, 12, 12]             128
             ReLU-44           [-1, 64, 12, 12]               0
      SkipConnect-45           [-1, 64, 12, 12]               0
           Conv2d-46          [-1, 512, 14, 14]         295,424
      BatchNorm2d-47          [-1, 512, 14, 14]           1,024
             ReLU-48          [-1, 512, 14, 14]               0
      SkipConnect-49          [-1, 512, 14, 14]               0
           Conv2d-50          [-1, 512, 16, 16]       2,359,808
      BatchNorm2d-51          [-1, 512, 16, 16]           1,024
             ReLU-52          [-1, 512, 16, 16]               0
      SkipConnect-53          [-1, 512, 16, 16]               0
           Conv2d-54          [-1, 128, 18, 18]         589,952
      BatchNorm2d-55          [-1, 128, 18, 18]             256
             ReLU-56          [-1, 128, 18, 18]               0
      SkipConnect-57          [-1, 128, 18, 18]               0
           Conv2d-58          [-1, 128, 20, 20]         147,584
      BatchNorm2d-59          [-1, 128, 20, 20]             256
             ReLU-60          [-1, 128, 20, 20]               0
      SkipConnect-61          [-1, 128, 20, 20]               0
================================================================
Total params: 7,530,720
Trainable params: 7,530,720
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 24.89
Params size (MB): 28.73
Estimated Total Size (MB): 53.63
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.93
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.45
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 2,253,408
Trainable params: 2,253,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.85
Params size (MB): 8.60
Estimated Total Size (MB): 17.46
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.44
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.31
Current Fitness:
{'0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.3-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 0,
 '0.8-0.6-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 0,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 5
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 2,770,272
Trainable params: 2,770,272
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.87
Params size (MB): 10.57
Estimated Total Size (MB): 17.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.91
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.47
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
        MaxPool2d-20            [-1, 128, 7, 7]               0
        MaxPool2d-21            [-1, 128, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]          73,792
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
           Conv2d-26            [-1, 128, 8, 8]          73,856
      BatchNorm2d-27            [-1, 128, 8, 8]             256
             ReLU-28            [-1, 128, 8, 8]               0
      SkipConnect-29            [-1, 128, 8, 8]               0
           Conv2d-30           [-1, 64, 10, 10]          73,792
      BatchNorm2d-31           [-1, 64, 10, 10]             128
             ReLU-32           [-1, 64, 10, 10]               0
      SkipConnect-33           [-1, 64, 10, 10]               0
           Conv2d-34          [-1, 128, 12, 12]          73,856
      BatchNorm2d-35          [-1, 128, 12, 12]             256
             ReLU-36          [-1, 128, 12, 12]               0
      SkipConnect-37          [-1, 128, 12, 12]               0
        AvgPool2d-38            [-1, 128, 7, 7]               0
        AvgPool2d-39            [-1, 128, 4, 4]               0
           Conv2d-40             [-1, 64, 6, 6]          73,792
      BatchNorm2d-41             [-1, 64, 6, 6]             128
             ReLU-42             [-1, 64, 6, 6]               0
      SkipConnect-43             [-1, 64, 6, 6]               0
           Conv2d-44            [-1, 256, 8, 8]         147,712
      BatchNorm2d-45            [-1, 256, 8, 8]             512
             ReLU-46            [-1, 256, 8, 8]               0
      SkipConnect-47            [-1, 256, 8, 8]               0
================================================================
Total params: 999,456
Trainable params: 999,456
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.85
Params size (MB): 3.81
Estimated Total Size (MB): 7.67
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.48
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.75
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
           Conv2d-23          [-1, 512, 20, 20]         590,336
      BatchNorm2d-24          [-1, 512, 20, 20]           1,024
             ReLU-25          [-1, 512, 20, 20]               0
      SkipConnect-26          [-1, 512, 20, 20]               0
        MaxPool2d-27          [-1, 512, 11, 11]               0
        MaxPool2d-28            [-1, 512, 6, 6]               0
        MaxPool2d-29            [-1, 512, 4, 4]               0
           Conv2d-30            [-1, 256, 6, 6]       1,179,904
      BatchNorm2d-31            [-1, 256, 6, 6]             512
             ReLU-32            [-1, 256, 6, 6]               0
      SkipConnect-33            [-1, 256, 6, 6]               0
           Conv2d-34            [-1, 128, 8, 8]         295,040
      BatchNorm2d-35            [-1, 128, 8, 8]             256
             ReLU-36            [-1, 128, 8, 8]               0
      SkipConnect-37            [-1, 128, 8, 8]               0
           Conv2d-38           [-1, 64, 10, 10]          73,792
      BatchNorm2d-39           [-1, 64, 10, 10]             128
             ReLU-40           [-1, 64, 10, 10]               0
      SkipConnect-41           [-1, 64, 10, 10]               0
           Conv2d-42           [-1, 64, 12, 12]          36,928
      BatchNorm2d-43           [-1, 64, 12, 12]             128
             ReLU-44           [-1, 64, 12, 12]               0
      SkipConnect-45           [-1, 64, 12, 12]               0
           Conv2d-46          [-1, 512, 14, 14]         295,424
      BatchNorm2d-47          [-1, 512, 14, 14]           1,024
             ReLU-48          [-1, 512, 14, 14]               0
      SkipConnect-49          [-1, 512, 14, 14]               0
           Conv2d-50          [-1, 512, 16, 16]       2,359,808
      BatchNorm2d-51          [-1, 512, 16, 16]           1,024
             ReLU-52          [-1, 512, 16, 16]               0
      SkipConnect-53          [-1, 512, 16, 16]               0
           Conv2d-54          [-1, 128, 18, 18]         589,952
      BatchNorm2d-55          [-1, 128, 18, 18]             256
             ReLU-56          [-1, 128, 18, 18]               0
      SkipConnect-57          [-1, 128, 18, 18]               0
           Conv2d-58          [-1, 128, 20, 20]         147,584
      BatchNorm2d-59          [-1, 128, 20, 20]             256
             ReLU-60          [-1, 128, 20, 20]               0
      SkipConnect-61          [-1, 128, 20, 20]               0
================================================================
Total params: 7,530,720
Trainable params: 7,530,720
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 24.89
Params size (MB): 28.73
Estimated Total Size (MB): 53.63
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 20.3125	Loss: 148.27
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.69
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 2,253,408
Trainable params: 2,253,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.85
Params size (MB): 8.60
Estimated Total Size (MB): 17.46
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.44
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.3
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
================================================================
Total params: 2,262,048
Trainable params: 2,262,048
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.62
Params size (MB): 8.63
Estimated Total Size (MB): 13.26
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 148.5
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.72
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        MaxPool2d-13          [-1, 512, 20, 20]               0
           Conv2d-14          [-1, 256, 22, 22]       1,179,904
      BatchNorm2d-15          [-1, 256, 22, 22]             512
             ReLU-16          [-1, 256, 22, 22]               0
      SkipConnect-17          [-1, 256, 22, 22]               0
           Conv2d-18          [-1, 128, 24, 24]         295,040
      BatchNorm2d-19          [-1, 128, 24, 24]             256
             ReLU-20          [-1, 128, 24, 24]               0
      SkipConnect-21          [-1, 128, 24, 24]               0
           Conv2d-22          [-1, 128, 26, 26]         147,584
      BatchNorm2d-23          [-1, 128, 26, 26]             256
             ReLU-24          [-1, 128, 26, 26]               0
      SkipConnect-25          [-1, 128, 26, 26]               0
           Conv2d-26          [-1, 512, 28, 28]         590,336
      BatchNorm2d-27          [-1, 512, 28, 28]           1,024
             ReLU-28          [-1, 512, 28, 28]               0
      SkipConnect-29          [-1, 512, 28, 28]               0
        MaxPool2d-30          [-1, 512, 15, 15]               0
        MaxPool2d-31            [-1, 512, 8, 8]               0
           Conv2d-32          [-1, 128, 10, 10]         589,952
      BatchNorm2d-33          [-1, 128, 10, 10]             256
             ReLU-34          [-1, 128, 10, 10]               0
      SkipConnect-35          [-1, 128, 10, 10]               0
           Conv2d-36           [-1, 64, 12, 12]          73,792
      BatchNorm2d-37           [-1, 64, 12, 12]             128
             ReLU-38           [-1, 64, 12, 12]               0
      SkipConnect-39           [-1, 64, 12, 12]               0
           Conv2d-40          [-1, 128, 14, 14]          73,856
      BatchNorm2d-41          [-1, 128, 14, 14]             256
             ReLU-42          [-1, 128, 14, 14]               0
      SkipConnect-43          [-1, 128, 14, 14]               0
        AvgPool2d-44            [-1, 128, 8, 8]               0
        AvgPool2d-45            [-1, 128, 5, 5]               0
================================================================
Total params: 3,259,488
Trainable params: 3,259,488
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 50.80
Params size (MB): 12.43
Estimated Total Size (MB): 63.24
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.51
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.35
Current Fitness:
{'0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 0,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 6
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        MaxPool2d-13          [-1, 512, 20, 20]               0
           Conv2d-14          [-1, 256, 22, 22]       1,179,904
      BatchNorm2d-15          [-1, 256, 22, 22]             512
             ReLU-16          [-1, 256, 22, 22]               0
      SkipConnect-17          [-1, 256, 22, 22]               0
           Conv2d-18          [-1, 128, 24, 24]         295,040
      BatchNorm2d-19          [-1, 128, 24, 24]             256
             ReLU-20          [-1, 128, 24, 24]               0
      SkipConnect-21          [-1, 128, 24, 24]               0
           Conv2d-22          [-1, 128, 26, 26]         147,584
      BatchNorm2d-23          [-1, 128, 26, 26]             256
             ReLU-24          [-1, 128, 26, 26]               0
      SkipConnect-25          [-1, 128, 26, 26]               0
           Conv2d-26          [-1, 512, 28, 28]         590,336
      BatchNorm2d-27          [-1, 512, 28, 28]           1,024
             ReLU-28          [-1, 512, 28, 28]               0
      SkipConnect-29          [-1, 512, 28, 28]               0
        MaxPool2d-30          [-1, 512, 15, 15]               0
        MaxPool2d-31            [-1, 512, 8, 8]               0
        AvgPool2d-32            [-1, 512, 5, 5]               0
        MaxPool2d-33            [-1, 512, 3, 3]               0
           Conv2d-34            [-1, 512, 5, 5]       2,359,808
      BatchNorm2d-35            [-1, 512, 5, 5]           1,024
             ReLU-36            [-1, 512, 5, 5]               0
      SkipConnect-37            [-1, 512, 5, 5]               0
           Conv2d-38            [-1, 128, 7, 7]         589,952
      BatchNorm2d-39            [-1, 128, 7, 7]             256
             ReLU-40            [-1, 128, 7, 7]               0
      SkipConnect-41            [-1, 128, 7, 7]               0
================================================================
Total params: 5,472,288
Trainable params: 5,472,288
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 49.99
Params size (MB): 20.88
Estimated Total Size (MB): 70.87
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 148.11
Epoch:  2
Epoch: 2 of 2	Acc: 28.125	Loss: 147.47
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 2,253,408
Trainable params: 2,253,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.85
Params size (MB): 8.60
Estimated Total Size (MB): 17.46
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 28.125	Loss: 147.44
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.33
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        MaxPool2d-13          [-1, 512, 20, 20]               0
           Conv2d-14          [-1, 256, 22, 22]       1,179,904
      BatchNorm2d-15          [-1, 256, 22, 22]             512
             ReLU-16          [-1, 256, 22, 22]               0
      SkipConnect-17          [-1, 256, 22, 22]               0
           Conv2d-18          [-1, 128, 24, 24]         295,040
      BatchNorm2d-19          [-1, 128, 24, 24]             256
             ReLU-20          [-1, 128, 24, 24]               0
      SkipConnect-21          [-1, 128, 24, 24]               0
           Conv2d-22          [-1, 128, 26, 26]         147,584
      BatchNorm2d-23          [-1, 128, 26, 26]             256
             ReLU-24          [-1, 128, 26, 26]               0
      SkipConnect-25          [-1, 128, 26, 26]               0
        MaxPool2d-26          [-1, 128, 14, 14]               0
        MaxPool2d-27            [-1, 128, 8, 8]               0
           Conv2d-28           [-1, 64, 10, 10]          73,792
      BatchNorm2d-29           [-1, 64, 10, 10]             128
             ReLU-30           [-1, 64, 10, 10]               0
      SkipConnect-31           [-1, 64, 10, 10]               0
           Conv2d-32          [-1, 128, 12, 12]          73,856
      BatchNorm2d-33          [-1, 128, 12, 12]             256
             ReLU-34          [-1, 128, 12, 12]               0
      SkipConnect-35          [-1, 128, 12, 12]               0
           Conv2d-36           [-1, 64, 14, 14]          73,792
      BatchNorm2d-37           [-1, 64, 14, 14]             128
             ReLU-38           [-1, 64, 14, 14]               0
      SkipConnect-39           [-1, 64, 14, 14]               0
           Conv2d-40          [-1, 128, 16, 16]          73,856
      BatchNorm2d-41          [-1, 128, 16, 16]             256
             ReLU-42          [-1, 128, 16, 16]               0
      SkipConnect-43          [-1, 128, 16, 16]               0
        AvgPool2d-44            [-1, 128, 9, 9]               0
        AvgPool2d-45            [-1, 128, 5, 5]               0
           Conv2d-46             [-1, 64, 7, 7]          73,792
      BatchNorm2d-47             [-1, 64, 7, 7]             128
             ReLU-48             [-1, 64, 7, 7]               0
      SkipConnect-49             [-1, 64, 7, 7]               0
           Conv2d-50            [-1, 256, 9, 9]         147,712
      BatchNorm2d-51            [-1, 256, 9, 9]             512
             ReLU-52            [-1, 256, 9, 9]               0
      SkipConnect-53            [-1, 256, 9, 9]               0
================================================================
Total params: 2,448,096
Trainable params: 2,448,096
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 39.12
Params size (MB): 9.34
Estimated Total Size (MB): 48.47
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.38
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.76
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
        AvgPool2d-15            [-1, 256, 8, 8]               0
           Conv2d-16          [-1, 256, 10, 10]         590,080
      BatchNorm2d-17          [-1, 256, 10, 10]             512
             ReLU-18          [-1, 256, 10, 10]               0
      SkipConnect-19          [-1, 256, 10, 10]               0
           Conv2d-20          [-1, 256, 12, 12]         590,080
      BatchNorm2d-21          [-1, 256, 12, 12]             512
             ReLU-22          [-1, 256, 12, 12]               0
      SkipConnect-23          [-1, 256, 12, 12]               0
        MaxPool2d-24            [-1, 256, 7, 7]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
================================================================
Total params: 2,972,448
Trainable params: 2,972,448
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.38
Params size (MB): 11.34
Estimated Total Size (MB): 16.73
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 149.04
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 147.9
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
           Conv2d-29          [-1, 128, 13, 13]         147,584
      BatchNorm2d-30          [-1, 128, 13, 13]             256
             ReLU-31          [-1, 128, 13, 13]               0
      SkipConnect-32          [-1, 128, 13, 13]               0
           Conv2d-33           [-1, 64, 15, 15]          73,792
      BatchNorm2d-34           [-1, 64, 15, 15]             128
             ReLU-35           [-1, 64, 15, 15]               0
      SkipConnect-36           [-1, 64, 15, 15]               0
           Conv2d-37          [-1, 128, 17, 17]          73,856
      BatchNorm2d-38          [-1, 128, 17, 17]             256
             ReLU-39          [-1, 128, 17, 17]               0
      SkipConnect-40          [-1, 128, 17, 17]               0
        AvgPool2d-41            [-1, 128, 9, 9]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 3,286,560
Trainable params: 3,286,560
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.19
Params size (MB): 12.54
Estimated Total Size (MB): 19.74
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.5
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.37
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 2,770,272
Trainable params: 2,770,272
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.87
Params size (MB): 10.57
Estimated Total Size (MB): 17.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 20.3125	Loss: 147.9
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 147.54
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 2,253,408
Trainable params: 2,253,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.85
Params size (MB): 8.60
Estimated Total Size (MB): 17.46
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.46
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.35
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
        AvgPool2d-29             [-1, 64, 5, 5]               0
        MaxPool2d-30             [-1, 64, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         295,424
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-36            [-1, 512, 7, 7]           1,024
             ReLU-37            [-1, 512, 7, 7]               0
      SkipConnect-38            [-1, 512, 7, 7]               0
           Conv2d-39            [-1, 128, 9, 9]         589,952
      BatchNorm2d-40            [-1, 128, 9, 9]             256
             ReLU-41            [-1, 128, 9, 9]               0
      SkipConnect-42            [-1, 128, 9, 9]               0
           Conv2d-43           [-1, 64, 11, 11]          73,792
      BatchNorm2d-44           [-1, 64, 11, 11]             128
             ReLU-45           [-1, 64, 11, 11]               0
      SkipConnect-46           [-1, 64, 11, 11]               0
================================================================
Total params: 5,352,672
Trainable params: 5,352,672
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.05
Params size (MB): 20.42
Estimated Total Size (MB): 29.48
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.92
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.33
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 128, 24, 24]         295,040
      BatchNorm2d-23          [-1, 128, 24, 24]             256
             ReLU-24          [-1, 128, 24, 24]               0
      SkipConnect-25          [-1, 128, 24, 24]               0
           Conv2d-26          [-1, 512, 26, 26]         590,336
      BatchNorm2d-27          [-1, 512, 26, 26]           1,024
             ReLU-28          [-1, 512, 26, 26]               0
      SkipConnect-29          [-1, 512, 26, 26]               0
           Conv2d-30          [-1, 512, 28, 28]       2,359,808
      BatchNorm2d-31          [-1, 512, 28, 28]           1,024
             ReLU-32          [-1, 512, 28, 28]               0
      SkipConnect-33          [-1, 512, 28, 28]               0
           Conv2d-34           [-1, 64, 30, 30]         294,976
      BatchNorm2d-35           [-1, 64, 30, 30]             128
             ReLU-36           [-1, 64, 30, 30]               0
      SkipConnect-37           [-1, 64, 30, 30]               0
        AvgPool2d-38           [-1, 64, 16, 16]               0
        MaxPool2d-39             [-1, 64, 9, 9]               0
           Conv2d-40          [-1, 512, 11, 11]         295,424
      BatchNorm2d-41          [-1, 512, 11, 11]           1,024
             ReLU-42          [-1, 512, 11, 11]               0
      SkipConnect-43          [-1, 512, 11, 11]               0
           Conv2d-44          [-1, 128, 13, 13]         589,952
      BatchNorm2d-45          [-1, 128, 13, 13]             256
             ReLU-46          [-1, 128, 13, 13]               0
      SkipConnect-47          [-1, 128, 13, 13]               0
================================================================
Total params: 5,178,912
Trainable params: 5,178,912
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 73.05
Params size (MB): 19.76
Estimated Total Size (MB): 92.81
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.23
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.77
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 0,
 '0.6-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.3-0.6-512-128': 0,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 7
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 512, 14, 14]         295,424
      BatchNorm2d-38          [-1, 512, 14, 14]           1,024
             ReLU-39          [-1, 512, 14, 14]               0
      SkipConnect-40          [-1, 512, 14, 14]               0
           Conv2d-41          [-1, 512, 16, 16]       2,359,808
      BatchNorm2d-42          [-1, 512, 16, 16]           1,024
             ReLU-43          [-1, 512, 16, 16]               0
      SkipConnect-44          [-1, 512, 16, 16]               0
           Conv2d-45          [-1, 128, 18, 18]         589,952
      BatchNorm2d-46          [-1, 128, 18, 18]             256
             ReLU-47          [-1, 128, 18, 18]               0
      SkipConnect-48          [-1, 128, 18, 18]               0
           Conv2d-49           [-1, 64, 20, 20]          73,792
      BatchNorm2d-50           [-1, 64, 20, 20]             128
             ReLU-51           [-1, 64, 20, 20]               0
      SkipConnect-52           [-1, 64, 20, 20]               0
================================================================
Total params: 5,500,704
Trainable params: 5,500,704
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 17.11
Params size (MB): 20.98
Estimated Total Size (MB): 38.10
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 148.27
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.53
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
           Conv2d-21            [-1, 512, 7, 7]       1,180,160
      BatchNorm2d-22            [-1, 512, 7, 7]           1,024
             ReLU-23            [-1, 512, 7, 7]               0
      SkipConnect-24            [-1, 512, 7, 7]               0
           Conv2d-25            [-1, 128, 9, 9]         589,952
      BatchNorm2d-26            [-1, 128, 9, 9]             256
             ReLU-27            [-1, 128, 9, 9]               0
      SkipConnect-28            [-1, 128, 9, 9]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-36            [-1, 512, 7, 7]           1,024
             ReLU-37            [-1, 512, 7, 7]               0
      SkipConnect-38            [-1, 512, 7, 7]               0
           Conv2d-39             [-1, 64, 9, 9]         294,976
      BatchNorm2d-40             [-1, 64, 9, 9]             128
             ReLU-41             [-1, 64, 9, 9]               0
      SkipConnect-42             [-1, 64, 9, 9]               0
           Conv2d-43          [-1, 512, 11, 11]         295,424
      BatchNorm2d-44          [-1, 512, 11, 11]           1,024
             ReLU-45          [-1, 512, 11, 11]               0
      SkipConnect-46          [-1, 512, 11, 11]               0
           Conv2d-47          [-1, 512, 13, 13]       2,359,808
      BatchNorm2d-48          [-1, 512, 13, 13]           1,024
             ReLU-49          [-1, 512, 13, 13]               0
      SkipConnect-50          [-1, 512, 13, 13]               0
           Conv2d-51          [-1, 128, 15, 15]         589,952
      BatchNorm2d-52          [-1, 128, 15, 15]             256
             ReLU-53          [-1, 128, 15, 15]               0
      SkipConnect-54          [-1, 128, 15, 15]               0
           Conv2d-55          [-1, 128, 17, 17]         147,584
      BatchNorm2d-56          [-1, 128, 17, 17]             256
             ReLU-57          [-1, 128, 17, 17]               0
      SkipConnect-58          [-1, 128, 17, 17]               0
================================================================
Total params: 8,609,184
Trainable params: 8,609,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 12.08
Params size (MB): 32.84
Estimated Total Size (MB): 44.93
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 29.6875	Loss: 148.15
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.6
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
        MaxPool2d-25            [-1, 512, 4, 4]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 2,410,080
Trainable params: 2,410,080
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.22
Params size (MB): 9.19
Estimated Total Size (MB): 15.42
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.94
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.41
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 256, 12, 12]          37,120
       BatchNorm2d-8          [-1, 256, 12, 12]             512
              ReLU-9          [-1, 256, 12, 12]               0
      SkipConnect-10          [-1, 256, 12, 12]               0
           Conv2d-11          [-1, 512, 14, 14]       1,180,160
      BatchNorm2d-12          [-1, 512, 14, 14]           1,024
             ReLU-13          [-1, 512, 14, 14]               0
      SkipConnect-14          [-1, 512, 14, 14]               0
           Conv2d-15          [-1, 128, 16, 16]         589,952
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
      SkipConnect-18          [-1, 128, 16, 16]               0
           Conv2d-19          [-1, 128, 18, 18]         147,584
      BatchNorm2d-20          [-1, 128, 18, 18]             256
             ReLU-21          [-1, 128, 18, 18]               0
      SkipConnect-22          [-1, 128, 18, 18]               0
        MaxPool2d-23          [-1, 128, 10, 10]               0
        MaxPool2d-24            [-1, 128, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]          73,792
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 2,253,408
Trainable params: 2,253,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.85
Params size (MB): 8.60
Estimated Total Size (MB): 17.46
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.43
Epoch:  2
Epoch: 2 of 2	Acc: 20.3125	Loss: 147.27
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        AvgPool2d-32            [-1, 128, 8, 8]               0
        MaxPool2d-33            [-1, 128, 5, 5]               0
           Conv2d-34            [-1, 128, 7, 7]         147,584
      BatchNorm2d-35            [-1, 128, 7, 7]             256
             ReLU-36            [-1, 128, 7, 7]               0
      SkipConnect-37            [-1, 128, 7, 7]               0
        AvgPool2d-38            [-1, 128, 4, 4]               0
        AvgPool2d-39            [-1, 128, 3, 3]               0
================================================================
Total params: 3,415,392
Trainable params: 3,415,392
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 10.75
Params size (MB): 13.03
Estimated Total Size (MB): 23.80
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.3
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.27
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 128, 24, 24]         295,040
      BatchNorm2d-23          [-1, 128, 24, 24]             256
             ReLU-24          [-1, 128, 24, 24]               0
      SkipConnect-25          [-1, 128, 24, 24]               0
           Conv2d-26          [-1, 512, 26, 26]         590,336
      BatchNorm2d-27          [-1, 512, 26, 26]           1,024
             ReLU-28          [-1, 512, 26, 26]               0
      SkipConnect-29          [-1, 512, 26, 26]               0
           Conv2d-30          [-1, 512, 28, 28]       2,359,808
      BatchNorm2d-31          [-1, 512, 28, 28]           1,024
             ReLU-32          [-1, 512, 28, 28]               0
      SkipConnect-33          [-1, 512, 28, 28]               0
           Conv2d-34           [-1, 64, 30, 30]         294,976
      BatchNorm2d-35           [-1, 64, 30, 30]             128
             ReLU-36           [-1, 64, 30, 30]               0
      SkipConnect-37           [-1, 64, 30, 30]               0
        AvgPool2d-38           [-1, 64, 16, 16]               0
        MaxPool2d-39             [-1, 64, 9, 9]               0
           Conv2d-40          [-1, 512, 11, 11]         295,424
      BatchNorm2d-41          [-1, 512, 11, 11]           1,024
             ReLU-42          [-1, 512, 11, 11]               0
      SkipConnect-43          [-1, 512, 11, 11]               0
           Conv2d-44          [-1, 128, 13, 13]         589,952
      BatchNorm2d-45          [-1, 128, 13, 13]             256
             ReLU-46          [-1, 128, 13, 13]               0
      SkipConnect-47          [-1, 128, 13, 13]               0
================================================================
Total params: 5,178,912
Trainable params: 5,178,912
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 73.05
Params size (MB): 19.76
Estimated Total Size (MB): 92.81
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.2
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.71
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-128-0.2-0.3': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.3-0.6-512-128': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 8
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 512, 8, 8]          74,240
       BatchNorm2d-9            [-1, 512, 8, 8]           1,024
             ReLU-10            [-1, 512, 8, 8]               0
      SkipConnect-11            [-1, 512, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         589,952
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
        MaxPool2d-20            [-1, 128, 7, 7]               0
        MaxPool2d-21            [-1, 128, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]          73,792
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
           Conv2d-26            [-1, 128, 8, 8]          73,856
      BatchNorm2d-27            [-1, 128, 8, 8]             256
             ReLU-28            [-1, 128, 8, 8]               0
      SkipConnect-29            [-1, 128, 8, 8]               0
           Conv2d-30           [-1, 64, 10, 10]          73,792
      BatchNorm2d-31           [-1, 64, 10, 10]             128
             ReLU-32           [-1, 64, 10, 10]               0
      SkipConnect-33           [-1, 64, 10, 10]               0
           Conv2d-34          [-1, 128, 12, 12]          73,856
      BatchNorm2d-35          [-1, 128, 12, 12]             256
             ReLU-36          [-1, 128, 12, 12]               0
      SkipConnect-37          [-1, 128, 12, 12]               0
        AvgPool2d-38            [-1, 128, 7, 7]               0
        AvgPool2d-39            [-1, 128, 4, 4]               0
================================================================
Total params: 1,109,856
Trainable params: 1,109,856
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.78
Params size (MB): 4.23
Estimated Total Size (MB): 8.02
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.47
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.31
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 2,770,272
Trainable params: 2,770,272
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.87
Params size (MB): 10.57
Estimated Total Size (MB): 17.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.07
Epoch:  2
Epoch: 2 of 2	Acc: 28.125	Loss: 147.38
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
        MaxPool2d-25            [-1, 512, 4, 4]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         147,520
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
           Conv2d-37             [-1, 64, 5, 5]          36,928
      BatchNorm2d-38             [-1, 64, 5, 5]             128
             ReLU-39             [-1, 64, 5, 5]               0
      SkipConnect-40             [-1, 64, 5, 5]               0
================================================================
Total params: 2,077,536
Trainable params: 2,077,536
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.22
Params size (MB): 7.93
Estimated Total Size (MB): 13.16
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.84
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.32
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         589,952
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 2,779,104
Trainable params: 2,779,104
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.67
Params size (MB): 10.60
Estimated Total Size (MB): 16.28
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.18
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.36
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]         147,520
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 1,865,952
Trainable params: 1,865,952
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.16
Params size (MB): 7.12
Estimated Total Size (MB): 16.29
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.44
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.29
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 128, 24, 24]         295,040
      BatchNorm2d-23          [-1, 128, 24, 24]             256
             ReLU-24          [-1, 128, 24, 24]               0
      SkipConnect-25          [-1, 128, 24, 24]               0
           Conv2d-26          [-1, 512, 26, 26]         590,336
      BatchNorm2d-27          [-1, 512, 26, 26]           1,024
             ReLU-28          [-1, 512, 26, 26]               0
      SkipConnect-29          [-1, 512, 26, 26]               0
           Conv2d-30          [-1, 512, 28, 28]       2,359,808
      BatchNorm2d-31          [-1, 512, 28, 28]           1,024
             ReLU-32          [-1, 512, 28, 28]               0
      SkipConnect-33          [-1, 512, 28, 28]               0
           Conv2d-34           [-1, 64, 30, 30]         294,976
      BatchNorm2d-35           [-1, 64, 30, 30]             128
             ReLU-36           [-1, 64, 30, 30]               0
      SkipConnect-37           [-1, 64, 30, 30]               0
        MaxPool2d-38           [-1, 64, 16, 16]               0
           Conv2d-39          [-1, 256, 18, 18]         147,712
      BatchNorm2d-40          [-1, 256, 18, 18]             512
             ReLU-41          [-1, 256, 18, 18]               0
      SkipConnect-42          [-1, 256, 18, 18]               0
           Conv2d-43          [-1, 128, 20, 20]         295,040
      BatchNorm2d-44          [-1, 128, 20, 20]             256
             ReLU-45          [-1, 128, 20, 20]               0
      SkipConnect-46          [-1, 128, 20, 20]               0
           Conv2d-47          [-1, 512, 22, 22]         590,336
      BatchNorm2d-48          [-1, 512, 22, 22]           1,024
             ReLU-49          [-1, 512, 22, 22]               0
      SkipConnect-50          [-1, 512, 22, 22]               0
           Conv2d-51          [-1, 128, 24, 24]         589,952
      BatchNorm2d-52          [-1, 128, 24, 24]             256
             ReLU-53          [-1, 128, 24, 24]               0
      SkipConnect-54          [-1, 128, 24, 24]               0
           Conv2d-55           [-1, 64, 26, 26]          73,792
      BatchNorm2d-56           [-1, 64, 26, 26]             128
             ReLU-57           [-1, 64, 26, 26]               0
      SkipConnect-58           [-1, 64, 26, 26]               0
================================================================
Total params: 5,991,264
Trainable params: 5,991,264
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 85.68
Params size (MB): 22.85
Estimated Total Size (MB): 108.55
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.49
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.9
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
        MaxPool2d-25            [-1, 512, 4, 4]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
================================================================
Total params: 6,098,208
Trainable params: 6,098,208
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.14
Params size (MB): 23.26
Estimated Total Size (MB): 29.42
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.1
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.35
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32             [-1, 64, 6, 6]         294,976
      BatchNorm2d-33             [-1, 64, 6, 6]             128
             ReLU-34             [-1, 64, 6, 6]               0
      SkipConnect-35             [-1, 64, 6, 6]               0
           Conv2d-36             [-1, 64, 8, 8]          36,928
      BatchNorm2d-37             [-1, 64, 8, 8]             128
             ReLU-38             [-1, 64, 8, 8]               0
      SkipConnect-39             [-1, 64, 8, 8]               0
           Conv2d-40          [-1, 512, 10, 10]         295,424
      BatchNorm2d-41          [-1, 512, 10, 10]           1,024
             ReLU-42          [-1, 512, 10, 10]               0
      SkipConnect-43          [-1, 512, 10, 10]               0
           Conv2d-44          [-1, 512, 12, 12]       2,359,808
      BatchNorm2d-45          [-1, 512, 12, 12]           1,024
             ReLU-46          [-1, 512, 12, 12]               0
      SkipConnect-47          [-1, 512, 12, 12]               0
           Conv2d-48          [-1, 128, 14, 14]         589,952
      BatchNorm2d-49          [-1, 128, 14, 14]             256
             ReLU-50          [-1, 128, 14, 14]               0
      SkipConnect-51          [-1, 128, 14, 14]               0
           Conv2d-52          [-1, 128, 16, 16]         147,584
      BatchNorm2d-53          [-1, 128, 16, 16]             256
             ReLU-54          [-1, 128, 16, 16]               0
      SkipConnect-55          [-1, 128, 16, 16]               0
================================================================
Total params: 7,160,928
Trainable params: 7,160,928
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.56
Params size (MB): 27.32
Estimated Total Size (MB): 38.89
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.27
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.62
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-64-64-512-512-128-128': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 0,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5}
Generation: 9
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         589,952
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39           [-1, 64, 11, 11]          36,928
      BatchNorm2d-40           [-1, 64, 11, 11]             128
             ReLU-41           [-1, 64, 11, 11]               0
      SkipConnect-42           [-1, 64, 11, 11]               0
           Conv2d-43          [-1, 512, 13, 13]         295,424
      BatchNorm2d-44          [-1, 512, 13, 13]           1,024
             ReLU-45          [-1, 512, 13, 13]               0
      SkipConnect-46          [-1, 512, 13, 13]               0
           Conv2d-47          [-1, 512, 15, 15]       2,359,808
      BatchNorm2d-48          [-1, 512, 15, 15]           1,024
             ReLU-49          [-1, 512, 15, 15]               0
      SkipConnect-50          [-1, 512, 15, 15]               0
           Conv2d-51          [-1, 128, 17, 17]         589,952
      BatchNorm2d-52          [-1, 128, 17, 17]             256
             ReLU-53          [-1, 128, 17, 17]               0
      SkipConnect-54          [-1, 128, 17, 17]               0
           Conv2d-55          [-1, 128, 19, 19]         147,584
      BatchNorm2d-56          [-1, 128, 19, 19]             256
             ReLU-57          [-1, 128, 19, 19]               0
      SkipConnect-58          [-1, 128, 19, 19]               0
================================================================
Total params: 6,063,456
Trainable params: 6,063,456
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 13.79
Params size (MB): 23.13
Estimated Total Size (MB): 36.94
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 148.37
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.65
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         147,520
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
           Conv2d-37             [-1, 64, 5, 5]          36,928
      BatchNorm2d-38             [-1, 64, 5, 5]             128
             ReLU-39             [-1, 64, 5, 5]               0
      SkipConnect-40             [-1, 64, 5, 5]               0
================================================================
Total params: 2,437,728
Trainable params: 2,437,728
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.87
Params size (MB): 9.30
Estimated Total Size (MB): 15.18
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.77
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.3
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
        MaxPool2d-20            [-1, 128, 5, 5]               0
        MaxPool2d-21            [-1, 128, 3, 3]               0
           Conv2d-22             [-1, 64, 5, 5]          73,792
      BatchNorm2d-23             [-1, 64, 5, 5]             128
             ReLU-24             [-1, 64, 5, 5]               0
      SkipConnect-25             [-1, 64, 5, 5]               0
           Conv2d-26            [-1, 128, 7, 7]          73,856
      BatchNorm2d-27            [-1, 128, 7, 7]             256
             ReLU-28            [-1, 128, 7, 7]               0
      SkipConnect-29            [-1, 128, 7, 7]               0
           Conv2d-30             [-1, 64, 9, 9]          73,792
      BatchNorm2d-31             [-1, 64, 9, 9]             128
             ReLU-32             [-1, 64, 9, 9]               0
      SkipConnect-33             [-1, 64, 9, 9]               0
           Conv2d-34          [-1, 128, 11, 11]          73,856
      BatchNorm2d-35          [-1, 128, 11, 11]             256
             ReLU-36          [-1, 128, 11, 11]               0
      SkipConnect-37          [-1, 128, 11, 11]               0
        AvgPool2d-38            [-1, 128, 6, 6]               0
        AvgPool2d-39            [-1, 128, 4, 4]               0
================================================================
Total params: 417,120
Trainable params: 417,120
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.70
Params size (MB): 1.59
Estimated Total Size (MB): 5.30
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.41
Epoch:  2
Epoch: 2 of 2	Acc: 20.3125	Loss: 147.29
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
        AvgPool2d-13           [-1, 64, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]          36,928
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 128, 24, 24]          73,856
      BatchNorm2d-19          [-1, 128, 24, 24]             256
             ReLU-20          [-1, 128, 24, 24]               0
      SkipConnect-21          [-1, 128, 24, 24]               0
           Conv2d-22          [-1, 128, 26, 26]         147,584
      BatchNorm2d-23          [-1, 128, 26, 26]             256
             ReLU-24          [-1, 128, 26, 26]               0
      SkipConnect-25          [-1, 128, 26, 26]               0
        MaxPool2d-26          [-1, 128, 14, 14]               0
        MaxPool2d-27            [-1, 128, 8, 8]               0
           Conv2d-28           [-1, 64, 10, 10]          73,792
      BatchNorm2d-29           [-1, 64, 10, 10]             128
             ReLU-30           [-1, 64, 10, 10]               0
      SkipConnect-31           [-1, 64, 10, 10]               0
           Conv2d-32          [-1, 128, 12, 12]          73,856
      BatchNorm2d-33          [-1, 128, 12, 12]             256
             ReLU-34          [-1, 128, 12, 12]               0
      SkipConnect-35          [-1, 128, 12, 12]               0
           Conv2d-36           [-1, 64, 14, 14]          73,792
      BatchNorm2d-37           [-1, 64, 14, 14]             128
             ReLU-38           [-1, 64, 14, 14]               0
      SkipConnect-39           [-1, 64, 14, 14]               0
           Conv2d-40          [-1, 128, 16, 16]          73,856
      BatchNorm2d-41          [-1, 128, 16, 16]             256
             ReLU-42          [-1, 128, 16, 16]               0
      SkipConnect-43          [-1, 128, 16, 16]               0
        AvgPool2d-44            [-1, 128, 9, 9]               0
        AvgPool2d-45            [-1, 128, 5, 5]               0
================================================================
Total params: 602,016
Trainable params: 602,016
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 14.45
Params size (MB): 2.30
Estimated Total Size (MB): 16.75
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 147.51
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.34
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
        AvgPool2d-13           [-1, 64, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]          36,928
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
           Conv2d-32           [-1, 64, 10, 10]         147,520
      BatchNorm2d-33           [-1, 64, 10, 10]             128
             ReLU-34           [-1, 64, 10, 10]               0
      SkipConnect-35           [-1, 64, 10, 10]               0
           Conv2d-36          [-1, 512, 12, 12]         295,424
      BatchNorm2d-37          [-1, 512, 12, 12]           1,024
             ReLU-38          [-1, 512, 12, 12]               0
      SkipConnect-39          [-1, 512, 12, 12]               0
           Conv2d-40          [-1, 256, 14, 14]       1,179,904
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
      SkipConnect-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 16, 16]         590,080
      BatchNorm2d-45          [-1, 256, 16, 16]             512
             ReLU-46          [-1, 256, 16, 16]               0
      SkipConnect-47          [-1, 256, 16, 16]               0
           Conv2d-48          [-1, 128, 18, 18]         295,040
      BatchNorm2d-49          [-1, 128, 18, 18]             256
             ReLU-50          [-1, 128, 18, 18]               0
      SkipConnect-51          [-1, 128, 18, 18]               0
           Conv2d-52           [-1, 64, 20, 20]          73,792
      BatchNorm2d-53           [-1, 64, 20, 20]             128
             ReLU-54           [-1, 64, 20, 20]               0
      SkipConnect-55           [-1, 64, 20, 20]               0
================================================================
Total params: 4,735,776
Trainable params: 4,735,776
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 36.05
Params size (MB): 18.07
Estimated Total Size (MB): 54.13
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.91
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.53
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
        AvgPool2d-39             [-1, 64, 5, 5]               0
        MaxPool2d-40             [-1, 64, 3, 3]               0
================================================================
Total params: 2,622,240
Trainable params: 2,622,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.08
Params size (MB): 10.00
Estimated Total Size (MB): 16.10
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.94
Epoch:  2
Epoch: 2 of 2	Acc: 37.5	Loss: 147.22
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
         AvgPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8             [-1, 64, 8, 8]           9,280
       BatchNorm2d-9             [-1, 64, 8, 8]             128
             ReLU-10             [-1, 64, 8, 8]               0
      SkipConnect-11             [-1, 64, 8, 8]               0
           Conv2d-12          [-1, 512, 10, 10]         295,424
      BatchNorm2d-13          [-1, 512, 10, 10]           1,024
             ReLU-14          [-1, 512, 10, 10]               0
      SkipConnect-15          [-1, 512, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]       1,179,904
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
           Conv2d-20          [-1, 256, 14, 14]         590,080
      BatchNorm2d-21          [-1, 256, 14, 14]             512
             ReLU-22          [-1, 256, 14, 14]               0
      SkipConnect-23          [-1, 256, 14, 14]               0
        MaxPool2d-24            [-1, 256, 8, 8]               0
        AvgPool2d-25            [-1, 256, 5, 5]               0
           Conv2d-26             [-1, 64, 7, 7]         147,520
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
      SkipConnect-29             [-1, 64, 7, 7]               0
           Conv2d-30            [-1, 512, 9, 9]         295,424
      BatchNorm2d-31            [-1, 512, 9, 9]           1,024
             ReLU-32            [-1, 512, 9, 9]               0
      SkipConnect-33            [-1, 512, 9, 9]               0
           Conv2d-34          [-1, 256, 11, 11]       1,179,904
      BatchNorm2d-35          [-1, 256, 11, 11]             512
             ReLU-36          [-1, 256, 11, 11]               0
      SkipConnect-37          [-1, 256, 11, 11]               0
           Conv2d-38          [-1, 256, 13, 13]         590,080
      BatchNorm2d-39          [-1, 256, 13, 13]             512
             ReLU-40          [-1, 256, 13, 13]               0
      SkipConnect-41          [-1, 256, 13, 13]               0
        AvgPool2d-42            [-1, 256, 7, 7]               0
        MaxPool2d-43            [-1, 256, 4, 4]               0
================================================================
Total params: 4,292,448
Trainable params: 4,292,448
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.89
Params size (MB): 16.37
Estimated Total Size (MB): 25.28
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.77
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 148.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
           Conv2d-26             [-1, 64, 7, 7]         294,976
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
      SkipConnect-29             [-1, 64, 7, 7]               0
           Conv2d-30            [-1, 512, 9, 9]         295,424
      BatchNorm2d-31            [-1, 512, 9, 9]           1,024
             ReLU-32            [-1, 512, 9, 9]               0
      SkipConnect-33            [-1, 512, 9, 9]               0
           Conv2d-34          [-1, 256, 11, 11]       1,179,904
      BatchNorm2d-35          [-1, 256, 11, 11]             512
             ReLU-36          [-1, 256, 11, 11]               0
      SkipConnect-37          [-1, 256, 11, 11]               0
           Conv2d-38          [-1, 256, 13, 13]         590,080
      BatchNorm2d-39          [-1, 256, 13, 13]             512
             ReLU-40          [-1, 256, 13, 13]               0
      SkipConnect-41          [-1, 256, 13, 13]               0
        AvgPool2d-42            [-1, 256, 7, 7]               0
        MaxPool2d-43            [-1, 256, 4, 4]               0
================================================================
Total params: 3,435,168
Trainable params: 3,435,168
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.24
Params size (MB): 13.10
Estimated Total Size (MB): 22.35
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.57
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 147.99
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-0.8-0.7-64-128-64-128-0.2-0.3': 0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-64-512-256-256-0.2-1.0': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0}
Generation: 10
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        AvgPool2d-32            [-1, 128, 8, 8]               0
           Conv2d-33          [-1, 256, 10, 10]         295,168
      BatchNorm2d-34          [-1, 256, 10, 10]             512
             ReLU-35          [-1, 256, 10, 10]               0
      SkipConnect-36          [-1, 256, 10, 10]               0
           Conv2d-37          [-1, 128, 12, 12]         295,040
      BatchNorm2d-38          [-1, 128, 12, 12]             256
             ReLU-39          [-1, 128, 12, 12]               0
      SkipConnect-40          [-1, 128, 12, 12]               0
           Conv2d-41           [-1, 64, 14, 14]          73,792
      BatchNorm2d-42           [-1, 64, 14, 14]             128
             ReLU-43           [-1, 64, 14, 14]               0
      SkipConnect-44           [-1, 64, 14, 14]               0
           Conv2d-45          [-1, 128, 16, 16]          73,856
      BatchNorm2d-46          [-1, 128, 16, 16]             256
             ReLU-47          [-1, 128, 16, 16]               0
      SkipConnect-48          [-1, 128, 16, 16]               0
           Conv2d-49           [-1, 64, 18, 18]          73,792
      BatchNorm2d-50           [-1, 64, 18, 18]             128
             ReLU-51           [-1, 64, 18, 18]               0
      SkipConnect-52           [-1, 64, 18, 18]               0
================================================================
Total params: 4,080,480
Trainable params: 4,080,480
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 13.87
Params size (MB): 15.57
Estimated Total Size (MB): 29.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.95
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.3
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28            [-1, 128, 6, 6]         589,952
      BatchNorm2d-29            [-1, 128, 6, 6]             256
             ReLU-30            [-1, 128, 6, 6]               0
      SkipConnect-31            [-1, 128, 6, 6]               0
           Conv2d-32             [-1, 64, 8, 8]          73,792
      BatchNorm2d-33             [-1, 64, 8, 8]             128
             ReLU-34             [-1, 64, 8, 8]               0
      SkipConnect-35             [-1, 64, 8, 8]               0
           Conv2d-36           [-1, 64, 10, 10]          36,928
      BatchNorm2d-37           [-1, 64, 10, 10]             128
             ReLU-38           [-1, 64, 10, 10]               0
      SkipConnect-39           [-1, 64, 10, 10]               0
           Conv2d-40          [-1, 512, 12, 12]         295,424
      BatchNorm2d-41          [-1, 512, 12, 12]           1,024
             ReLU-42          [-1, 512, 12, 12]               0
      SkipConnect-43          [-1, 512, 12, 12]               0
           Conv2d-44          [-1, 512, 14, 14]       2,359,808
      BatchNorm2d-45          [-1, 512, 14, 14]           1,024
             ReLU-46          [-1, 512, 14, 14]               0
      SkipConnect-47          [-1, 512, 14, 14]               0
           Conv2d-48          [-1, 128, 16, 16]         589,952
      BatchNorm2d-49          [-1, 128, 16, 16]             256
             ReLU-50          [-1, 128, 16, 16]               0
      SkipConnect-51          [-1, 128, 16, 16]               0
           Conv2d-52          [-1, 128, 18, 18]         147,584
      BatchNorm2d-53          [-1, 128, 18, 18]             256
             ReLU-54          [-1, 128, 18, 18]               0
      SkipConnect-55          [-1, 128, 18, 18]               0
================================================================
Total params: 6,026,400
Trainable params: 6,026,400
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 10.07
Params size (MB): 22.99
Estimated Total Size (MB): 33.07
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.31
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.5
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        AvgPool2d-13          [-1, 512, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]         294,976
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
           Conv2d-32           [-1, 64, 10, 10]         147,520
      BatchNorm2d-33           [-1, 64, 10, 10]             128
             ReLU-34           [-1, 64, 10, 10]               0
      SkipConnect-35           [-1, 64, 10, 10]               0
           Conv2d-36          [-1, 512, 12, 12]         295,424
      BatchNorm2d-37          [-1, 512, 12, 12]           1,024
             ReLU-38          [-1, 512, 12, 12]               0
      SkipConnect-39          [-1, 512, 12, 12]               0
           Conv2d-40          [-1, 256, 14, 14]       1,179,904
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
      SkipConnect-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 16, 16]         590,080
      BatchNorm2d-45          [-1, 256, 16, 16]             512
             ReLU-46          [-1, 256, 16, 16]               0
      SkipConnect-47          [-1, 256, 16, 16]               0
           Conv2d-48          [-1, 128, 18, 18]         295,040
      BatchNorm2d-49          [-1, 128, 18, 18]             256
             ReLU-50          [-1, 128, 18, 18]               0
      SkipConnect-51          [-1, 128, 18, 18]               0
           Conv2d-52           [-1, 64, 20, 20]          73,792
      BatchNorm2d-53           [-1, 64, 20, 20]             128
             ReLU-54           [-1, 64, 20, 20]               0
      SkipConnect-55           [-1, 64, 20, 20]               0
================================================================
Total params: 5,253,216
Trainable params: 5,253,216
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 57.16
Params size (MB): 20.04
Estimated Total Size (MB): 77.21
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 147.94
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.67
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0}
Generation: 11
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
        MaxPool2d-21            [-1, 256, 3, 3]               0
           Conv2d-22             [-1, 64, 5, 5]         147,520
      BatchNorm2d-23             [-1, 64, 5, 5]             128
             ReLU-24             [-1, 64, 5, 5]               0
      SkipConnect-25             [-1, 64, 5, 5]               0
        AvgPool2d-26             [-1, 64, 3, 3]               0
           Conv2d-27             [-1, 64, 5, 5]          36,928
      BatchNorm2d-28             [-1, 64, 5, 5]             128
             ReLU-29             [-1, 64, 5, 5]               0
      SkipConnect-30             [-1, 64, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]          73,856
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
        AvgPool2d-35            [-1, 128, 4, 4]               0
        AvgPool2d-36            [-1, 128, 3, 3]               0
================================================================
Total params: 453,984
Trainable params: 453,984
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.44
Params size (MB): 1.73
Estimated Total Size (MB): 5.19
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.32
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.25
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
           Conv2d-26             [-1, 64, 6, 6]         147,520
      BatchNorm2d-27             [-1, 64, 6, 6]             128
             ReLU-28             [-1, 64, 6, 6]               0
      SkipConnect-29             [-1, 64, 6, 6]               0
           Conv2d-30            [-1, 512, 8, 8]         295,424
      BatchNorm2d-31            [-1, 512, 8, 8]           1,024
             ReLU-32            [-1, 512, 8, 8]               0
      SkipConnect-33            [-1, 512, 8, 8]               0
           Conv2d-34          [-1, 256, 10, 10]       1,179,904
      BatchNorm2d-35          [-1, 256, 10, 10]             512
             ReLU-36          [-1, 256, 10, 10]               0
      SkipConnect-37          [-1, 256, 10, 10]               0
           Conv2d-38          [-1, 256, 12, 12]         590,080
      BatchNorm2d-39          [-1, 256, 12, 12]             512
             ReLU-40          [-1, 256, 12, 12]               0
      SkipConnect-41          [-1, 256, 12, 12]               0
           Conv2d-42          [-1, 128, 14, 14]         295,040
      BatchNorm2d-43          [-1, 128, 14, 14]             256
             ReLU-44          [-1, 128, 14, 14]               0
      SkipConnect-45          [-1, 128, 14, 14]               0
           Conv2d-46           [-1, 64, 16, 16]          73,792
      BatchNorm2d-47           [-1, 64, 16, 16]             128
             ReLU-48           [-1, 64, 16, 16]               0
      SkipConnect-49           [-1, 64, 16, 16]               0
================================================================
Total params: 3,370,080
Trainable params: 3,370,080
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.35
Params size (MB): 12.86
Estimated Total Size (MB): 21.21
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.14
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.6
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 128, 6, 6]          73,856
      BatchNorm2d-14            [-1, 128, 6, 6]             256
             ReLU-15            [-1, 128, 6, 6]               0
      SkipConnect-16            [-1, 128, 6, 6]               0
           Conv2d-17            [-1, 512, 8, 8]         590,336
      BatchNorm2d-18            [-1, 512, 8, 8]           1,024
             ReLU-19            [-1, 512, 8, 8]               0
      SkipConnect-20            [-1, 512, 8, 8]               0
        MaxPool2d-21            [-1, 512, 5, 5]               0
        MaxPool2d-22            [-1, 512, 3, 3]               0
        MaxPool2d-23            [-1, 512, 2, 2]               0
           Conv2d-24            [-1, 256, 4, 4]       1,179,904
      BatchNorm2d-25            [-1, 256, 4, 4]             512
             ReLU-26            [-1, 256, 4, 4]               0
      SkipConnect-27            [-1, 256, 4, 4]               0
           Conv2d-28            [-1, 128, 6, 6]         295,040
      BatchNorm2d-29            [-1, 128, 6, 6]             256
             ReLU-30            [-1, 128, 6, 6]               0
      SkipConnect-31            [-1, 128, 6, 6]               0
           Conv2d-32             [-1, 64, 8, 8]          73,792
      BatchNorm2d-33             [-1, 64, 8, 8]             128
             ReLU-34             [-1, 64, 8, 8]               0
      SkipConnect-35             [-1, 64, 8, 8]               0
           Conv2d-36          [-1, 128, 10, 10]          73,856
      BatchNorm2d-37          [-1, 128, 10, 10]             256
             ReLU-38          [-1, 128, 10, 10]               0
      SkipConnect-39          [-1, 128, 10, 10]               0
           Conv2d-40           [-1, 64, 12, 12]          73,792
      BatchNorm2d-41           [-1, 64, 12, 12]             128
             ReLU-42           [-1, 64, 12, 12]               0
      SkipConnect-43           [-1, 64, 12, 12]               0
================================================================
Total params: 2,373,024
Trainable params: 2,373,024
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.28
Params size (MB): 9.05
Estimated Total Size (MB): 12.34
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 148.0
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.45
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28            [-1, 128, 6, 6]         589,952
      BatchNorm2d-29            [-1, 128, 6, 6]             256
             ReLU-30            [-1, 128, 6, 6]               0
      SkipConnect-31            [-1, 128, 6, 6]               0
           Conv2d-32             [-1, 64, 8, 8]          73,792
      BatchNorm2d-33             [-1, 64, 8, 8]             128
             ReLU-34             [-1, 64, 8, 8]               0
      SkipConnect-35             [-1, 64, 8, 8]               0
           Conv2d-36          [-1, 128, 10, 10]          73,856
      BatchNorm2d-37          [-1, 128, 10, 10]             256
             ReLU-38          [-1, 128, 10, 10]               0
      SkipConnect-39          [-1, 128, 10, 10]               0
           Conv2d-40           [-1, 64, 12, 12]          73,792
      BatchNorm2d-41           [-1, 64, 12, 12]             128
             ReLU-42           [-1, 64, 12, 12]               0
      SkipConnect-43           [-1, 64, 12, 12]               0
================================================================
Total params: 2,742,048
Trainable params: 2,742,048
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.97
Params size (MB): 10.46
Estimated Total Size (MB): 13.44
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.89
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.35
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
        MaxPool2d-21            [-1, 256, 3, 3]               0
           Conv2d-22             [-1, 64, 5, 5]         147,520
      BatchNorm2d-23             [-1, 64, 5, 5]             128
             ReLU-24             [-1, 64, 5, 5]               0
      SkipConnect-25             [-1, 64, 5, 5]               0
        AvgPool2d-26             [-1, 64, 3, 3]               0
        MaxPool2d-27             [-1, 64, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]         295,424
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
           Conv2d-44          [-1, 512, 12, 12]         295,424
      BatchNorm2d-45          [-1, 512, 12, 12]           1,024
             ReLU-46          [-1, 512, 12, 12]               0
      SkipConnect-47          [-1, 512, 12, 12]               0
           Conv2d-48          [-1, 128, 14, 14]         589,952
      BatchNorm2d-49          [-1, 128, 14, 14]             256
             ReLU-50          [-1, 128, 14, 14]               0
      SkipConnect-51          [-1, 128, 14, 14]               0
           Conv2d-52          [-1, 128, 16, 16]         147,584
      BatchNorm2d-53          [-1, 128, 16, 16]             256
             ReLU-54          [-1, 128, 16, 16]               0
      SkipConnect-55          [-1, 128, 16, 16]               0
================================================================
Total params: 4,698,720
Trainable params: 4,698,720
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.45
Params size (MB): 17.92
Estimated Total Size (MB): 26.39
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 148.19
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.57
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]          36,928
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
        MaxPool2d-17           [-1, 64, 21, 21]               0
        AvgPool2d-18           [-1, 64, 11, 11]               0
           Conv2d-19          [-1, 256, 13, 13]         147,712
      BatchNorm2d-20          [-1, 256, 13, 13]             512
             ReLU-21          [-1, 256, 13, 13]               0
      SkipConnect-22          [-1, 256, 13, 13]               0
        MaxPool2d-23            [-1, 256, 7, 7]               0
        MaxPool2d-24            [-1, 256, 4, 4]               0
           Conv2d-25             [-1, 64, 6, 6]         147,520
      BatchNorm2d-26             [-1, 64, 6, 6]             128
             ReLU-27             [-1, 64, 6, 6]               0
      SkipConnect-28             [-1, 64, 6, 6]               0
           Conv2d-29            [-1, 128, 8, 8]          73,856
      BatchNorm2d-30            [-1, 128, 8, 8]             256
             ReLU-31            [-1, 128, 8, 8]               0
      SkipConnect-32            [-1, 128, 8, 8]               0
           Conv2d-33           [-1, 64, 10, 10]          73,792
      BatchNorm2d-34           [-1, 64, 10, 10]             128
             ReLU-35           [-1, 64, 10, 10]               0
      SkipConnect-36           [-1, 64, 10, 10]               0
           Conv2d-37          [-1, 128, 12, 12]          73,856
      BatchNorm2d-38          [-1, 128, 12, 12]             256
             ReLU-39          [-1, 128, 12, 12]               0
      SkipConnect-40          [-1, 128, 12, 12]               0
        AvgPool2d-41            [-1, 128, 7, 7]               0
        AvgPool2d-42            [-1, 128, 4, 4]               0
================================================================
Total params: 602,016
Trainable params: 602,016
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.90
Params size (MB): 2.30
Estimated Total Size (MB): 14.21
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.48
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.3
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39           [-1, 64, 10, 10]         294,976
      BatchNorm2d-40           [-1, 64, 10, 10]             128
             ReLU-41           [-1, 64, 10, 10]               0
      SkipConnect-42           [-1, 64, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          36,928
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 6,275,040
Trainable params: 6,275,040
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.95
Params size (MB): 23.94
Estimated Total Size (MB): 30.90
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 148.11
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 147.4
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        AvgPool2d-13          [-1, 512, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]         294,976
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
        AvgPool2d-32            [-1, 256, 5, 5]               0
           Conv2d-33            [-1, 512, 7, 7]       1,180,160
      BatchNorm2d-34            [-1, 512, 7, 7]           1,024
             ReLU-35            [-1, 512, 7, 7]               0
      SkipConnect-36            [-1, 512, 7, 7]               0
           Conv2d-37             [-1, 64, 9, 9]         294,976
      BatchNorm2d-38             [-1, 64, 9, 9]             128
             ReLU-39             [-1, 64, 9, 9]               0
      SkipConnect-40             [-1, 64, 9, 9]               0
        MaxPool2d-41             [-1, 64, 5, 5]               0
        MaxPool2d-42             [-1, 64, 3, 3]               0
           Conv2d-43             [-1, 64, 5, 5]          36,928
      BatchNorm2d-44             [-1, 64, 5, 5]             128
             ReLU-45             [-1, 64, 5, 5]               0
      SkipConnect-46             [-1, 64, 5, 5]               0
================================================================
Total params: 4,182,240
Trainable params: 4,182,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 50.17
Params size (MB): 15.95
Estimated Total Size (MB): 66.14
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 28.125	Loss: 147.8
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.32
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
           Conv2d-30            [-1, 256, 8, 8]         295,168
      BatchNorm2d-31            [-1, 256, 8, 8]             512
             ReLU-32            [-1, 256, 8, 8]               0
      SkipConnect-33            [-1, 256, 8, 8]               0
           Conv2d-34          [-1, 128, 10, 10]         295,040
      BatchNorm2d-35          [-1, 128, 10, 10]             256
             ReLU-36          [-1, 128, 10, 10]               0
      SkipConnect-37          [-1, 128, 10, 10]               0
           Conv2d-38           [-1, 64, 12, 12]          73,792
      BatchNorm2d-39           [-1, 64, 12, 12]             128
             ReLU-40           [-1, 64, 12, 12]               0
      SkipConnect-41           [-1, 64, 12, 12]               0
           Conv2d-42          [-1, 128, 14, 14]          73,856
      BatchNorm2d-43          [-1, 128, 14, 14]             256
             ReLU-44          [-1, 128, 14, 14]               0
      SkipConnect-45          [-1, 128, 14, 14]               0
           Conv2d-46           [-1, 64, 16, 16]          73,792
      BatchNorm2d-47           [-1, 64, 16, 16]             128
             ReLU-48           [-1, 64, 16, 16]               0
      SkipConnect-49           [-1, 64, 16, 16]               0
================================================================
Total params: 3,803,616
Trainable params: 3,803,616
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.33
Params size (MB): 14.51
Estimated Total Size (MB): 21.85
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.95
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.56
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        AvgPool2d-32            [-1, 128, 8, 8]               0
           Conv2d-33          [-1, 256, 10, 10]         295,168
      BatchNorm2d-34          [-1, 256, 10, 10]             512
             ReLU-35          [-1, 256, 10, 10]               0
      SkipConnect-36          [-1, 256, 10, 10]               0
           Conv2d-37          [-1, 128, 12, 12]         295,040
      BatchNorm2d-38          [-1, 128, 12, 12]             256
             ReLU-39          [-1, 128, 12, 12]               0
      SkipConnect-40          [-1, 128, 12, 12]               0
        MaxPool2d-41            [-1, 128, 7, 7]               0
        MaxPool2d-42            [-1, 128, 4, 4]               0
================================================================
Total params: 3,858,528
Trainable params: 3,858,528
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.92
Params size (MB): 14.72
Estimated Total Size (MB): 26.65
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 28.125	Loss: 149.69
Epoch:  2
Epoch: 2 of 2	Acc: 21.875	Loss: 148.63
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 12
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
           Conv2d-23             [-1, 64, 5, 5]         147,520
      BatchNorm2d-24             [-1, 64, 5, 5]             128
             ReLU-25             [-1, 64, 5, 5]               0
      SkipConnect-26             [-1, 64, 5, 5]               0
           Conv2d-27            [-1, 512, 7, 7]         295,424
      BatchNorm2d-28            [-1, 512, 7, 7]           1,024
             ReLU-29            [-1, 512, 7, 7]               0
      SkipConnect-30            [-1, 512, 7, 7]               0
           Conv2d-31            [-1, 256, 9, 9]       1,179,904
      BatchNorm2d-32            [-1, 256, 9, 9]             512
             ReLU-33            [-1, 256, 9, 9]               0
      SkipConnect-34            [-1, 256, 9, 9]               0
           Conv2d-35          [-1, 256, 11, 11]         590,080
      BatchNorm2d-36          [-1, 256, 11, 11]             512
             ReLU-37          [-1, 256, 11, 11]               0
      SkipConnect-38          [-1, 256, 11, 11]               0
           Conv2d-39          [-1, 128, 13, 13]         295,040
      BatchNorm2d-40          [-1, 128, 13, 13]             256
             ReLU-41          [-1, 128, 13, 13]               0
      SkipConnect-42          [-1, 128, 13, 13]               0
           Conv2d-43           [-1, 64, 15, 15]          73,792
      BatchNorm2d-44           [-1, 64, 15, 15]             128
             ReLU-45           [-1, 64, 15, 15]               0
      SkipConnect-46           [-1, 64, 15, 15]               0
================================================================
Total params: 3,333,024
Trainable params: 3,333,024
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.27
Params size (MB): 12.71
Estimated Total Size (MB): 18.00
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.88
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.36
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
        MaxPool2d-25            [-1, 512, 4, 4]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
        AvgPool2d-39             [-1, 64, 5, 5]               0
        MaxPool2d-40             [-1, 64, 3, 3]               0
================================================================
Total params: 2,262,048
Trainable params: 2,262,048
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.43
Params size (MB): 8.63
Estimated Total Size (MB): 14.07
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.75
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.26
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
        MaxPool2d-17           [-1, 64, 21, 21]               0
        AvgPool2d-18           [-1, 64, 11, 11]               0
           Conv2d-19          [-1, 256, 13, 13]         147,712
      BatchNorm2d-20          [-1, 256, 13, 13]             512
             ReLU-21          [-1, 256, 13, 13]               0
      SkipConnect-22          [-1, 256, 13, 13]               0
           Conv2d-23          [-1, 256, 15, 15]         590,080
      BatchNorm2d-24          [-1, 256, 15, 15]             512
             ReLU-25          [-1, 256, 15, 15]               0
      SkipConnect-26          [-1, 256, 15, 15]               0
        MaxPool2d-27            [-1, 256, 8, 8]               0
        AvgPool2d-28            [-1, 256, 5, 5]               0
        AvgPool2d-29            [-1, 256, 3, 3]               0
           Conv2d-30            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-31            [-1, 512, 5, 5]           1,024
             ReLU-32            [-1, 512, 5, 5]               0
      SkipConnect-33            [-1, 512, 5, 5]               0
           Conv2d-34            [-1, 128, 7, 7]         589,952
      BatchNorm2d-35            [-1, 128, 7, 7]             256
             ReLU-36            [-1, 128, 7, 7]               0
      SkipConnect-37            [-1, 128, 7, 7]               0
           Conv2d-38             [-1, 64, 9, 9]          73,792
      BatchNorm2d-39             [-1, 64, 9, 9]             128
             ReLU-40             [-1, 64, 9, 9]               0
      SkipConnect-41             [-1, 64, 9, 9]               0
           Conv2d-42          [-1, 128, 11, 11]          73,856
      BatchNorm2d-43          [-1, 128, 11, 11]             256
             ReLU-44          [-1, 128, 11, 11]               0
      SkipConnect-45          [-1, 128, 11, 11]               0
           Conv2d-46           [-1, 64, 13, 13]          73,792
      BatchNorm2d-47           [-1, 64, 13, 13]             128
             ReLU-48           [-1, 64, 13, 13]               0
      SkipConnect-49           [-1, 64, 13, 13]               0
================================================================
Total params: 3,333,600
Trainable params: 3,333,600
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 33.87
Params size (MB): 12.72
Estimated Total Size (MB): 46.60
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 21.875	Loss: 148.31
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.54
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
        MaxPool2d-21            [-1, 256, 3, 3]               0
           Conv2d-22             [-1, 64, 5, 5]         147,520
      BatchNorm2d-23             [-1, 64, 5, 5]             128
             ReLU-24             [-1, 64, 5, 5]               0
      SkipConnect-25             [-1, 64, 5, 5]               0
        AvgPool2d-26             [-1, 64, 3, 3]               0
        MaxPool2d-27             [-1, 64, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]         295,424
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
           Conv2d-44          [-1, 512, 12, 12]         295,424
      BatchNorm2d-45          [-1, 512, 12, 12]           1,024
             ReLU-46          [-1, 512, 12, 12]               0
      SkipConnect-47          [-1, 512, 12, 12]               0
           Conv2d-48          [-1, 128, 14, 14]         589,952
      BatchNorm2d-49          [-1, 128, 14, 14]             256
             ReLU-50          [-1, 128, 14, 14]               0
      SkipConnect-51          [-1, 128, 14, 14]               0
           Conv2d-52          [-1, 128, 16, 16]         147,584
      BatchNorm2d-53          [-1, 128, 16, 16]             256
             ReLU-54          [-1, 128, 16, 16]               0
      SkipConnect-55          [-1, 128, 16, 16]               0
================================================================
Total params: 4,698,720
Trainable params: 4,698,720
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.45
Params size (MB): 17.92
Estimated Total Size (MB): 26.39
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 148.16
Epoch:  2
Epoch: 2 of 2	Acc: 23.4375	Loss: 147.56
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
           Conv2d-22             [-1, 64, 7, 7]         147,520
      BatchNorm2d-23             [-1, 64, 7, 7]             128
             ReLU-24             [-1, 64, 7, 7]               0
      SkipConnect-25             [-1, 64, 7, 7]               0
           Conv2d-26            [-1, 128, 9, 9]          73,856
      BatchNorm2d-27            [-1, 128, 9, 9]             256
             ReLU-28            [-1, 128, 9, 9]               0
      SkipConnect-29            [-1, 128, 9, 9]               0
           Conv2d-30           [-1, 64, 11, 11]          73,792
      BatchNorm2d-31           [-1, 64, 11, 11]             128
             ReLU-32           [-1, 64, 11, 11]               0
      SkipConnect-33           [-1, 64, 11, 11]               0
           Conv2d-34          [-1, 128, 13, 13]          73,856
      BatchNorm2d-35          [-1, 128, 13, 13]             256
             ReLU-36          [-1, 128, 13, 13]               0
      SkipConnect-37          [-1, 128, 13, 13]               0
        AvgPool2d-38            [-1, 128, 7, 7]               0
        AvgPool2d-39            [-1, 128, 4, 4]               0
================================================================
Total params: 1,118,496
Trainable params: 1,118,496
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.13
Params size (MB): 4.27
Estimated Total Size (MB): 7.41
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 26.5625	Loss: 147.52
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.28
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 128, 24, 24]         295,040
      BatchNorm2d-23          [-1, 128, 24, 24]             256
             ReLU-24          [-1, 128, 24, 24]               0
      SkipConnect-25          [-1, 128, 24, 24]               0
           Conv2d-26          [-1, 512, 26, 26]         590,336
      BatchNorm2d-27          [-1, 512, 26, 26]           1,024
             ReLU-28          [-1, 512, 26, 26]               0
      SkipConnect-29          [-1, 512, 26, 26]               0
           Conv2d-30          [-1, 512, 28, 28]       2,359,808
      BatchNorm2d-31          [-1, 512, 28, 28]           1,024
             ReLU-32          [-1, 512, 28, 28]               0
      SkipConnect-33          [-1, 512, 28, 28]               0
        MaxPool2d-34          [-1, 512, 15, 15]               0
        MaxPool2d-35            [-1, 512, 8, 8]               0
           Conv2d-36          [-1, 256, 10, 10]       1,179,904
      BatchNorm2d-37          [-1, 256, 10, 10]             512
             ReLU-38          [-1, 256, 10, 10]               0
      SkipConnect-39          [-1, 256, 10, 10]               0
           Conv2d-40          [-1, 128, 12, 12]         295,040
      BatchNorm2d-41          [-1, 128, 12, 12]             256
             ReLU-42          [-1, 128, 12, 12]               0
      SkipConnect-43          [-1, 128, 12, 12]               0
           Conv2d-44           [-1, 64, 14, 14]          73,792
      BatchNorm2d-45           [-1, 64, 14, 14]             128
             ReLU-46           [-1, 64, 14, 14]               0
      SkipConnect-47           [-1, 64, 14, 14]               0
           Conv2d-48          [-1, 128, 16, 16]          73,856
      BatchNorm2d-49          [-1, 128, 16, 16]             256
             ReLU-50          [-1, 128, 16, 16]               0
      SkipConnect-51          [-1, 128, 16, 16]               0
           Conv2d-52           [-1, 64, 18, 18]          73,792
      BatchNorm2d-53           [-1, 64, 18, 18]             128
             ReLU-54           [-1, 64, 18, 18]               0
      SkipConnect-55           [-1, 64, 18, 18]               0
================================================================
Total params: 5,694,816
Trainable params: 5,694,816
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 73.06
Params size (MB): 21.72
Estimated Total Size (MB): 94.80
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 23.4375	Loss: 147.67
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.39
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         AvgPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8             [-1, 64, 8, 8]           9,280
       BatchNorm2d-9             [-1, 64, 8, 8]             128
             ReLU-10             [-1, 64, 8, 8]               0
      SkipConnect-11             [-1, 64, 8, 8]               0
           Conv2d-12          [-1, 512, 10, 10]         295,424
      BatchNorm2d-13          [-1, 512, 10, 10]           1,024
             ReLU-14          [-1, 512, 10, 10]               0
      SkipConnect-15          [-1, 512, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]       1,179,904
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
           Conv2d-20          [-1, 256, 14, 14]         590,080
      BatchNorm2d-21          [-1, 256, 14, 14]             512
             ReLU-22          [-1, 256, 14, 14]               0
      SkipConnect-23          [-1, 256, 14, 14]               0
        MaxPool2d-24            [-1, 256, 8, 8]               0
        AvgPool2d-25            [-1, 256, 5, 5]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
           Conv2d-37             [-1, 64, 5, 5]          36,928
      BatchNorm2d-38             [-1, 64, 5, 5]             128
             ReLU-39             [-1, 64, 5, 5]               0
      SkipConnect-40             [-1, 64, 5, 5]               0
================================================================
Total params: 3,590,688
Trainable params: 3,590,688
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.70
Params size (MB): 13.70
Estimated Total Size (MB): 19.41
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 25.0	Loss: 147.76
Epoch:  2
Epoch: 2 of 2	Acc: 26.5625	Loss: 147.29
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         295,168
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]         589,952
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 6,016,800
Trainable params: 6,016,800
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.76
Params size (MB): 22.95
Estimated Total Size (MB): 29.72
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 28.125	Loss: 147.9
Epoch:  2
Epoch: 2 of 2	Acc: 25.0	Loss: 147.33
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
           Conv2d-26             [-1, 64, 6, 6]         147,520
      BatchNorm2d-27             [-1, 64, 6, 6]             128
             ReLU-28             [-1, 64, 6, 6]               0
      SkipConnect-29             [-1, 64, 6, 6]               0
           Conv2d-30            [-1, 512, 8, 8]         295,424
      BatchNorm2d-31            [-1, 512, 8, 8]           1,024
             ReLU-32            [-1, 512, 8, 8]               0
      SkipConnect-33            [-1, 512, 8, 8]               0
           Conv2d-34          [-1, 256, 10, 10]       1,179,904
      BatchNorm2d-35          [-1, 256, 10, 10]             512
             ReLU-36          [-1, 256, 10, 10]               0
      SkipConnect-37          [-1, 256, 10, 10]               0
           Conv2d-38          [-1, 256, 12, 12]         590,080
      BatchNorm2d-39          [-1, 256, 12, 12]             512
             ReLU-40          [-1, 256, 12, 12]               0
      SkipConnect-41          [-1, 256, 12, 12]               0
           Conv2d-42          [-1, 128, 14, 14]         295,040
      BatchNorm2d-43          [-1, 128, 14, 14]             256
             ReLU-44          [-1, 128, 14, 14]               0
      SkipConnect-45          [-1, 128, 14, 14]               0
           Conv2d-46           [-1, 64, 16, 16]          73,792
      BatchNorm2d-47           [-1, 64, 16, 16]             128
             ReLU-48           [-1, 64, 16, 16]               0
      SkipConnect-49           [-1, 64, 16, 16]               0
================================================================
Total params: 3,370,080
Trainable params: 3,370,080
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.35
Params size (MB): 12.86
Estimated Total Size (MB): 21.21
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 2	Acc: 28.125	Loss: 148.21
Epoch:  2
Epoch: 2 of 2	Acc: 28.125	Loss: 147.63
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-0.2-1.0': 0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 13
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 256, 24, 24]         590,080
      BatchNorm2d-23          [-1, 256, 24, 24]             512
             ReLU-24          [-1, 256, 24, 24]               0
      SkipConnect-25          [-1, 256, 24, 24]               0
        MaxPool2d-26          [-1, 256, 13, 13]               0
           Conv2d-27          [-1, 512, 15, 15]       1,180,160
      BatchNorm2d-28          [-1, 512, 15, 15]           1,024
             ReLU-29          [-1, 512, 15, 15]               0
      SkipConnect-30          [-1, 512, 15, 15]               0
           Conv2d-31          [-1, 128, 17, 17]         589,952
      BatchNorm2d-32          [-1, 128, 17, 17]             256
             ReLU-33          [-1, 128, 17, 17]               0
      SkipConnect-34          [-1, 128, 17, 17]               0
        MaxPool2d-35            [-1, 128, 9, 9]               0
           Conv2d-36          [-1, 256, 11, 11]         295,168
      BatchNorm2d-37          [-1, 256, 11, 11]             512
             ReLU-38          [-1, 256, 11, 11]               0
      SkipConnect-39          [-1, 256, 11, 11]               0
           Conv2d-40          [-1, 128, 13, 13]         295,040
      BatchNorm2d-41          [-1, 128, 13, 13]             256
             ReLU-42          [-1, 128, 13, 13]               0
      SkipConnect-43          [-1, 128, 13, 13]               0
           Conv2d-44           [-1, 64, 15, 15]          73,792
      BatchNorm2d-45           [-1, 64, 15, 15]             128
             ReLU-46           [-1, 64, 15, 15]               0
      SkipConnect-47           [-1, 64, 15, 15]               0
           Conv2d-48          [-1, 128, 17, 17]          73,856
      BatchNorm2d-49          [-1, 128, 17, 17]             256
             ReLU-50          [-1, 128, 17, 17]               0
      SkipConnect-51          [-1, 128, 17, 17]               0
           Conv2d-52           [-1, 64, 19, 19]          73,792
      BatchNorm2d-53           [-1, 64, 19, 19]             128
             ReLU-54           [-1, 64, 19, 19]               0
      SkipConnect-55           [-1, 64, 19, 19]               0
================================================================
Total params: 3,924,576
Trainable params: 3,924,576
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 56.94
Params size (MB): 14.97
Estimated Total Size (MB): 71.93
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 21.875	Loss: 148.32
Epoch:  2
Epoch: 2 of 10	Acc: 29.6875	Loss: 147.73
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.46
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.32
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.19
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-36            [-1, 512, 7, 7]           1,024
             ReLU-37            [-1, 512, 7, 7]               0
      SkipConnect-38            [-1, 512, 7, 7]               0
           Conv2d-39             [-1, 64, 9, 9]         294,976
      BatchNorm2d-40             [-1, 64, 9, 9]             128
             ReLU-41             [-1, 64, 9, 9]               0
      SkipConnect-42             [-1, 64, 9, 9]               0
           Conv2d-43          [-1, 512, 11, 11]         295,424
      BatchNorm2d-44          [-1, 512, 11, 11]           1,024
             ReLU-45          [-1, 512, 11, 11]               0
      SkipConnect-46          [-1, 512, 11, 11]               0
           Conv2d-47          [-1, 512, 13, 13]       2,359,808
      BatchNorm2d-48          [-1, 512, 13, 13]           1,024
             ReLU-49          [-1, 512, 13, 13]               0
      SkipConnect-50          [-1, 512, 13, 13]               0
           Conv2d-51          [-1, 128, 15, 15]         589,952
      BatchNorm2d-52          [-1, 128, 15, 15]             256
             ReLU-53          [-1, 128, 15, 15]               0
      SkipConnect-54          [-1, 128, 15, 15]               0
           Conv2d-55          [-1, 128, 17, 17]         147,584
      BatchNorm2d-56          [-1, 128, 17, 17]             256
             ReLU-57          [-1, 128, 17, 17]               0
      SkipConnect-58          [-1, 128, 17, 17]               0
================================================================
Total params: 7,945,248
Trainable params: 7,945,248
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 12.91
Params size (MB): 30.31
Estimated Total Size (MB): 43.23
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.38
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.93
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.61
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.48
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.41
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.4
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.32
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.26
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.26
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.22
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
        MaxPool2d-25            [-1, 512, 4, 4]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
================================================================
Total params: 6,098,208
Trainable params: 6,098,208
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.14
Params size (MB): 23.26
Estimated Total Size (MB): 29.42
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 147.76
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.36
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  4
Epoch: 4 of 10	Acc: 28.125	Loss: 147.22
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.19
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 50.0	Loss: 147.27
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]         147,520
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
        MaxPool2d-27             [-1, 64, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         295,424
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
           Conv2d-32            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-33            [-1, 512, 7, 7]           1,024
             ReLU-34            [-1, 512, 7, 7]               0
      SkipConnect-35            [-1, 512, 7, 7]               0
           Conv2d-36            [-1, 128, 9, 9]         589,952
      BatchNorm2d-37            [-1, 128, 9, 9]             256
             ReLU-38            [-1, 128, 9, 9]               0
      SkipConnect-39            [-1, 128, 9, 9]               0
           Conv2d-40           [-1, 64, 11, 11]          73,792
      BatchNorm2d-41           [-1, 64, 11, 11]             128
             ReLU-42           [-1, 64, 11, 11]               0
      SkipConnect-43           [-1, 64, 11, 11]               0
           Conv2d-44          [-1, 512, 13, 13]         295,424
      BatchNorm2d-45          [-1, 512, 13, 13]           1,024
             ReLU-46          [-1, 512, 13, 13]               0
      SkipConnect-47          [-1, 512, 13, 13]               0
           Conv2d-48          [-1, 128, 15, 15]         589,952
      BatchNorm2d-49          [-1, 128, 15, 15]             256
             ReLU-50          [-1, 128, 15, 15]               0
      SkipConnect-51          [-1, 128, 15, 15]               0
           Conv2d-52          [-1, 128, 17, 17]         147,584
      BatchNorm2d-53          [-1, 128, 17, 17]             256
             ReLU-54          [-1, 128, 17, 17]               0
      SkipConnect-55          [-1, 128, 17, 17]               0
================================================================
Total params: 5,722,848
Trainable params: 5,722,848
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.59
Params size (MB): 21.83
Estimated Total Size (MB): 31.44
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.97
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.52
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.39
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.4
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.33
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.29
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.25
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.3
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.26
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-128-64': 12.5,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 14
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
           Conv2d-22             [-1, 64, 7, 7]         147,520
      BatchNorm2d-23             [-1, 64, 7, 7]             128
             ReLU-24             [-1, 64, 7, 7]               0
      SkipConnect-25             [-1, 64, 7, 7]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
        MaxPool2d-27             [-1, 64, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         295,424
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
           Conv2d-32            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-33            [-1, 512, 7, 7]           1,024
             ReLU-34            [-1, 512, 7, 7]               0
      SkipConnect-35            [-1, 512, 7, 7]               0
           Conv2d-36             [-1, 64, 9, 9]         294,976
      BatchNorm2d-37             [-1, 64, 9, 9]             128
             ReLU-38             [-1, 64, 9, 9]               0
      SkipConnect-39             [-1, 64, 9, 9]               0
           Conv2d-40          [-1, 512, 11, 11]         295,424
      BatchNorm2d-41          [-1, 512, 11, 11]           1,024
             ReLU-42          [-1, 512, 11, 11]               0
      SkipConnect-43          [-1, 512, 11, 11]               0
           Conv2d-44          [-1, 512, 13, 13]       2,359,808
      BatchNorm2d-45          [-1, 512, 13, 13]           1,024
             ReLU-46          [-1, 512, 13, 13]               0
      SkipConnect-47          [-1, 512, 13, 13]               0
           Conv2d-48          [-1, 128, 15, 15]         589,952
      BatchNorm2d-49          [-1, 128, 15, 15]             256
             ReLU-50          [-1, 128, 15, 15]               0
      SkipConnect-51          [-1, 128, 15, 15]               0
           Conv2d-52          [-1, 128, 17, 17]         147,584
      BatchNorm2d-53          [-1, 128, 17, 17]             256
             ReLU-54          [-1, 128, 17, 17]               0
      SkipConnect-55          [-1, 128, 17, 17]               0
================================================================
Total params: 7,244,064
Trainable params: 7,244,064
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.72
Params size (MB): 27.63
Estimated Total Size (MB): 37.37
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.15
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.77
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.53
Epoch:  4
Epoch: 4 of 10	Acc: 31.25	Loss: 147.45
Epoch:  5
Epoch: 5 of 10	Acc: 37.5	Loss: 147.36
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.3
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.32
Epoch:  8
Epoch: 8 of 10	Acc: 28.125	Loss: 147.27
Epoch:  9
Epoch: 9 of 10	Acc: 28.125	Loss: 147.27
Epoch:  10
Epoch: 10 of 10	Acc: 29.6875	Loss: 147.29
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
           Conv2d-30            [-1, 512, 8, 8]         590,336
      BatchNorm2d-31            [-1, 512, 8, 8]           1,024
             ReLU-32            [-1, 512, 8, 8]               0
      SkipConnect-33            [-1, 512, 8, 8]               0
           Conv2d-34           [-1, 64, 10, 10]         294,976
      BatchNorm2d-35           [-1, 64, 10, 10]             128
             ReLU-36           [-1, 64, 10, 10]               0
      SkipConnect-37           [-1, 64, 10, 10]               0
        MaxPool2d-38             [-1, 64, 6, 6]               0
        MaxPool2d-39             [-1, 64, 4, 4]               0
================================================================
Total params: 3,877,152
Trainable params: 3,877,152
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.12
Params size (MB): 14.79
Estimated Total Size (MB): 20.92
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.73
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.58
Epoch:  3
Epoch: 3 of 10	Acc: 29.6875	Loss: 147.41
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.32
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.38
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.29
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.25
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35             [-1, 64, 7, 7]         294,976
      BatchNorm2d-36             [-1, 64, 7, 7]             128
             ReLU-37             [-1, 64, 7, 7]               0
      SkipConnect-38             [-1, 64, 7, 7]               0
           Conv2d-39            [-1, 128, 9, 9]          73,856
      BatchNorm2d-40            [-1, 128, 9, 9]             256
             ReLU-41            [-1, 128, 9, 9]               0
      SkipConnect-42            [-1, 128, 9, 9]               0
           Conv2d-43           [-1, 64, 11, 11]          73,792
      BatchNorm2d-44           [-1, 64, 11, 11]             128
             ReLU-45           [-1, 64, 11, 11]               0
      SkipConnect-46           [-1, 64, 11, 11]               0
================================================================
Total params: 2,337,120
Trainable params: 2,337,120
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.09
Params size (MB): 8.92
Estimated Total Size (MB): 15.02
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.03
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.45
Epoch:  3
Epoch: 3 of 10	Acc: 37.5	Loss: 147.29
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.24
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.22
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.2
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 29.6875	Loss: 147.19
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
        AvgPool2d-13           [-1, 64, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]          36,928
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
           Conv2d-32           [-1, 64, 10, 10]         147,520
      BatchNorm2d-33           [-1, 64, 10, 10]             128
             ReLU-34           [-1, 64, 10, 10]               0
      SkipConnect-35           [-1, 64, 10, 10]               0
           Conv2d-36          [-1, 512, 12, 12]         295,424
      BatchNorm2d-37          [-1, 512, 12, 12]           1,024
             ReLU-38          [-1, 512, 12, 12]               0
      SkipConnect-39          [-1, 512, 12, 12]               0
           Conv2d-40          [-1, 256, 14, 14]       1,179,904
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
      SkipConnect-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 16, 16]         590,080
      BatchNorm2d-45          [-1, 256, 16, 16]             512
             ReLU-46          [-1, 256, 16, 16]               0
      SkipConnect-47          [-1, 256, 16, 16]               0
        AvgPool2d-48            [-1, 256, 9, 9]               0
================================================================
Total params: 4,366,560
Trainable params: 4,366,560
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 34.16
Params size (MB): 16.66
Estimated Total Size (MB): 50.83
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.96
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.67
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.44
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.34
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.34
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.36
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.27
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.26
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.26
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28             [-1, 64, 6, 6]         294,976
      BatchNorm2d-29             [-1, 64, 6, 6]             128
             ReLU-30             [-1, 64, 6, 6]               0
      SkipConnect-31             [-1, 64, 6, 6]               0
        MaxPool2d-32             [-1, 64, 4, 4]               0
        MaxPool2d-33             [-1, 64, 3, 3]               0
================================================================
Total params: 2,224,992
Trainable params: 2,224,992
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.12
Params size (MB): 8.49
Estimated Total Size (MB): 10.62
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 37.5	Loss: 148.55
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.66
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.54
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.46
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.37
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.33
Epoch:  7
Epoch: 7 of 10	Acc: 37.5	Loss: 147.28
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.27
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.24
Epoch:  10
Epoch: 10 of 10	Acc: 26.5625	Loss: 147.27
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 256, 24, 24]         590,080
      BatchNorm2d-23          [-1, 256, 24, 24]             512
             ReLU-24          [-1, 256, 24, 24]               0
      SkipConnect-25          [-1, 256, 24, 24]               0
        MaxPool2d-26          [-1, 256, 13, 13]               0
           Conv2d-27          [-1, 512, 15, 15]       1,180,160
      BatchNorm2d-28          [-1, 512, 15, 15]           1,024
             ReLU-29          [-1, 512, 15, 15]               0
      SkipConnect-30          [-1, 512, 15, 15]               0
           Conv2d-31          [-1, 128, 17, 17]         589,952
      BatchNorm2d-32          [-1, 128, 17, 17]             256
             ReLU-33          [-1, 128, 17, 17]               0
      SkipConnect-34          [-1, 128, 17, 17]               0
        MaxPool2d-35            [-1, 128, 9, 9]               0
           Conv2d-36          [-1, 256, 11, 11]         295,168
      BatchNorm2d-37          [-1, 256, 11, 11]             512
             ReLU-38          [-1, 256, 11, 11]               0
      SkipConnect-39          [-1, 256, 11, 11]               0
           Conv2d-40          [-1, 128, 13, 13]         295,040
      BatchNorm2d-41          [-1, 128, 13, 13]             256
             ReLU-42          [-1, 128, 13, 13]               0
      SkipConnect-43          [-1, 128, 13, 13]               0
           Conv2d-44           [-1, 64, 15, 15]          73,792
      BatchNorm2d-45           [-1, 64, 15, 15]             128
             ReLU-46           [-1, 64, 15, 15]               0
      SkipConnect-47           [-1, 64, 15, 15]               0
           Conv2d-48           [-1, 64, 17, 17]          36,928
      BatchNorm2d-49           [-1, 64, 17, 17]             128
             ReLU-50           [-1, 64, 17, 17]               0
      SkipConnect-51           [-1, 64, 17, 17]               0
           Conv2d-52          [-1, 512, 19, 19]         295,424
      BatchNorm2d-53          [-1, 512, 19, 19]           1,024
             ReLU-54          [-1, 512, 19, 19]               0
      SkipConnect-55          [-1, 512, 19, 19]               0
           Conv2d-56          [-1, 512, 21, 21]       2,359,808
      BatchNorm2d-57          [-1, 512, 21, 21]           1,024
             ReLU-58          [-1, 512, 21, 21]               0
      SkipConnect-59          [-1, 512, 21, 21]               0
           Conv2d-60          [-1, 128, 23, 23]         589,952
      BatchNorm2d-61          [-1, 128, 23, 23]             256
             ReLU-62          [-1, 128, 23, 23]               0
      SkipConnect-63          [-1, 128, 23, 23]               0
           Conv2d-64          [-1, 128, 25, 25]         147,584
      BatchNorm2d-65          [-1, 128, 25, 25]             256
             ReLU-66          [-1, 128, 25, 25]               0
      SkipConnect-67          [-1, 128, 25, 25]               0
================================================================
Total params: 7,208,928
Trainable params: 7,208,928
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 72.71
Params size (MB): 27.50
Estimated Total Size (MB): 100.22
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.33
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.67
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.62
Epoch:  4
Epoch: 4 of 10	Acc: 29.6875	Loss: 147.44
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.37
Epoch:  6
Epoch: 6 of 10	Acc: 28.125	Loss: 147.36
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.31
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.25
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.21
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 15
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35             [-1, 64, 7, 7]         294,976
      BatchNorm2d-36             [-1, 64, 7, 7]             128
             ReLU-37             [-1, 64, 7, 7]               0
      SkipConnect-38             [-1, 64, 7, 7]               0
           Conv2d-39             [-1, 64, 9, 9]          36,928
      BatchNorm2d-40             [-1, 64, 9, 9]             128
             ReLU-41             [-1, 64, 9, 9]               0
      SkipConnect-42             [-1, 64, 9, 9]               0
           Conv2d-43          [-1, 512, 11, 11]         295,424
      BatchNorm2d-44          [-1, 512, 11, 11]           1,024
             ReLU-45          [-1, 512, 11, 11]               0
      SkipConnect-46          [-1, 512, 11, 11]               0
           Conv2d-47          [-1, 512, 13, 13]       2,359,808
      BatchNorm2d-48          [-1, 512, 13, 13]           1,024
             ReLU-49          [-1, 512, 13, 13]               0
      SkipConnect-50          [-1, 512, 13, 13]               0
           Conv2d-51          [-1, 128, 15, 15]         589,952
      BatchNorm2d-52          [-1, 128, 15, 15]             256
             ReLU-53          [-1, 128, 15, 15]               0
      SkipConnect-54          [-1, 128, 15, 15]               0
           Conv2d-55          [-1, 128, 17, 17]         147,584
      BatchNorm2d-56          [-1, 128, 17, 17]             256
             ReLU-57          [-1, 128, 17, 17]               0
      SkipConnect-58          [-1, 128, 17, 17]               0
================================================================
Total params: 5,621,472
Trainable params: 5,621,472
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 12.24
Params size (MB): 21.44
Estimated Total Size (MB): 33.70
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.2
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.68
Epoch:  3
Epoch: 3 of 10	Acc: 28.125	Loss: 147.61
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.39
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.35
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.33
Epoch:  7
Epoch: 7 of 10	Acc: 29.6875	Loss: 147.32
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 28.125	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28            [-1, 128, 6, 6]         589,952
      BatchNorm2d-29            [-1, 128, 6, 6]             256
             ReLU-30            [-1, 128, 6, 6]               0
      SkipConnect-31            [-1, 128, 6, 6]               0
           Conv2d-32             [-1, 64, 8, 8]          73,792
      BatchNorm2d-33             [-1, 64, 8, 8]             128
             ReLU-34             [-1, 64, 8, 8]               0
      SkipConnect-35             [-1, 64, 8, 8]               0
           Conv2d-36           [-1, 64, 10, 10]          36,928
      BatchNorm2d-37           [-1, 64, 10, 10]             128
             ReLU-38           [-1, 64, 10, 10]               0
      SkipConnect-39           [-1, 64, 10, 10]               0
           Conv2d-40          [-1, 512, 12, 12]         295,424
      BatchNorm2d-41          [-1, 512, 12, 12]           1,024
             ReLU-42          [-1, 512, 12, 12]               0
      SkipConnect-43          [-1, 512, 12, 12]               0
================================================================
Total params: 2,927,520
Trainable params: 2,927,520
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.75
Params size (MB): 11.17
Estimated Total Size (MB): 15.92
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.75
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 148.11
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.93
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.74
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.63
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.51
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.47
Epoch:  8
Epoch: 8 of 10	Acc: 62.5	Loss: 147.37
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.36
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.33
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
           Conv2d-12            [-1, 128, 9, 9]          73,856
      BatchNorm2d-13            [-1, 128, 9, 9]             256
             ReLU-14            [-1, 128, 9, 9]               0
      SkipConnect-15            [-1, 128, 9, 9]               0
           Conv2d-16          [-1, 128, 11, 11]         147,584
      BatchNorm2d-17          [-1, 128, 11, 11]             256
             ReLU-18          [-1, 128, 11, 11]               0
      SkipConnect-19          [-1, 128, 11, 11]               0
           Conv2d-20          [-1, 512, 13, 13]         590,336
      BatchNorm2d-21          [-1, 512, 13, 13]           1,024
             ReLU-22          [-1, 512, 13, 13]               0
      SkipConnect-23          [-1, 512, 13, 13]               0
        MaxPool2d-24            [-1, 512, 7, 7]               0
        MaxPool2d-25            [-1, 512, 4, 4]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 128, 6, 6]         589,952
      BatchNorm2d-33            [-1, 128, 6, 6]             256
             ReLU-34            [-1, 128, 6, 6]               0
      SkipConnect-35            [-1, 128, 6, 6]               0
================================================================
Total params: 3,774,240
Trainable params: 3,774,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.05
Params size (MB): 14.40
Estimated Total Size (MB): 19.46
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.48
Epoch:  2
Epoch: 2 of 10	Acc: 29.6875	Loss: 147.61
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.36
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.34
Epoch:  5
Epoch: 5 of 10	Acc: 37.5	Loss: 147.29
Epoch:  6
Epoch: 6 of 10	Acc: 37.5	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 29.6875	Loss: 147.25
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        AvgPool2d-13          [-1, 512, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]         294,976
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
        AvgPool2d-32            [-1, 256, 5, 5]               0
           Conv2d-33            [-1, 512, 7, 7]       1,180,160
      BatchNorm2d-34            [-1, 512, 7, 7]           1,024
             ReLU-35            [-1, 512, 7, 7]               0
      SkipConnect-36            [-1, 512, 7, 7]               0
           Conv2d-37             [-1, 64, 9, 9]         294,976
      BatchNorm2d-38             [-1, 64, 9, 9]             128
             ReLU-39             [-1, 64, 9, 9]               0
      SkipConnect-40             [-1, 64, 9, 9]               0
        MaxPool2d-41             [-1, 64, 5, 5]               0
        MaxPool2d-42             [-1, 64, 3, 3]               0
           Conv2d-43             [-1, 64, 5, 5]          36,928
      BatchNorm2d-44             [-1, 64, 5, 5]             128
             ReLU-45             [-1, 64, 5, 5]               0
      SkipConnect-46             [-1, 64, 5, 5]               0
           Conv2d-47            [-1, 512, 7, 7]         295,424
      BatchNorm2d-48            [-1, 512, 7, 7]           1,024
             ReLU-49            [-1, 512, 7, 7]               0
      SkipConnect-50            [-1, 512, 7, 7]               0
           Conv2d-51            [-1, 128, 9, 9]         589,952
      BatchNorm2d-52            [-1, 128, 9, 9]             256
             ReLU-53            [-1, 128, 9, 9]               0
      SkipConnect-54            [-1, 128, 9, 9]               0
           Conv2d-55          [-1, 128, 11, 11]         147,584
      BatchNorm2d-56          [-1, 128, 11, 11]             256
             ReLU-57          [-1, 128, 11, 11]               0
      SkipConnect-58          [-1, 128, 11, 11]               0
================================================================
Total params: 5,216,736
Trainable params: 5,216,736
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 51.73
Params size (MB): 19.90
Estimated Total Size (MB): 71.64
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.09
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.52
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.37
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.29
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.28
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 29.6875	Loss: 147.27
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.25
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.23
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        AvgPool2d-32            [-1, 128, 8, 8]               0
           Conv2d-33          [-1, 256, 10, 10]         295,168
      BatchNorm2d-34          [-1, 256, 10, 10]             512
             ReLU-35          [-1, 256, 10, 10]               0
      SkipConnect-36          [-1, 256, 10, 10]               0
           Conv2d-37          [-1, 128, 12, 12]         295,040
      BatchNorm2d-38          [-1, 128, 12, 12]             256
             ReLU-39          [-1, 128, 12, 12]               0
      SkipConnect-40          [-1, 128, 12, 12]               0
           Conv2d-41           [-1, 64, 14, 14]          73,792
      BatchNorm2d-42           [-1, 64, 14, 14]             128
             ReLU-43           [-1, 64, 14, 14]               0
      SkipConnect-44           [-1, 64, 14, 14]               0
           Conv2d-45          [-1, 128, 16, 16]          73,856
      BatchNorm2d-46          [-1, 128, 16, 16]             256
             ReLU-47          [-1, 128, 16, 16]               0
      SkipConnect-48          [-1, 128, 16, 16]               0
           Conv2d-49           [-1, 64, 18, 18]          73,792
      BatchNorm2d-50           [-1, 64, 18, 18]             128
             ReLU-51           [-1, 64, 18, 18]               0
      SkipConnect-52           [-1, 64, 18, 18]               0
================================================================
Total params: 4,080,480
Trainable params: 4,080,480
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 13.87
Params size (MB): 15.57
Estimated Total Size (MB): 29.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 37.5	Loss: 147.68
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.44
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.37
Epoch:  4
Epoch: 4 of 10	Acc: 28.125	Loss: 147.32
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.32
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 28.125	Loss: 147.22
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
           Conv2d-23             [-1, 64, 5, 5]         147,520
      BatchNorm2d-24             [-1, 64, 5, 5]             128
             ReLU-25             [-1, 64, 5, 5]               0
      SkipConnect-26             [-1, 64, 5, 5]               0
           Conv2d-27            [-1, 512, 7, 7]         295,424
      BatchNorm2d-28            [-1, 512, 7, 7]           1,024
             ReLU-29            [-1, 512, 7, 7]               0
      SkipConnect-30            [-1, 512, 7, 7]               0
           Conv2d-31            [-1, 256, 9, 9]       1,179,904
      BatchNorm2d-32            [-1, 256, 9, 9]             512
             ReLU-33            [-1, 256, 9, 9]               0
      SkipConnect-34            [-1, 256, 9, 9]               0
           Conv2d-35          [-1, 256, 11, 11]         590,080
      BatchNorm2d-36          [-1, 256, 11, 11]             512
             ReLU-37          [-1, 256, 11, 11]               0
      SkipConnect-38          [-1, 256, 11, 11]               0
        AvgPool2d-39            [-1, 256, 6, 6]               0
================================================================
Total params: 2,963,808
Trainable params: 2,963,808
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.24
Params size (MB): 11.31
Estimated Total Size (MB): 15.56
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.98
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.54
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.37
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.31
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.25
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.22
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.27
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.23
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-0.3': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 16
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28            [-1, 128, 6, 6]         589,952
      BatchNorm2d-29            [-1, 128, 6, 6]             256
             ReLU-30            [-1, 128, 6, 6]               0
      SkipConnect-31            [-1, 128, 6, 6]               0
           Conv2d-32             [-1, 64, 8, 8]          73,792
      BatchNorm2d-33             [-1, 64, 8, 8]             128
             ReLU-34             [-1, 64, 8, 8]               0
      SkipConnect-35             [-1, 64, 8, 8]               0
           Conv2d-36           [-1, 64, 10, 10]          36,928
      BatchNorm2d-37           [-1, 64, 10, 10]             128
             ReLU-38           [-1, 64, 10, 10]               0
      SkipConnect-39           [-1, 64, 10, 10]               0
           Conv2d-40           [-1, 64, 12, 12]          36,928
      BatchNorm2d-41           [-1, 64, 12, 12]             128
             ReLU-42           [-1, 64, 12, 12]               0
      SkipConnect-43           [-1, 64, 12, 12]               0
           Conv2d-44          [-1, 512, 14, 14]         295,424
      BatchNorm2d-45          [-1, 512, 14, 14]           1,024
             ReLU-46          [-1, 512, 14, 14]               0
      SkipConnect-47          [-1, 512, 14, 14]               0
           Conv2d-48          [-1, 128, 16, 16]         589,952
      BatchNorm2d-49          [-1, 128, 16, 16]             256
             ReLU-50          [-1, 128, 16, 16]               0
      SkipConnect-51          [-1, 128, 16, 16]               0
           Conv2d-52          [-1, 128, 18, 18]         147,584
      BatchNorm2d-53          [-1, 128, 18, 18]             256
             ReLU-54          [-1, 128, 18, 18]               0
      SkipConnect-55          [-1, 128, 18, 18]               0
================================================================
Total params: 3,702,624
Trainable params: 3,702,624
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.10
Params size (MB): 14.12
Estimated Total Size (MB): 22.24
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 147.96
Epoch:  2
Epoch: 2 of 10	Acc: 28.125	Loss: 147.71
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.48
Epoch:  4
Epoch: 4 of 10	Acc: 28.125	Loss: 147.39
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.38
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.4
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.29
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.27
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.31
Epoch:  10
Epoch: 10 of 10	Acc: 26.5625	Loss: 147.28
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
        AvgPool2d-13           [-1, 64, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]          36,928
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
        MaxPool2d-26          [-1, 256, 14, 14]               0
           Conv2d-27          [-1, 512, 16, 16]       1,180,160
      BatchNorm2d-28          [-1, 512, 16, 16]           1,024
             ReLU-29          [-1, 512, 16, 16]               0
      SkipConnect-30          [-1, 512, 16, 16]               0
           Conv2d-31          [-1, 128, 18, 18]         589,952
      BatchNorm2d-32          [-1, 128, 18, 18]             256
             ReLU-33          [-1, 128, 18, 18]               0
      SkipConnect-34          [-1, 128, 18, 18]               0
        AvgPool2d-35          [-1, 128, 10, 10]               0
        MaxPool2d-36            [-1, 128, 6, 6]               0
           Conv2d-37            [-1, 512, 8, 8]         590,336
      BatchNorm2d-38            [-1, 512, 8, 8]           1,024
             ReLU-39            [-1, 512, 8, 8]               0
      SkipConnect-40            [-1, 512, 8, 8]               0
           Conv2d-41          [-1, 512, 10, 10]       2,359,808
      BatchNorm2d-42          [-1, 512, 10, 10]           1,024
             ReLU-43          [-1, 512, 10, 10]               0
      SkipConnect-44          [-1, 512, 10, 10]               0
           Conv2d-45           [-1, 64, 12, 12]         294,976
      BatchNorm2d-46           [-1, 64, 12, 12]             128
             ReLU-47           [-1, 64, 12, 12]               0
      SkipConnect-48           [-1, 64, 12, 12]               0
           Conv2d-49          [-1, 512, 14, 14]         295,424
      BatchNorm2d-50          [-1, 512, 14, 14]           1,024
             ReLU-51          [-1, 512, 14, 14]               0
      SkipConnect-52          [-1, 512, 14, 14]               0
           Conv2d-53          [-1, 512, 16, 16]       2,359,808
      BatchNorm2d-54          [-1, 512, 16, 16]           1,024
             ReLU-55          [-1, 512, 16, 16]               0
      SkipConnect-56          [-1, 512, 16, 16]               0
           Conv2d-57          [-1, 128, 18, 18]         589,952
      BatchNorm2d-58          [-1, 128, 18, 18]             256
             ReLU-59          [-1, 128, 18, 18]               0
      SkipConnect-60          [-1, 128, 18, 18]               0
           Conv2d-61          [-1, 128, 20, 20]         147,584
      BatchNorm2d-62          [-1, 128, 20, 20]             256
             ReLU-63          [-1, 128, 20, 20]               0
      SkipConnect-64          [-1, 128, 20, 20]               0
================================================================
Total params: 9,974,880
Trainable params: 9,974,880
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 39.85
Params size (MB): 38.05
Estimated Total Size (MB): 77.92
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.46
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.78
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.53
Epoch:  4
Epoch: 4 of 10	Acc: 31.25	Loss: 147.37
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.29
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.29
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.28
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.24
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]         147,520
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
        MaxPool2d-27             [-1, 64, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         295,424
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
           Conv2d-32            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-33            [-1, 512, 7, 7]           1,024
             ReLU-34            [-1, 512, 7, 7]               0
      SkipConnect-35            [-1, 512, 7, 7]               0
           Conv2d-36            [-1, 128, 9, 9]         589,952
      BatchNorm2d-37            [-1, 128, 9, 9]             256
             ReLU-38            [-1, 128, 9, 9]               0
      SkipConnect-39            [-1, 128, 9, 9]               0
           Conv2d-40           [-1, 64, 11, 11]          73,792
      BatchNorm2d-41           [-1, 64, 11, 11]             128
             ReLU-42           [-1, 64, 11, 11]               0
      SkipConnect-43           [-1, 64, 11, 11]               0
================================================================
Total params: 4,688,352
Trainable params: 4,688,352
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.95
Params size (MB): 17.88
Estimated Total Size (MB): 22.84
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.9
Epoch:  2
Epoch: 2 of 10	Acc: 62.5	Loss: 147.36
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.36
Epoch:  4
Epoch: 4 of 10	Acc: 37.5	Loss: 147.25
Epoch:  5
Epoch: 5 of 10	Acc: 21.875	Loss: 147.24
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 37.5	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.2
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 37.5	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 128, 6, 6]         147,584
      BatchNorm2d-32            [-1, 128, 6, 6]             256
             ReLU-33            [-1, 128, 6, 6]               0
      SkipConnect-34            [-1, 128, 6, 6]               0
        AvgPool2d-35            [-1, 128, 4, 4]               0
        AvgPool2d-36            [-1, 128, 3, 3]               0
================================================================
Total params: 3,138,528
Trainable params: 3,138,528
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.08
Params size (MB): 11.97
Estimated Total Size (MB): 17.06
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.3
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.26
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.26
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.24
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 29.6875	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 29.6875	Loss: 147.2
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]         589,952
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 6,607,008
Trainable params: 6,607,008
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.15
Params size (MB): 25.20
Estimated Total Size (MB): 32.36
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.87
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.34
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.2
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.19
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.19
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.31
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        AvgPool2d-13          [-1, 512, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]         294,976
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
        AvgPool2d-32            [-1, 256, 5, 5]               0
           Conv2d-33            [-1, 512, 7, 7]       1,180,160
      BatchNorm2d-34            [-1, 512, 7, 7]           1,024
             ReLU-35            [-1, 512, 7, 7]               0
      SkipConnect-36            [-1, 512, 7, 7]               0
           Conv2d-37            [-1, 128, 9, 9]         589,952
      BatchNorm2d-38            [-1, 128, 9, 9]             256
             ReLU-39            [-1, 128, 9, 9]               0
      SkipConnect-40            [-1, 128, 9, 9]               0
           Conv2d-41           [-1, 64, 11, 11]          73,792
      BatchNorm2d-42           [-1, 64, 11, 11]             128
             ReLU-43           [-1, 64, 11, 11]               0
      SkipConnect-44           [-1, 64, 11, 11]               0
           Conv2d-45          [-1, 128, 13, 13]          73,856
      BatchNorm2d-46          [-1, 128, 13, 13]             256
             ReLU-47          [-1, 128, 13, 13]               0
      SkipConnect-48          [-1, 128, 13, 13]               0
           Conv2d-49           [-1, 64, 15, 15]          73,792
      BatchNorm2d-50           [-1, 64, 15, 15]             128
             ReLU-51           [-1, 64, 15, 15]               0
      SkipConnect-52           [-1, 64, 15, 15]               0
================================================================
Total params: 4,662,240
Trainable params: 4,662,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 51.60
Params size (MB): 17.79
Estimated Total Size (MB): 69.40
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 147.82
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.45
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.32
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.21
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 26.5625	Loss: 147.25
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
           Conv2d-29           [-1, 64, 10, 10]          73,792
      BatchNorm2d-30           [-1, 64, 10, 10]             128
             ReLU-31           [-1, 64, 10, 10]               0
      SkipConnect-32           [-1, 64, 10, 10]               0
           Conv2d-33          [-1, 512, 12, 12]         295,424
      BatchNorm2d-34          [-1, 512, 12, 12]           1,024
             ReLU-35          [-1, 512, 12, 12]               0
      SkipConnect-36          [-1, 512, 12, 12]               0
           Conv2d-37          [-1, 256, 14, 14]       1,179,904
      BatchNorm2d-38          [-1, 256, 14, 14]             512
             ReLU-39          [-1, 256, 14, 14]               0
      SkipConnect-40          [-1, 256, 14, 14]               0
           Conv2d-41          [-1, 256, 16, 16]         590,080
      BatchNorm2d-42          [-1, 256, 16, 16]             512
             ReLU-43          [-1, 256, 16, 16]               0
      SkipConnect-44          [-1, 256, 16, 16]               0
        AvgPool2d-45            [-1, 256, 9, 9]               0
================================================================
Total params: 3,444,000
Trainable params: 3,444,000
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.16
Params size (MB): 13.14
Estimated Total Size (MB): 24.31
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.0
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.56
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.33
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.3
Epoch:  5
Epoch: 5 of 10	Acc: 21.875	Loss: 147.27
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.26
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.25
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.23
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-64-512-256-256-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 17
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         295,168
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        MaxPool2d-32            [-1, 128, 8, 8]               0
           Conv2d-33          [-1, 256, 10, 10]         295,168
      BatchNorm2d-34          [-1, 256, 10, 10]             512
             ReLU-35          [-1, 256, 10, 10]               0
      SkipConnect-36          [-1, 256, 10, 10]               0
           Conv2d-37          [-1, 128, 12, 12]         295,040
      BatchNorm2d-38          [-1, 128, 12, 12]             256
             ReLU-39          [-1, 128, 12, 12]               0
      SkipConnect-40          [-1, 128, 12, 12]               0
           Conv2d-41           [-1, 64, 14, 14]          73,792
      BatchNorm2d-42           [-1, 64, 14, 14]             128
             ReLU-43           [-1, 64, 14, 14]               0
      SkipConnect-44           [-1, 64, 14, 14]               0
           Conv2d-45           [-1, 64, 16, 16]          36,928
      BatchNorm2d-46           [-1, 64, 16, 16]             128
             ReLU-47           [-1, 64, 16, 16]               0
      SkipConnect-48           [-1, 64, 16, 16]               0
           Conv2d-49          [-1, 512, 18, 18]         295,424
      BatchNorm2d-50          [-1, 512, 18, 18]           1,024
             ReLU-51          [-1, 512, 18, 18]               0
      SkipConnect-52          [-1, 512, 18, 18]               0
           Conv2d-53          [-1, 512, 20, 20]       2,359,808
      BatchNorm2d-54          [-1, 512, 20, 20]           1,024
             ReLU-55          [-1, 512, 20, 20]               0
      SkipConnect-56          [-1, 512, 20, 20]               0
           Conv2d-57          [-1, 128, 22, 22]         589,952
      BatchNorm2d-58          [-1, 128, 22, 22]             256
             ReLU-59          [-1, 128, 22, 22]               0
      SkipConnect-60          [-1, 128, 22, 22]               0
           Conv2d-61          [-1, 128, 24, 24]         147,584
      BatchNorm2d-62          [-1, 128, 24, 24]             256
             ReLU-63          [-1, 128, 24, 24]               0
      SkipConnect-64          [-1, 128, 24, 24]               0
================================================================
Total params: 7,364,832
Trainable params: 7,364,832
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 28.19
Params size (MB): 28.09
Estimated Total Size (MB): 56.30
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.26
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.66
Epoch:  3
Epoch: 3 of 10	Acc: 28.125	Loss: 147.56
Epoch:  4
Epoch: 4 of 10	Acc: 29.6875	Loss: 147.41
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.43
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.32
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.25
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.26
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.24
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
           Conv2d-47          [-1, 512, 15, 15]         295,424
      BatchNorm2d-48          [-1, 512, 15, 15]           1,024
             ReLU-49          [-1, 512, 15, 15]               0
      SkipConnect-50          [-1, 512, 15, 15]               0
           Conv2d-51          [-1, 128, 17, 17]         589,952
      BatchNorm2d-52          [-1, 128, 17, 17]             256
             ReLU-53          [-1, 128, 17, 17]               0
      SkipConnect-54          [-1, 128, 17, 17]               0
           Conv2d-55          [-1, 128, 19, 19]         147,584
      BatchNorm2d-56          [-1, 128, 19, 19]             256
             ReLU-57          [-1, 128, 19, 19]               0
      SkipConnect-58          [-1, 128, 19, 19]               0
================================================================
Total params: 3,804,768
Trainable params: 3,804,768
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 12.92
Params size (MB): 14.51
Estimated Total Size (MB): 27.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.99
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.67
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.54
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.48
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.46
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.34
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.35
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 29.6875	Loss: 147.28
Epoch:  10
Epoch: 10 of 10	Acc: 28.125	Loss: 147.23
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
           Conv2d-30            [-1, 512, 8, 8]         590,336
      BatchNorm2d-31            [-1, 512, 8, 8]           1,024
             ReLU-32            [-1, 512, 8, 8]               0
      SkipConnect-33            [-1, 512, 8, 8]               0
           Conv2d-34           [-1, 64, 10, 10]         294,976
      BatchNorm2d-35           [-1, 64, 10, 10]             128
             ReLU-36           [-1, 64, 10, 10]               0
      SkipConnect-37           [-1, 64, 10, 10]               0
        MaxPool2d-38             [-1, 64, 6, 6]               0
        MaxPool2d-39             [-1, 64, 4, 4]               0
           Conv2d-40             [-1, 64, 6, 6]          36,928
      BatchNorm2d-41             [-1, 64, 6, 6]             128
             ReLU-42             [-1, 64, 6, 6]               0
      SkipConnect-43             [-1, 64, 6, 6]               0
           Conv2d-44            [-1, 512, 8, 8]         295,424
      BatchNorm2d-45            [-1, 512, 8, 8]           1,024
             ReLU-46            [-1, 512, 8, 8]               0
      SkipConnect-47            [-1, 512, 8, 8]               0
           Conv2d-48          [-1, 128, 10, 10]         589,952
      BatchNorm2d-49          [-1, 128, 10, 10]             256
             ReLU-50          [-1, 128, 10, 10]               0
      SkipConnect-51          [-1, 128, 10, 10]               0
           Conv2d-52          [-1, 128, 12, 12]         147,584
      BatchNorm2d-53          [-1, 128, 12, 12]             256
             ReLU-54          [-1, 128, 12, 12]               0
      SkipConnect-55          [-1, 128, 12, 12]               0
================================================================
Total params: 4,948,704
Trainable params: 4,948,704
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.14
Params size (MB): 18.88
Estimated Total Size (MB): 27.03
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.26
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.64
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.46
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.31
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.28
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.26
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.25
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
         AvgPool2d-9           [-1, 64, 19, 19]               0
        MaxPool2d-10           [-1, 64, 10, 10]               0
           Conv2d-11          [-1, 256, 12, 12]         147,712
      BatchNorm2d-12          [-1, 256, 12, 12]             512
             ReLU-13          [-1, 256, 12, 12]               0
      SkipConnect-14          [-1, 256, 12, 12]               0
           Conv2d-15          [-1, 256, 14, 14]         590,080
      BatchNorm2d-16          [-1, 256, 14, 14]             512
             ReLU-17          [-1, 256, 14, 14]               0
      SkipConnect-18          [-1, 256, 14, 14]               0
           Conv2d-19          [-1, 256, 16, 16]         590,080
      BatchNorm2d-20          [-1, 256, 16, 16]             512
             ReLU-21          [-1, 256, 16, 16]               0
      SkipConnect-22          [-1, 256, 16, 16]               0
        MaxPool2d-23            [-1, 256, 9, 9]               0
           Conv2d-24          [-1, 512, 11, 11]       1,180,160
      BatchNorm2d-25          [-1, 512, 11, 11]           1,024
             ReLU-26          [-1, 512, 11, 11]               0
      SkipConnect-27          [-1, 512, 11, 11]               0
           Conv2d-28          [-1, 128, 13, 13]         589,952
      BatchNorm2d-29          [-1, 128, 13, 13]             256
             ReLU-30          [-1, 128, 13, 13]               0
      SkipConnect-31          [-1, 128, 13, 13]               0
        AvgPool2d-32            [-1, 128, 7, 7]               0
        MaxPool2d-33            [-1, 128, 4, 4]               0
           Conv2d-34            [-1, 128, 6, 6]         147,584
      BatchNorm2d-35            [-1, 128, 6, 6]             256
             ReLU-36            [-1, 128, 6, 6]               0
      SkipConnect-37            [-1, 128, 6, 6]               0
        AvgPool2d-38            [-1, 128, 4, 4]               0
        AvgPool2d-39            [-1, 128, 3, 3]               0
================================================================
Total params: 3,258,528
Trainable params: 3,258,528
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 10.91
Params size (MB): 12.43
Estimated Total Size (MB): 23.36
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.29
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.25
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 21.875	Loss: 147.2
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.2
Epoch:  10
Epoch: 10 of 10	Acc: 26.5625	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
        MaxPool2d-17            [-1, 256, 4, 4]               0
        MaxPool2d-18            [-1, 256, 3, 3]               0
           Conv2d-19             [-1, 64, 5, 5]         147,520
      BatchNorm2d-20             [-1, 64, 5, 5]             128
             ReLU-21             [-1, 64, 5, 5]               0
      SkipConnect-22             [-1, 64, 5, 5]               0
        AvgPool2d-23             [-1, 64, 3, 3]               0
           Conv2d-24             [-1, 64, 5, 5]          36,928
      BatchNorm2d-25             [-1, 64, 5, 5]             128
             ReLU-26             [-1, 64, 5, 5]               0
      SkipConnect-27             [-1, 64, 5, 5]               0
           Conv2d-28            [-1, 128, 7, 7]          73,856
      BatchNorm2d-29            [-1, 128, 7, 7]             256
             ReLU-30            [-1, 128, 7, 7]               0
      SkipConnect-31            [-1, 128, 7, 7]               0
        AvgPool2d-32            [-1, 128, 4, 4]               0
        AvgPool2d-33            [-1, 128, 3, 3]               0
================================================================
Total params: 416,928
Trainable params: 416,928
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 1.58
Params size (MB): 1.59
Estimated Total Size (MB): 3.18
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.35
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.28
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.26
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.24
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 28.125	Loss: 147.2
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]         147,520
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
        MaxPool2d-27             [-1, 64, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         295,424
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
           Conv2d-32             [-1, 64, 7, 7]         294,976
      BatchNorm2d-33             [-1, 64, 7, 7]             128
             ReLU-34             [-1, 64, 7, 7]               0
      SkipConnect-35             [-1, 64, 7, 7]               0
           Conv2d-36            [-1, 128, 9, 9]          73,856
      BatchNorm2d-37            [-1, 128, 9, 9]             256
             ReLU-38            [-1, 128, 9, 9]               0
      SkipConnect-39            [-1, 128, 9, 9]               0
           Conv2d-40           [-1, 64, 11, 11]          73,792
      BatchNorm2d-41           [-1, 64, 11, 11]             128
             ReLU-42           [-1, 64, 11, 11]               0
      SkipConnect-43           [-1, 64, 11, 11]               0
================================================================
Total params: 2,106,528
Trainable params: 2,106,528
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.28
Params size (MB): 8.04
Estimated Total Size (MB): 12.32
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.87
Epoch:  2
Epoch: 2 of 10	Acc: 28.125	Loss: 147.35
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.3
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.24
Epoch:  5
Epoch: 5 of 10	Acc: 28.125	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.22
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.28
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.23
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 18
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         295,168
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
================================================================
Total params: 1,893,024
Trainable params: 1,893,024
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.30
Params size (MB): 7.22
Estimated Total Size (MB): 11.54
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.51
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.76
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.56
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.48
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.41
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.33
Epoch:  7
Epoch: 7 of 10	Acc: 29.6875	Loss: 147.31
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.31
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.29
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.24
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
        MaxPool2d-24            [-1, 256, 2, 2]               0
           Conv2d-25            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-26            [-1, 512, 4, 4]           1,024
             ReLU-27            [-1, 512, 4, 4]               0
      SkipConnect-28            [-1, 512, 4, 4]               0
           Conv2d-29             [-1, 64, 6, 6]         294,976
      BatchNorm2d-30             [-1, 64, 6, 6]             128
             ReLU-31             [-1, 64, 6, 6]               0
      SkipConnect-32             [-1, 64, 6, 6]               0
           Conv2d-33            [-1, 128, 8, 8]          73,856
      BatchNorm2d-34            [-1, 128, 8, 8]             256
             ReLU-35            [-1, 128, 8, 8]               0
      SkipConnect-36            [-1, 128, 8, 8]               0
           Conv2d-37           [-1, 64, 10, 10]          73,792
      BatchNorm2d-38           [-1, 64, 10, 10]             128
             ReLU-39           [-1, 64, 10, 10]               0
      SkipConnect-40           [-1, 64, 10, 10]               0
================================================================
Total params: 2,373,024
Trainable params: 2,373,024
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.56
Params size (MB): 9.05
Estimated Total Size (MB): 11.62
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 50.0	Loss: 147.79
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.33
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.21
Epoch:  5
Epoch: 5 of 10	Acc: 37.5	Loss: 147.2
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.23
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  10
Epoch: 10 of 10	Acc: 26.5625	Loss: 147.19
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35             [-1, 64, 8, 8]         294,976
      BatchNorm2d-36             [-1, 64, 8, 8]             128
             ReLU-37             [-1, 64, 8, 8]               0
      SkipConnect-38             [-1, 64, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]          73,856
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 4,025,184
Trainable params: 4,025,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.27
Params size (MB): 15.35
Estimated Total Size (MB): 21.64
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 147.8
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.32
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.28
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.22
Epoch:  5
Epoch: 5 of 10	Acc: 37.5	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.2
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.19
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.19
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        MaxPool2d-29            [-1, 128, 6, 6]               0
           Conv2d-30            [-1, 256, 8, 8]         295,168
      BatchNorm2d-31            [-1, 256, 8, 8]             512
             ReLU-32            [-1, 256, 8, 8]               0
      SkipConnect-33            [-1, 256, 8, 8]               0
           Conv2d-34          [-1, 128, 10, 10]         295,040
      BatchNorm2d-35          [-1, 128, 10, 10]             256
             ReLU-36          [-1, 128, 10, 10]               0
      SkipConnect-37          [-1, 128, 10, 10]               0
           Conv2d-38           [-1, 64, 12, 12]          73,792
      BatchNorm2d-39           [-1, 64, 12, 12]             128
             ReLU-40           [-1, 64, 12, 12]               0
      SkipConnect-41           [-1, 64, 12, 12]               0
           Conv2d-42           [-1, 64, 14, 14]          36,928
      BatchNorm2d-43           [-1, 64, 14, 14]             128
             ReLU-44           [-1, 64, 14, 14]               0
      SkipConnect-45           [-1, 64, 14, 14]               0
           Conv2d-46          [-1, 512, 16, 16]         295,424
      BatchNorm2d-47          [-1, 512, 16, 16]           1,024
             ReLU-48          [-1, 512, 16, 16]               0
      SkipConnect-49          [-1, 512, 16, 16]               0
           Conv2d-50          [-1, 512, 18, 18]       2,359,808
      BatchNorm2d-51          [-1, 512, 18, 18]           1,024
             ReLU-52          [-1, 512, 18, 18]               0
      SkipConnect-53          [-1, 512, 18, 18]               0
           Conv2d-54          [-1, 128, 20, 20]         589,952
      BatchNorm2d-55          [-1, 128, 20, 20]             256
             ReLU-56          [-1, 128, 20, 20]               0
      SkipConnect-57          [-1, 128, 20, 20]               0
           Conv2d-58          [-1, 128, 22, 22]         147,584
      BatchNorm2d-59          [-1, 128, 22, 22]             256
             ReLU-60          [-1, 128, 22, 22]               0
      SkipConnect-61          [-1, 128, 22, 22]               0
================================================================
Total params: 7,087,968
Trainable params: 7,087,968
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 18.97
Params size (MB): 27.04
Estimated Total Size (MB): 46.02
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.39
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.73
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.47
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.45
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.39
Epoch:  6
Epoch: 6 of 10	Acc: 28.125	Loss: 147.31
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.37
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.29
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 128, 6, 6]          73,856
      BatchNorm2d-14            [-1, 128, 6, 6]             256
             ReLU-15            [-1, 128, 6, 6]               0
      SkipConnect-16            [-1, 128, 6, 6]               0
           Conv2d-17            [-1, 512, 8, 8]         590,336
      BatchNorm2d-18            [-1, 512, 8, 8]           1,024
             ReLU-19            [-1, 512, 8, 8]               0
      SkipConnect-20            [-1, 512, 8, 8]               0
        MaxPool2d-21            [-1, 512, 5, 5]               0
           Conv2d-22            [-1, 128, 7, 7]         589,952
      BatchNorm2d-23            [-1, 128, 7, 7]             256
             ReLU-24            [-1, 128, 7, 7]               0
      SkipConnect-25            [-1, 128, 7, 7]               0
        AvgPool2d-26            [-1, 128, 4, 4]               0
        MaxPool2d-27            [-1, 128, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         590,336
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
           Conv2d-32             [-1, 64, 7, 7]         294,976
      BatchNorm2d-33             [-1, 64, 7, 7]             128
             ReLU-34             [-1, 64, 7, 7]               0
      SkipConnect-35             [-1, 64, 7, 7]               0
           Conv2d-36             [-1, 64, 9, 9]          36,928
      BatchNorm2d-37             [-1, 64, 9, 9]             128
             ReLU-38             [-1, 64, 9, 9]               0
      SkipConnect-39             [-1, 64, 9, 9]               0
           Conv2d-40          [-1, 512, 11, 11]         295,424
      BatchNorm2d-41          [-1, 512, 11, 11]           1,024
             ReLU-42          [-1, 512, 11, 11]               0
      SkipConnect-43          [-1, 512, 11, 11]               0
           Conv2d-44          [-1, 512, 13, 13]       2,359,808
      BatchNorm2d-45          [-1, 512, 13, 13]           1,024
             ReLU-46          [-1, 512, 13, 13]               0
      SkipConnect-47          [-1, 512, 13, 13]               0
           Conv2d-48          [-1, 128, 15, 15]         589,952
      BatchNorm2d-49          [-1, 128, 15, 15]             256
             ReLU-50          [-1, 128, 15, 15]               0
      SkipConnect-51          [-1, 128, 15, 15]               0
           Conv2d-52          [-1, 128, 17, 17]         147,584
      BatchNorm2d-53          [-1, 128, 17, 17]             256
             ReLU-54          [-1, 128, 17, 17]               0
      SkipConnect-55          [-1, 128, 17, 17]               0
================================================================
Total params: 5,584,416
Trainable params: 5,584,416
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.57
Params size (MB): 21.30
Estimated Total Size (MB): 30.88
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.31
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.69
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.44
Epoch:  4
Epoch: 4 of 10	Acc: 28.125	Loss: 147.33
Epoch:  5
Epoch: 5 of 10	Acc: 28.125	Loss: 147.27
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.26
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.3
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.3
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.26
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         AvgPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8             [-1, 64, 8, 8]           9,280
       BatchNorm2d-9             [-1, 64, 8, 8]             128
             ReLU-10             [-1, 64, 8, 8]               0
      SkipConnect-11             [-1, 64, 8, 8]               0
           Conv2d-12          [-1, 512, 10, 10]         295,424
      BatchNorm2d-13          [-1, 512, 10, 10]           1,024
             ReLU-14          [-1, 512, 10, 10]               0
      SkipConnect-15          [-1, 512, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]       1,179,904
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
           Conv2d-20          [-1, 256, 14, 14]         590,080
      BatchNorm2d-21          [-1, 256, 14, 14]             512
             ReLU-22          [-1, 256, 14, 14]               0
      SkipConnect-23          [-1, 256, 14, 14]               0
        MaxPool2d-24            [-1, 256, 8, 8]               0
        AvgPool2d-25            [-1, 256, 5, 5]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
           Conv2d-36             [-1, 64, 6, 6]          36,928
      BatchNorm2d-37             [-1, 64, 6, 6]             128
             ReLU-38             [-1, 64, 6, 6]               0
      SkipConnect-39             [-1, 64, 6, 6]               0
           Conv2d-40             [-1, 64, 8, 8]          36,928
      BatchNorm2d-41             [-1, 64, 8, 8]             128
             ReLU-42             [-1, 64, 8, 8]               0
      SkipConnect-43             [-1, 64, 8, 8]               0
           Conv2d-44          [-1, 512, 10, 10]         295,424
      BatchNorm2d-45          [-1, 512, 10, 10]           1,024
             ReLU-46          [-1, 512, 10, 10]               0
      SkipConnect-47          [-1, 512, 10, 10]               0
           Conv2d-48          [-1, 128, 12, 12]         589,952
      BatchNorm2d-49          [-1, 128, 12, 12]             256
             ReLU-50          [-1, 128, 12, 12]               0
      SkipConnect-51          [-1, 128, 12, 12]               0
           Conv2d-52          [-1, 128, 14, 14]         147,584
      BatchNorm2d-53          [-1, 128, 14, 14]             256
             ReLU-54          [-1, 128, 14, 14]               0
      SkipConnect-55          [-1, 128, 14, 14]               0
================================================================
Total params: 4,662,240
Trainable params: 4,662,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.74
Params size (MB): 17.79
Estimated Total Size (MB): 26.53
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.22
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.59
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.37
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.27
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.24
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.35
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.28
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.24
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         295,168
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        MaxPool2d-29            [-1, 128, 6, 6]               0
           Conv2d-30            [-1, 256, 8, 8]         295,168
      BatchNorm2d-31            [-1, 256, 8, 8]             512
             ReLU-32            [-1, 256, 8, 8]               0
      SkipConnect-33            [-1, 256, 8, 8]               0
           Conv2d-34          [-1, 128, 10, 10]         295,040
      BatchNorm2d-35          [-1, 128, 10, 10]             256
             ReLU-36          [-1, 128, 10, 10]               0
      SkipConnect-37          [-1, 128, 10, 10]               0
           Conv2d-38           [-1, 64, 12, 12]          73,792
      BatchNorm2d-39           [-1, 64, 12, 12]             128
             ReLU-40           [-1, 64, 12, 12]               0
      SkipConnect-41           [-1, 64, 12, 12]               0
           Conv2d-42           [-1, 64, 14, 14]          36,928
      BatchNorm2d-43           [-1, 64, 14, 14]             128
             ReLU-44           [-1, 64, 14, 14]               0
      SkipConnect-45           [-1, 64, 14, 14]               0
           Conv2d-46          [-1, 512, 16, 16]         295,424
      BatchNorm2d-47          [-1, 512, 16, 16]           1,024
             ReLU-48          [-1, 512, 16, 16]               0
      SkipConnect-49          [-1, 512, 16, 16]               0
           Conv2d-50          [-1, 512, 18, 18]       2,359,808
      BatchNorm2d-51          [-1, 512, 18, 18]           1,024
             ReLU-52          [-1, 512, 18, 18]               0
      SkipConnect-53          [-1, 512, 18, 18]               0
           Conv2d-54          [-1, 128, 20, 20]         589,952
      BatchNorm2d-55          [-1, 128, 20, 20]             256
             ReLU-56          [-1, 128, 20, 20]               0
      SkipConnect-57          [-1, 128, 20, 20]               0
           Conv2d-58          [-1, 128, 22, 22]         147,584
      BatchNorm2d-59          [-1, 128, 22, 22]             256
             ReLU-60          [-1, 128, 22, 22]               0
      SkipConnect-61          [-1, 128, 22, 22]               0
================================================================
Total params: 6,497,760
Trainable params: 6,497,760
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 18.58
Params size (MB): 24.79
Estimated Total Size (MB): 43.37
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.08
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.73
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.45
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.38
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.33
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.27
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.3
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 37.5	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.21
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 19
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-36            [-1, 512, 7, 7]           1,024
             ReLU-37            [-1, 512, 7, 7]               0
      SkipConnect-38            [-1, 512, 7, 7]               0
           Conv2d-39             [-1, 64, 9, 9]         294,976
      BatchNorm2d-40             [-1, 64, 9, 9]             128
             ReLU-41             [-1, 64, 9, 9]               0
      SkipConnect-42             [-1, 64, 9, 9]               0
           Conv2d-43          [-1, 512, 11, 11]         295,424
      BatchNorm2d-44          [-1, 512, 11, 11]           1,024
             ReLU-45          [-1, 512, 11, 11]               0
      SkipConnect-46          [-1, 512, 11, 11]               0
================================================================
Total params: 4,846,368
Trainable params: 4,846,368
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.26
Params size (MB): 18.49
Estimated Total Size (MB): 26.76
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 21.875	Loss: 148.53
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 148.08
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.71
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.72
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.66
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.49
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.5
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.53
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.39
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.33
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         295,040
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
           Conv2d-25          [-1, 128, 10, 10]         589,952
      BatchNorm2d-26          [-1, 128, 10, 10]             256
             ReLU-27          [-1, 128, 10, 10]               0
      SkipConnect-28          [-1, 128, 10, 10]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39           [-1, 64, 10, 10]         294,976
      BatchNorm2d-40           [-1, 64, 10, 10]             128
             ReLU-41           [-1, 64, 10, 10]               0
      SkipConnect-42           [-1, 64, 10, 10]               0
           Conv2d-43          [-1, 512, 12, 12]         295,424
      BatchNorm2d-44          [-1, 512, 12, 12]           1,024
             ReLU-45          [-1, 512, 12, 12]               0
      SkipConnect-46          [-1, 512, 12, 12]               0
           Conv2d-47          [-1, 512, 14, 14]       2,359,808
      BatchNorm2d-48          [-1, 512, 14, 14]           1,024
             ReLU-49          [-1, 512, 14, 14]               0
      SkipConnect-50          [-1, 512, 14, 14]               0
           Conv2d-51          [-1, 128, 16, 16]         589,952
      BatchNorm2d-52          [-1, 128, 16, 16]             256
             ReLU-53          [-1, 128, 16, 16]               0
      SkipConnect-54          [-1, 128, 16, 16]               0
           Conv2d-55          [-1, 128, 18, 18]         147,584
      BatchNorm2d-56          [-1, 128, 18, 18]             256
             ReLU-57          [-1, 128, 18, 18]               0
      SkipConnect-58          [-1, 128, 18, 18]               0
================================================================
Total params: 8,748,192
Trainable params: 8,748,192
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 15.55
Params size (MB): 33.37
Estimated Total Size (MB): 48.94
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.37
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.71
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.49
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.41
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.34
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.37
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.31
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.29
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  10
Epoch: 10 of 10	Acc: 26.5625	Loss: 147.25
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
        MaxPool2d-17            [-1, 256, 4, 4]               0
           Conv2d-18            [-1, 512, 6, 6]       1,180,160
      BatchNorm2d-19            [-1, 512, 6, 6]           1,024
             ReLU-20            [-1, 512, 6, 6]               0
      SkipConnect-21            [-1, 512, 6, 6]               0
           Conv2d-22            [-1, 128, 8, 8]         589,952
      BatchNorm2d-23            [-1, 128, 8, 8]             256
             ReLU-24            [-1, 128, 8, 8]               0
      SkipConnect-25            [-1, 128, 8, 8]               0
        AvgPool2d-26            [-1, 128, 5, 5]               0
        MaxPool2d-27            [-1, 128, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         590,336
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
           Conv2d-32            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-33            [-1, 512, 7, 7]           1,024
             ReLU-34            [-1, 512, 7, 7]               0
      SkipConnect-35            [-1, 512, 7, 7]               0
           Conv2d-36            [-1, 128, 9, 9]         589,952
      BatchNorm2d-37            [-1, 128, 9, 9]             256
             ReLU-38            [-1, 128, 9, 9]               0
      SkipConnect-39            [-1, 128, 9, 9]               0
           Conv2d-40           [-1, 64, 11, 11]          73,792
      BatchNorm2d-41           [-1, 64, 11, 11]             128
             ReLU-42           [-1, 64, 11, 11]               0
      SkipConnect-43           [-1, 64, 11, 11]               0
================================================================
Total params: 5,545,824
Trainable params: 5,545,824
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.80
Params size (MB): 21.16
Estimated Total Size (MB): 24.96
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.91
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.27
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.22
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.19
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.19
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        MaxPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 256, 5, 5]       1,179,904
      BatchNorm2d-28            [-1, 256, 5, 5]             512
             ReLU-29            [-1, 256, 5, 5]               0
      SkipConnect-30            [-1, 256, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         295,040
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
           Conv2d-47          [-1, 512, 15, 15]         295,424
      BatchNorm2d-48          [-1, 512, 15, 15]           1,024
             ReLU-49          [-1, 512, 15, 15]               0
      SkipConnect-50          [-1, 512, 15, 15]               0
           Conv2d-51          [-1, 128, 17, 17]         589,952
      BatchNorm2d-52          [-1, 128, 17, 17]             256
             ReLU-53          [-1, 128, 17, 17]               0
      SkipConnect-54          [-1, 128, 17, 17]               0
           Conv2d-55          [-1, 128, 19, 19]         147,584
      BatchNorm2d-56          [-1, 128, 19, 19]             256
             ReLU-57          [-1, 128, 19, 19]               0
      SkipConnect-58          [-1, 128, 19, 19]               0
================================================================
Total params: 3,804,768
Trainable params: 3,804,768
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 12.92
Params size (MB): 14.51
Estimated Total Size (MB): 27.45
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.17
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.54
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.52
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.4
Epoch:  5
Epoch: 5 of 10	Acc: 29.6875	Loss: 147.26
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.26
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  9
Epoch: 9 of 10	Acc: 28.125	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 26.5625	Loss: 147.23
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         295,168
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
           Conv2d-20          [-1, 256, 14, 14]         590,080
      BatchNorm2d-21          [-1, 256, 14, 14]             512
             ReLU-22          [-1, 256, 14, 14]               0
      SkipConnect-23          [-1, 256, 14, 14]               0
        MaxPool2d-24            [-1, 256, 8, 8]               0
        AvgPool2d-25            [-1, 256, 5, 5]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         589,952
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 3,213,024
Trainable params: 3,213,024
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.90
Params size (MB): 12.26
Estimated Total Size (MB): 18.17
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.01
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.51
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.36
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.3
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.3
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.2
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28            [-1, 128, 6, 6]         589,952
      BatchNorm2d-29            [-1, 128, 6, 6]             256
             ReLU-30            [-1, 128, 6, 6]               0
      SkipConnect-31            [-1, 128, 6, 6]               0
           Conv2d-32            [-1, 512, 8, 8]         590,336
      BatchNorm2d-33            [-1, 512, 8, 8]           1,024
             ReLU-34            [-1, 512, 8, 8]               0
      SkipConnect-35            [-1, 512, 8, 8]               0
           Conv2d-36          [-1, 128, 10, 10]         589,952
      BatchNorm2d-37          [-1, 128, 10, 10]             256
             ReLU-38          [-1, 128, 10, 10]               0
      SkipConnect-39          [-1, 128, 10, 10]               0
           Conv2d-40           [-1, 64, 12, 12]          73,792
      BatchNorm2d-41           [-1, 64, 12, 12]             128
             ReLU-42           [-1, 64, 12, 12]               0
      SkipConnect-43           [-1, 64, 12, 12]               0
================================================================
Total params: 3,775,584
Trainable params: 3,775,584
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.85
Params size (MB): 14.40
Estimated Total Size (MB): 18.26
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.99
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.45
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.29
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.25
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.26
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.27
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.2
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35             [-1, 64, 8, 8]         294,976
      BatchNorm2d-36             [-1, 64, 8, 8]             128
             ReLU-37             [-1, 64, 8, 8]               0
      SkipConnect-38             [-1, 64, 8, 8]               0
           Conv2d-39           [-1, 64, 10, 10]          36,928
      BatchNorm2d-40           [-1, 64, 10, 10]             128
             ReLU-41           [-1, 64, 10, 10]               0
      SkipConnect-42           [-1, 64, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          36,928
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
           Conv2d-47          [-1, 512, 14, 14]         295,424
      BatchNorm2d-48          [-1, 512, 14, 14]           1,024
             ReLU-49          [-1, 512, 14, 14]               0
      SkipConnect-50          [-1, 512, 14, 14]               0
           Conv2d-51          [-1, 128, 16, 16]         589,952
      BatchNorm2d-52          [-1, 128, 16, 16]             256
             ReLU-53          [-1, 128, 16, 16]               0
      SkipConnect-54          [-1, 128, 16, 16]               0
           Conv2d-55          [-1, 128, 18, 18]         147,584
      BatchNorm2d-56          [-1, 128, 18, 18]             256
             ReLU-57          [-1, 128, 18, 18]               0
      SkipConnect-58          [-1, 128, 18, 18]               0
================================================================
Total params: 4,985,760
Trainable params: 4,985,760
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.40
Params size (MB): 19.02
Estimated Total Size (MB): 30.43
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.29
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.81
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.55
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.4
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.35
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.31
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.27
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.26
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.28
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.26
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         MaxPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7          [-1, 128, 12, 12]          18,560
       BatchNorm2d-8          [-1, 128, 12, 12]             256
              ReLU-9          [-1, 128, 12, 12]               0
      SkipConnect-10          [-1, 128, 12, 12]               0
        MaxPool2d-11            [-1, 128, 7, 7]               0
        AvgPool2d-12            [-1, 128, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         295,168
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28             [-1, 64, 6, 6]         294,976
      BatchNorm2d-29             [-1, 64, 6, 6]             128
             ReLU-30             [-1, 64, 6, 6]               0
      SkipConnect-31             [-1, 64, 6, 6]               0
        MaxPool2d-32             [-1, 64, 4, 4]               0
        MaxPool2d-33             [-1, 64, 3, 3]               0
================================================================
Total params: 2,381,856
Trainable params: 2,381,856
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.43
Params size (MB): 9.09
Estimated Total Size (MB): 11.53
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.7
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.69
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.53
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.45
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.39
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.42
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.34
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.32
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.31
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 20
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
           Conv2d-25          [-1, 128, 10, 10]         589,952
      BatchNorm2d-26          [-1, 128, 10, 10]             256
             ReLU-27          [-1, 128, 10, 10]               0
      SkipConnect-28          [-1, 128, 10, 10]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39           [-1, 64, 10, 10]         294,976
      BatchNorm2d-40           [-1, 64, 10, 10]             128
             ReLU-41           [-1, 64, 10, 10]               0
      SkipConnect-42           [-1, 64, 10, 10]               0
           Conv2d-43          [-1, 512, 12, 12]         295,424
      BatchNorm2d-44          [-1, 512, 12, 12]           1,024
             ReLU-45          [-1, 512, 12, 12]               0
      SkipConnect-46          [-1, 512, 12, 12]               0
================================================================
Total params: 5,206,560
Trainable params: 5,206,560
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.84
Params size (MB): 19.86
Estimated Total Size (MB): 29.71
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.58
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 148.04
Epoch:  3
Epoch: 3 of 10	Acc: 37.5	Loss: 147.9
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.67
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.56
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.5
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.48
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.41
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.45
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.4
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
        MaxPool2d-29            [-1, 128, 5, 5]               0
           Conv2d-30            [-1, 256, 7, 7]         295,168
      BatchNorm2d-31            [-1, 256, 7, 7]             512
             ReLU-32            [-1, 256, 7, 7]               0
      SkipConnect-33            [-1, 256, 7, 7]               0
           Conv2d-34            [-1, 128, 9, 9]         295,040
      BatchNorm2d-35            [-1, 128, 9, 9]             256
             ReLU-36            [-1, 128, 9, 9]               0
      SkipConnect-37            [-1, 128, 9, 9]               0
           Conv2d-38           [-1, 64, 11, 11]          73,792
      BatchNorm2d-39           [-1, 64, 11, 11]             128
             ReLU-40           [-1, 64, 11, 11]               0
      SkipConnect-41           [-1, 64, 11, 11]               0
           Conv2d-42           [-1, 64, 13, 13]          36,928
      BatchNorm2d-43           [-1, 64, 13, 13]             128
             ReLU-44           [-1, 64, 13, 13]               0
      SkipConnect-45           [-1, 64, 13, 13]               0
           Conv2d-46          [-1, 512, 15, 15]         295,424
      BatchNorm2d-47          [-1, 512, 15, 15]           1,024
             ReLU-48          [-1, 512, 15, 15]               0
      SkipConnect-49          [-1, 512, 15, 15]               0
           Conv2d-50          [-1, 512, 17, 17]       2,359,808
      BatchNorm2d-51          [-1, 512, 17, 17]           1,024
             ReLU-52          [-1, 512, 17, 17]               0
      SkipConnect-53          [-1, 512, 17, 17]               0
           Conv2d-54          [-1, 128, 19, 19]         589,952
      BatchNorm2d-55          [-1, 128, 19, 19]             256
             ReLU-56          [-1, 128, 19, 19]               0
      SkipConnect-57          [-1, 128, 19, 19]               0
           Conv2d-58          [-1, 128, 21, 21]         147,584
      BatchNorm2d-59          [-1, 128, 21, 21]             256
             ReLU-60          [-1, 128, 21, 21]               0
      SkipConnect-61          [-1, 128, 21, 21]               0
================================================================
Total params: 5,399,904
Trainable params: 5,399,904
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 17.48
Params size (MB): 20.60
Estimated Total Size (MB): 38.09
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 21.875	Loss: 148.33
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.67
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.46
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.35
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.26
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.25
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
        MaxPool2d-27            [-1, 256, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32             [-1, 64, 6, 6]         294,976
      BatchNorm2d-33             [-1, 64, 6, 6]             128
             ReLU-34             [-1, 64, 6, 6]               0
      SkipConnect-35             [-1, 64, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]          73,856
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
================================================================
Total params: 2,410,080
Trainable params: 2,410,080
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.90
Params size (MB): 9.19
Estimated Total Size (MB): 14.10
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.14
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.43
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.33
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.31
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  7
Epoch: 7 of 10	Acc: 20.3125	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         295,168
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
           Conv2d-20          [-1, 256, 14, 14]         590,080
      BatchNorm2d-21          [-1, 256, 14, 14]             512
             ReLU-22          [-1, 256, 14, 14]               0
      SkipConnect-23          [-1, 256, 14, 14]               0
        MaxPool2d-24            [-1, 256, 8, 8]               0
        AvgPool2d-25            [-1, 256, 5, 5]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         589,952
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
           Conv2d-47          [-1, 512, 15, 15]         295,424
      BatchNorm2d-48          [-1, 512, 15, 15]           1,024
             ReLU-49          [-1, 512, 15, 15]               0
      SkipConnect-50          [-1, 512, 15, 15]               0
           Conv2d-51          [-1, 128, 17, 17]         589,952
      BatchNorm2d-52          [-1, 128, 17, 17]             256
             ReLU-53          [-1, 128, 17, 17]               0
      SkipConnect-54          [-1, 128, 17, 17]               0
           Conv2d-55          [-1, 128, 19, 19]         147,584
      BatchNorm2d-56          [-1, 128, 19, 19]             256
             ReLU-57          [-1, 128, 19, 19]               0
      SkipConnect-58          [-1, 128, 19, 19]               0
================================================================
Total params: 4,247,520
Trainable params: 4,247,520
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.96
Params size (MB): 16.20
Estimated Total Size (MB): 28.17
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.33
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.88
Epoch:  3
Epoch: 3 of 10	Acc: 29.6875	Loss: 147.53
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.46
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.33
Epoch:  6
Epoch: 6 of 10	Acc: 28.125	Loss: 147.31
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 50.0	Loss: 147.25
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.28
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.25
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
        MaxPool2d-20            [-1, 256, 5, 5]               0
        MaxPool2d-21            [-1, 256, 3, 3]               0
        MaxPool2d-22            [-1, 256, 2, 2]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
        MaxPool2d-24            [-1, 256, 2, 2]               0
           Conv2d-25            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-26            [-1, 512, 4, 4]           1,024
             ReLU-27            [-1, 512, 4, 4]               0
      SkipConnect-28            [-1, 512, 4, 4]               0
           Conv2d-29            [-1, 128, 6, 6]         589,952
      BatchNorm2d-30            [-1, 128, 6, 6]             256
             ReLU-31            [-1, 128, 6, 6]               0
      SkipConnect-32            [-1, 128, 6, 6]               0
================================================================
Total params: 1,966,560
Trainable params: 1,966,560
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.54
Params size (MB): 7.50
Estimated Total Size (MB): 11.05
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.4
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.43
Epoch:  3
Epoch: 3 of 10	Acc: 28.125	Loss: 147.31
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.24
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.25
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.2
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 29.6875	Loss: 147.28
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 28.125	Loss: 147.24
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64-512-128-128': 50.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 21
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
           Conv2d-25          [-1, 128, 10, 10]         589,952
      BatchNorm2d-26          [-1, 128, 10, 10]             256
             ReLU-27          [-1, 128, 10, 10]               0
      SkipConnect-28          [-1, 128, 10, 10]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35             [-1, 64, 8, 8]         294,976
      BatchNorm2d-36             [-1, 64, 8, 8]             128
             ReLU-37             [-1, 64, 8, 8]               0
      SkipConnect-38             [-1, 64, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]          73,856
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 2,697,312
Trainable params: 2,697,312
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.19
Params size (MB): 10.29
Estimated Total Size (MB): 17.49
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.05
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.52
Epoch:  3
Epoch: 3 of 10	Acc: 20.3125	Loss: 147.32
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.26
Epoch:  5
Epoch: 5 of 10	Acc: 21.875	Loss: 147.21
Epoch:  6
Epoch: 6 of 10	Acc: 20.3125	Loss: 147.24
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.18
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.19
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
        MaxPool2d-17            [-1, 256, 4, 4]               0
        MaxPool2d-18            [-1, 256, 3, 3]               0
           Conv2d-19             [-1, 64, 5, 5]         147,520
      BatchNorm2d-20             [-1, 64, 5, 5]             128
             ReLU-21             [-1, 64, 5, 5]               0
      SkipConnect-22             [-1, 64, 5, 5]               0
        AvgPool2d-23             [-1, 64, 3, 3]               0
           Conv2d-24             [-1, 64, 5, 5]          36,928
      BatchNorm2d-25             [-1, 64, 5, 5]             128
             ReLU-26             [-1, 64, 5, 5]               0
      SkipConnect-27             [-1, 64, 5, 5]               0
           Conv2d-28            [-1, 128, 7, 7]          73,856
      BatchNorm2d-29            [-1, 128, 7, 7]             256
             ReLU-30            [-1, 128, 7, 7]               0
      SkipConnect-31            [-1, 128, 7, 7]               0
           Conv2d-32             [-1, 64, 9, 9]          73,792
      BatchNorm2d-33             [-1, 64, 9, 9]             128
             ReLU-34             [-1, 64, 9, 9]               0
      SkipConnect-35             [-1, 64, 9, 9]               0
           Conv2d-36          [-1, 128, 11, 11]          73,856
      BatchNorm2d-37          [-1, 128, 11, 11]             256
             ReLU-38          [-1, 128, 11, 11]               0
      SkipConnect-39          [-1, 128, 11, 11]               0
           Conv2d-40           [-1, 64, 13, 13]          73,792
      BatchNorm2d-41           [-1, 64, 13, 13]             128
             ReLU-42           [-1, 64, 13, 13]               0
      SkipConnect-43           [-1, 64, 13, 13]               0
================================================================
Total params: 638,880
Trainable params: 638,880
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.51
Params size (MB): 2.44
Estimated Total Size (MB): 4.96
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.83
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.41
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.25
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.22
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
        AvgPool2d-13          [-1, 512, 20, 20]               0
        MaxPool2d-14          [-1, 512, 11, 11]               0
        AvgPool2d-15            [-1, 512, 6, 6]               0
           Conv2d-16            [-1, 256, 8, 8]       1,179,904
      BatchNorm2d-17            [-1, 256, 8, 8]             512
             ReLU-18            [-1, 256, 8, 8]               0
      SkipConnect-19            [-1, 256, 8, 8]               0
           Conv2d-20          [-1, 256, 10, 10]         590,080
      BatchNorm2d-21          [-1, 256, 10, 10]             512
             ReLU-22          [-1, 256, 10, 10]               0
      SkipConnect-23          [-1, 256, 10, 10]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       1,180,160
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31             [-1, 64, 7, 7]         294,976
      BatchNorm2d-32             [-1, 64, 7, 7]             128
             ReLU-33             [-1, 64, 7, 7]               0
      SkipConnect-34             [-1, 64, 7, 7]               0
        MaxPool2d-35             [-1, 64, 4, 4]               0
        MaxPool2d-36             [-1, 64, 3, 3]               0
================================================================
Total params: 3,553,632
Trainable params: 3,553,632
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.73
Params size (MB): 13.56
Estimated Total Size (MB): 43.30
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.48
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.71
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.54
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.46
Epoch:  5
Epoch: 5 of 10	Acc: 32.8125	Loss: 147.38
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.34
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.31
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.34
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 37.5	Loss: 147.26
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
        AvgPool2d-13           [-1, 64, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]          36,928
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
           Conv2d-32           [-1, 64, 10, 10]         147,520
      BatchNorm2d-33           [-1, 64, 10, 10]             128
             ReLU-34           [-1, 64, 10, 10]               0
      SkipConnect-35           [-1, 64, 10, 10]               0
        MaxPool2d-36             [-1, 64, 6, 6]               0
           Conv2d-37            [-1, 512, 8, 8]         295,424
      BatchNorm2d-38            [-1, 512, 8, 8]           1,024
             ReLU-39            [-1, 512, 8, 8]               0
      SkipConnect-40            [-1, 512, 8, 8]               0
           Conv2d-41          [-1, 512, 10, 10]       2,359,808
      BatchNorm2d-42          [-1, 512, 10, 10]           1,024
             ReLU-43          [-1, 512, 10, 10]               0
      SkipConnect-44          [-1, 512, 10, 10]               0
           Conv2d-45          [-1, 128, 12, 12]         589,952
      BatchNorm2d-46          [-1, 128, 12, 12]             256
             ReLU-47          [-1, 128, 12, 12]               0
      SkipConnect-48          [-1, 128, 12, 12]               0
           Conv2d-49           [-1, 64, 14, 14]          73,792
      BatchNorm2d-50           [-1, 64, 14, 14]             128
             ReLU-51           [-1, 64, 14, 14]               0
      SkipConnect-52           [-1, 64, 14, 14]               0
================================================================
Total params: 5,620,512
Trainable params: 5,620,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 31.75
Params size (MB): 21.44
Estimated Total Size (MB): 53.20
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.94
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.52
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.35
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.3
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.27
Epoch:  6
Epoch: 6 of 10	Acc: 28.125	Loss: 147.26
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.26
Epoch:  8
Epoch: 8 of 10	Acc: 21.875	Loss: 147.29
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.24
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.23
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
           Conv2d-30            [-1, 512, 8, 8]         590,336
      BatchNorm2d-31            [-1, 512, 8, 8]           1,024
             ReLU-32            [-1, 512, 8, 8]               0
      SkipConnect-33            [-1, 512, 8, 8]               0
           Conv2d-34          [-1, 128, 10, 10]         589,952
      BatchNorm2d-35          [-1, 128, 10, 10]             256
             ReLU-36          [-1, 128, 10, 10]               0
      SkipConnect-37          [-1, 128, 10, 10]               0
           Conv2d-38           [-1, 64, 12, 12]          73,792
      BatchNorm2d-39           [-1, 64, 12, 12]             128
             ReLU-40           [-1, 64, 12, 12]               0
      SkipConnect-41           [-1, 64, 12, 12]               0
           Conv2d-42          [-1, 128, 14, 14]          73,856
      BatchNorm2d-43          [-1, 128, 14, 14]             256
             ReLU-44          [-1, 128, 14, 14]               0
      SkipConnect-45          [-1, 128, 14, 14]               0
           Conv2d-46           [-1, 64, 16, 16]          73,792
      BatchNorm2d-47           [-1, 64, 16, 16]             128
             ReLU-48           [-1, 64, 16, 16]               0
      SkipConnect-49           [-1, 64, 16, 16]               0
           Conv2d-50          [-1, 512, 18, 18]         295,424
      BatchNorm2d-51          [-1, 512, 18, 18]           1,024
             ReLU-52          [-1, 512, 18, 18]               0
      SkipConnect-53          [-1, 512, 18, 18]               0
           Conv2d-54          [-1, 128, 20, 20]         589,952
      BatchNorm2d-55          [-1, 128, 20, 20]             256
             ReLU-56          [-1, 128, 20, 20]               0
      SkipConnect-57          [-1, 128, 20, 20]               0
           Conv2d-58          [-1, 128, 22, 22]         147,584
      BatchNorm2d-59          [-1, 128, 22, 22]             256
             ReLU-60          [-1, 128, 22, 22]               0
      SkipConnect-61          [-1, 128, 22, 22]               0
================================================================
Total params: 5,428,704
Trainable params: 5,428,704
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 16.35
Params size (MB): 20.71
Estimated Total Size (MB): 37.07
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.05
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.54
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.45
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.42
Epoch:  5
Epoch: 5 of 10	Acc: 21.875	Loss: 147.44
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.34
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.28
Epoch:  8
Epoch: 8 of 10	Acc: 29.6875	Loss: 147.28
Epoch:  9
Epoch: 9 of 10	Acc: 37.5	Loss: 147.27
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.29
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        MaxPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
        MaxPool2d-24            [-1, 256, 2, 2]               0
           Conv2d-25            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-26            [-1, 512, 4, 4]           1,024
             ReLU-27            [-1, 512, 4, 4]               0
      SkipConnect-28            [-1, 512, 4, 4]               0
           Conv2d-29            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-30            [-1, 512, 6, 6]           1,024
             ReLU-31            [-1, 512, 6, 6]               0
      SkipConnect-32            [-1, 512, 6, 6]               0
           Conv2d-33            [-1, 128, 8, 8]         589,952
      BatchNorm2d-34            [-1, 128, 8, 8]             256
             ReLU-35            [-1, 128, 8, 8]               0
      SkipConnect-36            [-1, 128, 8, 8]               0
           Conv2d-37           [-1, 64, 10, 10]          73,792
      BatchNorm2d-38           [-1, 64, 10, 10]             128
             ReLU-39           [-1, 64, 10, 10]               0
      SkipConnect-40           [-1, 64, 10, 10]               0
================================================================
Total params: 4,954,848
Trainable params: 4,954,848
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.05
Params size (MB): 18.90
Estimated Total Size (MB): 21.96
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.19
Epoch:  2
Epoch: 2 of 10	Acc: 28.125	Loss: 147.55
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.33
Epoch:  4
Epoch: 4 of 10	Acc: 37.5	Loss: 147.27
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.28
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.22
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.2
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         147,712
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        AvgPool2d-32            [-1, 128, 8, 8]               0
        MaxPool2d-33            [-1, 128, 5, 5]               0
           Conv2d-34            [-1, 512, 7, 7]         590,336
      BatchNorm2d-35            [-1, 512, 7, 7]           1,024
             ReLU-36            [-1, 512, 7, 7]               0
      SkipConnect-37            [-1, 512, 7, 7]               0
           Conv2d-38             [-1, 64, 9, 9]         294,976
      BatchNorm2d-39             [-1, 64, 9, 9]             128
             ReLU-40             [-1, 64, 9, 9]               0
      SkipConnect-41             [-1, 64, 9, 9]               0
           Conv2d-42          [-1, 128, 11, 11]          73,856
      BatchNorm2d-43          [-1, 128, 11, 11]             256
             ReLU-44          [-1, 128, 11, 11]               0
      SkipConnect-45          [-1, 128, 11, 11]               0
           Conv2d-46           [-1, 64, 13, 13]          73,792
      BatchNorm2d-47           [-1, 64, 13, 13]             128
             ReLU-48           [-1, 64, 13, 13]               0
      SkipConnect-49           [-1, 64, 13, 13]               0
================================================================
Total params: 4,145,184
Trainable params: 4,145,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.98
Params size (MB): 15.81
Estimated Total Size (MB): 27.81
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.76
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.33
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.31
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 21.875	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.19
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64-512-128-128': 50.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.4-512-128-64-128-64-512-128-128': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-1.0-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-0.6-512-512-128-64': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 22
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
        MaxPool2d-17            [-1, 256, 4, 4]               0
        MaxPool2d-18            [-1, 256, 3, 3]               0
           Conv2d-19             [-1, 64, 5, 5]         147,520
      BatchNorm2d-20             [-1, 64, 5, 5]             128
             ReLU-21             [-1, 64, 5, 5]               0
      SkipConnect-22             [-1, 64, 5, 5]               0
        AvgPool2d-23             [-1, 64, 3, 3]               0
           Conv2d-24             [-1, 64, 5, 5]          36,928
      BatchNorm2d-25             [-1, 64, 5, 5]             128
             ReLU-26             [-1, 64, 5, 5]               0
      SkipConnect-27             [-1, 64, 5, 5]               0
           Conv2d-28            [-1, 128, 7, 7]          73,856
      BatchNorm2d-29            [-1, 128, 7, 7]             256
             ReLU-30            [-1, 128, 7, 7]               0
      SkipConnect-31            [-1, 128, 7, 7]               0
        AvgPool2d-32            [-1, 128, 4, 4]               0
        AvgPool2d-33            [-1, 128, 3, 3]               0
           Conv2d-34            [-1, 128, 5, 5]         147,584
      BatchNorm2d-35            [-1, 128, 5, 5]             256
             ReLU-36            [-1, 128, 5, 5]               0
      SkipConnect-37            [-1, 128, 5, 5]               0
================================================================
Total params: 564,768
Trainable params: 564,768
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 1.67
Params size (MB): 2.15
Estimated Total Size (MB): 3.84
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.39
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.51
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.33
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.24
Epoch:  5
Epoch: 5 of 10	Acc: 20.3125	Loss: 147.21
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 20.3125	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.19
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.23
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         295,168
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]         147,520
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
           Conv2d-27             [-1, 64, 6, 6]          36,928
      BatchNorm2d-28             [-1, 64, 6, 6]             128
             ReLU-29             [-1, 64, 6, 6]               0
      SkipConnect-30             [-1, 64, 6, 6]               0
           Conv2d-31            [-1, 128, 8, 8]          73,856
      BatchNorm2d-32            [-1, 128, 8, 8]             256
             ReLU-33            [-1, 128, 8, 8]               0
      SkipConnect-34            [-1, 128, 8, 8]               0
        AvgPool2d-35            [-1, 128, 5, 5]               0
        AvgPool2d-36            [-1, 128, 3, 3]               0
================================================================
Total params: 887,904
Trainable params: 887,904
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.19
Params size (MB): 3.39
Estimated Total Size (MB): 6.59
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.35
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.28
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.26
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.25
Epoch:  5
Epoch: 5 of 10	Acc: 28.125	Loss: 147.24
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 37.5	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 34.375	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.18
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.22
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
        AvgPool2d-25            [-1, 256, 4, 4]               0
        AvgPool2d-26            [-1, 256, 3, 3]               0
        MaxPool2d-27            [-1, 256, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
================================================================
Total params: 4,991,904
Trainable params: 4,991,904
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.39
Params size (MB): 19.04
Estimated Total Size (MB): 24.44
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 147.8
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.4
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.27
Epoch:  4
Epoch: 4 of 10	Acc: 28.125	Loss: 147.3
Epoch:  5
Epoch: 5 of 10	Acc: 28.125	Loss: 147.24
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.2
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.2
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.2
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.19
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.18
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 512, 8, 8]       1,180,160
      BatchNorm2d-18            [-1, 512, 8, 8]           1,024
             ReLU-19            [-1, 512, 8, 8]               0
      SkipConnect-20            [-1, 512, 8, 8]               0
        MaxPool2d-21            [-1, 512, 5, 5]               0
        MaxPool2d-22            [-1, 512, 3, 3]               0
        MaxPool2d-23            [-1, 512, 2, 2]               0
           Conv2d-24            [-1, 256, 4, 4]       1,179,904
      BatchNorm2d-25            [-1, 256, 4, 4]             512
             ReLU-26            [-1, 256, 4, 4]               0
      SkipConnect-27            [-1, 256, 4, 4]               0
           Conv2d-28             [-1, 64, 6, 6]         147,520
      BatchNorm2d-29             [-1, 64, 6, 6]             128
             ReLU-30             [-1, 64, 6, 6]               0
      SkipConnect-31             [-1, 64, 6, 6]               0
        MaxPool2d-32             [-1, 64, 4, 4]               0
        MaxPool2d-33             [-1, 64, 3, 3]               0
           Conv2d-34             [-1, 64, 5, 5]          36,928
      BatchNorm2d-35             [-1, 64, 5, 5]             128
             ReLU-36             [-1, 64, 5, 5]               0
      SkipConnect-37             [-1, 64, 5, 5]               0
================================================================
Total params: 2,704,416
Trainable params: 2,704,416
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.62
Params size (MB): 10.32
Estimated Total Size (MB): 12.94
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 29.6875	Loss: 148.02
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.34
Epoch:  3
Epoch: 3 of 10	Acc: 37.5	Loss: 147.23
Epoch:  4
Epoch: 4 of 10	Acc: 37.5	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.29
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.22
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  9
Epoch: 9 of 10	Acc: 28.125	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
           Conv2d-11          [-1, 256, 14, 14]         147,712
      BatchNorm2d-12          [-1, 256, 14, 14]             512
             ReLU-13          [-1, 256, 14, 14]               0
      SkipConnect-14          [-1, 256, 14, 14]               0
           Conv2d-15          [-1, 256, 16, 16]         590,080
      BatchNorm2d-16          [-1, 256, 16, 16]             512
             ReLU-17          [-1, 256, 16, 16]               0
      SkipConnect-18          [-1, 256, 16, 16]               0
           Conv2d-19          [-1, 256, 18, 18]         590,080
      BatchNorm2d-20          [-1, 256, 18, 18]             512
             ReLU-21          [-1, 256, 18, 18]               0
      SkipConnect-22          [-1, 256, 18, 18]               0
        MaxPool2d-23          [-1, 256, 10, 10]               0
           Conv2d-24          [-1, 512, 12, 12]       1,180,160
      BatchNorm2d-25          [-1, 512, 12, 12]           1,024
             ReLU-26          [-1, 512, 12, 12]               0
      SkipConnect-27          [-1, 512, 12, 12]               0
           Conv2d-28          [-1, 128, 14, 14]         589,952
      BatchNorm2d-29          [-1, 128, 14, 14]             256
             ReLU-30          [-1, 128, 14, 14]               0
      SkipConnect-31          [-1, 128, 14, 14]               0
        AvgPool2d-32            [-1, 128, 8, 8]               0
        MaxPool2d-33            [-1, 128, 5, 5]               0
           Conv2d-34            [-1, 512, 7, 7]         590,336
      BatchNorm2d-35            [-1, 512, 7, 7]           1,024
             ReLU-36            [-1, 512, 7, 7]               0
      SkipConnect-37            [-1, 512, 7, 7]               0
           Conv2d-38             [-1, 64, 9, 9]         294,976
      BatchNorm2d-39             [-1, 64, 9, 9]             128
             ReLU-40             [-1, 64, 9, 9]               0
      SkipConnect-41             [-1, 64, 9, 9]               0
           Conv2d-42          [-1, 128, 11, 11]          73,856
      BatchNorm2d-43          [-1, 128, 11, 11]             256
             ReLU-44          [-1, 128, 11, 11]               0
      SkipConnect-45          [-1, 128, 11, 11]               0
           Conv2d-46           [-1, 64, 13, 13]          73,792
      BatchNorm2d-47           [-1, 64, 13, 13]             128
             ReLU-48           [-1, 64, 13, 13]               0
      SkipConnect-49           [-1, 64, 13, 13]               0
           Conv2d-50          [-1, 128, 15, 15]          73,856
      BatchNorm2d-51          [-1, 128, 15, 15]             256
             ReLU-52          [-1, 128, 15, 15]               0
      SkipConnect-53          [-1, 128, 15, 15]               0
           Conv2d-54          [-1, 128, 17, 17]         147,584
      BatchNorm2d-55          [-1, 128, 17, 17]             256
             ReLU-56          [-1, 128, 17, 17]               0
      SkipConnect-57          [-1, 128, 17, 17]               0
================================================================
Total params: 4,367,136
Trainable params: 4,367,136
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 13.99
Params size (MB): 16.66
Estimated Total Size (MB): 30.66
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.24
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.59
Epoch:  3
Epoch: 3 of 10	Acc: 21.875	Loss: 147.44
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.37
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.33
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.3
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.35
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.31
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.4
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36             [-1, 64, 8, 8]         294,976
      BatchNorm2d-37             [-1, 64, 8, 8]             128
             ReLU-38             [-1, 64, 8, 8]               0
      SkipConnect-39             [-1, 64, 8, 8]               0
           Conv2d-40          [-1, 512, 10, 10]         295,424
      BatchNorm2d-41          [-1, 512, 10, 10]           1,024
             ReLU-42          [-1, 512, 10, 10]               0
      SkipConnect-43          [-1, 512, 10, 10]               0
================================================================
Total params: 6,385,824
Trainable params: 6,385,824
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.03
Params size (MB): 24.36
Estimated Total Size (MB): 32.41
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.72
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 148.13
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.86
Epoch:  4
Epoch: 4 of 10	Acc: 31.25	Loss: 147.81
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.68
Epoch:  6
Epoch: 6 of 10	Acc: 31.25	Loss: 147.46
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.54
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.47
Epoch:  9
Epoch: 9 of 10	Acc: 37.5	Loss: 147.4
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.42
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28             [-1, 64, 6, 6]         294,976
      BatchNorm2d-29             [-1, 64, 6, 6]             128
             ReLU-30             [-1, 64, 6, 6]               0
      SkipConnect-31             [-1, 64, 6, 6]               0
        MaxPool2d-32             [-1, 64, 4, 4]               0
           Conv2d-33             [-1, 64, 6, 6]          36,928
      BatchNorm2d-34             [-1, 64, 6, 6]             128
             ReLU-35             [-1, 64, 6, 6]               0
      SkipConnect-36             [-1, 64, 6, 6]               0
           Conv2d-37            [-1, 512, 8, 8]         295,424
      BatchNorm2d-38            [-1, 512, 8, 8]           1,024
             ReLU-39            [-1, 512, 8, 8]               0
      SkipConnect-40            [-1, 512, 8, 8]               0
           Conv2d-41          [-1, 512, 10, 10]       2,359,808
      BatchNorm2d-42          [-1, 512, 10, 10]           1,024
             ReLU-43          [-1, 512, 10, 10]               0
      SkipConnect-44          [-1, 512, 10, 10]               0
           Conv2d-45          [-1, 128, 12, 12]         589,952
      BatchNorm2d-46          [-1, 128, 12, 12]             256
             ReLU-47          [-1, 128, 12, 12]               0
      SkipConnect-48          [-1, 128, 12, 12]               0
           Conv2d-49          [-1, 128, 14, 14]         147,584
      BatchNorm2d-50          [-1, 128, 14, 14]             256
             ReLU-51          [-1, 128, 14, 14]               0
      SkipConnect-52          [-1, 128, 14, 14]               0
================================================================
Total params: 5,657,376
Trainable params: 5,657,376
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.07
Params size (MB): 21.58
Estimated Total Size (MB): 27.67
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.25
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.56
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.46
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.34
Epoch:  5
Epoch: 5 of 10	Acc: 37.5	Loss: 147.29
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.27
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.25
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 256, 9, 9]         147,712
      BatchNorm2d-17            [-1, 256, 9, 9]             512
             ReLU-18            [-1, 256, 9, 9]               0
      SkipConnect-19            [-1, 256, 9, 9]               0
           Conv2d-20          [-1, 256, 11, 11]         590,080
      BatchNorm2d-21          [-1, 256, 11, 11]             512
             ReLU-22          [-1, 256, 11, 11]               0
      SkipConnect-23          [-1, 256, 11, 11]               0
        MaxPool2d-24            [-1, 256, 6, 6]               0
           Conv2d-25             [-1, 64, 8, 8]         147,520
      BatchNorm2d-26             [-1, 64, 8, 8]             128
             ReLU-27             [-1, 64, 8, 8]               0
      SkipConnect-28             [-1, 64, 8, 8]               0
           Conv2d-29          [-1, 128, 10, 10]          73,856
      BatchNorm2d-30          [-1, 128, 10, 10]             256
             ReLU-31          [-1, 128, 10, 10]               0
      SkipConnect-32          [-1, 128, 10, 10]               0
           Conv2d-33           [-1, 64, 12, 12]          73,792
      BatchNorm2d-34           [-1, 64, 12, 12]             128
             ReLU-35           [-1, 64, 12, 12]               0
      SkipConnect-36           [-1, 64, 12, 12]               0
           Conv2d-37          [-1, 128, 14, 14]          73,856
      BatchNorm2d-38          [-1, 128, 14, 14]             256
             ReLU-39          [-1, 128, 14, 14]               0
      SkipConnect-40          [-1, 128, 14, 14]               0
        AvgPool2d-41            [-1, 128, 8, 8]               0
        AvgPool2d-42            [-1, 128, 5, 5]               0
================================================================
Total params: 1,155,552
Trainable params: 1,155,552
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.72
Params size (MB): 4.41
Estimated Total Size (MB): 10.14
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.45
Epoch:  2
Epoch: 2 of 10	Acc: 28.125	Loss: 147.29
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.25
Epoch:  4
Epoch: 4 of 10	Acc: 28.125	Loss: 147.25
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.22
Epoch:  6
Epoch: 6 of 10	Acc: 37.5	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 31.25	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.2
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.3-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64-512-128-128': 50.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.4-512-128-64-128-64-512-128-128': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-1.0-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 37.5,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64-128-128': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-0.6-512-512-128-64': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 23
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
           Conv2d-21          [-1, 512, 10, 10]       1,180,160
      BatchNorm2d-22          [-1, 512, 10, 10]           1,024
             ReLU-23          [-1, 512, 10, 10]               0
      SkipConnect-24          [-1, 512, 10, 10]               0
           Conv2d-25          [-1, 128, 12, 12]         589,952
      BatchNorm2d-26          [-1, 128, 12, 12]             256
             ReLU-27          [-1, 128, 12, 12]               0
      SkipConnect-28          [-1, 128, 12, 12]               0
        AvgPool2d-29            [-1, 128, 7, 7]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39           [-1, 64, 10, 10]         294,976
      BatchNorm2d-40           [-1, 64, 10, 10]             128
             ReLU-41           [-1, 64, 10, 10]               0
      SkipConnect-42           [-1, 64, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          36,928
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 5,804,448
Trainable params: 5,804,448
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.94
Params size (MB): 22.14
Estimated Total Size (MB): 28.09
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.08
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.33
Epoch:  3
Epoch: 3 of 10	Acc: 37.5	Loss: 147.28
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.28
Epoch:  5
Epoch: 5 of 10	Acc: 37.5	Loss: 147.26
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.2
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.19
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
        AvgPool2d-25            [-1, 512, 4, 4]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
           Conv2d-27            [-1, 512, 5, 5]       2,359,808
      BatchNorm2d-28            [-1, 512, 5, 5]           1,024
             ReLU-29            [-1, 512, 5, 5]               0
      SkipConnect-30            [-1, 512, 5, 5]               0
           Conv2d-31            [-1, 128, 7, 7]         589,952
      BatchNorm2d-32            [-1, 128, 7, 7]             256
             ReLU-33            [-1, 128, 7, 7]               0
      SkipConnect-34            [-1, 128, 7, 7]               0
           Conv2d-35             [-1, 64, 9, 9]          73,792
      BatchNorm2d-36             [-1, 64, 9, 9]             128
             ReLU-37             [-1, 64, 9, 9]               0
      SkipConnect-38             [-1, 64, 9, 9]               0
           Conv2d-39          [-1, 128, 11, 11]          73,856
      BatchNorm2d-40          [-1, 128, 11, 11]             256
             ReLU-41          [-1, 128, 11, 11]               0
      SkipConnect-42          [-1, 128, 11, 11]               0
           Conv2d-43           [-1, 64, 13, 13]          73,792
      BatchNorm2d-44           [-1, 64, 13, 13]             128
             ReLU-45           [-1, 64, 13, 13]               0
      SkipConnect-46           [-1, 64, 13, 13]               0
================================================================
Total params: 3,885,408
Trainable params: 3,885,408
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.41
Params size (MB): 14.82
Estimated Total Size (MB): 21.25
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 147.97
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.49
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.38
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.25
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.24
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 37.5	Loss: 147.21
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         295,168
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]         147,520
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
        MaxPool2d-27             [-1, 64, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         295,424
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
           Conv2d-32            [-1, 512, 7, 7]       2,359,808
      BatchNorm2d-33            [-1, 512, 7, 7]           1,024
             ReLU-34            [-1, 512, 7, 7]               0
      SkipConnect-35            [-1, 512, 7, 7]               0
           Conv2d-36            [-1, 128, 9, 9]         589,952
      BatchNorm2d-37            [-1, 128, 9, 9]             256
             ReLU-38            [-1, 128, 9, 9]               0
      SkipConnect-39            [-1, 128, 9, 9]               0
           Conv2d-40           [-1, 64, 11, 11]          73,792
      BatchNorm2d-41           [-1, 64, 11, 11]             128
             ReLU-42           [-1, 64, 11, 11]               0
      SkipConnect-43           [-1, 64, 11, 11]               0
================================================================
Total params: 4,098,144
Trainable params: 4,098,144
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.55
Params size (MB): 15.63
Estimated Total Size (MB): 20.20
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.09
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.47
Epoch:  3
Epoch: 3 of 10	Acc: 37.5	Loss: 147.3
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.25
Epoch:  7
Epoch: 7 of 10	Acc: 26.5625	Loss: 147.24
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]         147,520
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
           Conv2d-27             [-1, 64, 6, 6]          36,928
      BatchNorm2d-28             [-1, 64, 6, 6]             128
             ReLU-29             [-1, 64, 6, 6]               0
      SkipConnect-30             [-1, 64, 6, 6]               0
           Conv2d-31            [-1, 128, 8, 8]          73,856
      BatchNorm2d-32            [-1, 128, 8, 8]             256
             ReLU-33            [-1, 128, 8, 8]               0
      SkipConnect-34            [-1, 128, 8, 8]               0
        AvgPool2d-35            [-1, 128, 5, 5]               0
        AvgPool2d-36            [-1, 128, 3, 3]               0
================================================================
Total params: 1,478,112
Trainable params: 1,478,112
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.59
Params size (MB): 5.64
Estimated Total Size (MB): 9.24
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 34.375	Loss: 147.33
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.32
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.27
Epoch:  4
Epoch: 4 of 10	Acc: 20.3125	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 28.125	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.22
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-0.5-0.4-512-128-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.3-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64-512-128-128': 50.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.4-512-128-64-128-64-512-128-128': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-1.0-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-512-128-0.1-0.6-512-512-64-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 37.5,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64-128-128': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-0.6-512-512-128-64': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 24
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9           [-1, 64, 38, 38]          36,928
      BatchNorm2d-10           [-1, 64, 38, 38]             128
             ReLU-11           [-1, 64, 38, 38]               0
      SkipConnect-12           [-1, 64, 38, 38]               0
        AvgPool2d-13           [-1, 64, 20, 20]               0
           Conv2d-14           [-1, 64, 22, 22]          36,928
      BatchNorm2d-15           [-1, 64, 22, 22]             128
             ReLU-16           [-1, 64, 22, 22]               0
      SkipConnect-17           [-1, 64, 22, 22]               0
           Conv2d-18          [-1, 512, 24, 24]         295,424
      BatchNorm2d-19          [-1, 512, 24, 24]           1,024
             ReLU-20          [-1, 512, 24, 24]               0
      SkipConnect-21          [-1, 512, 24, 24]               0
           Conv2d-22          [-1, 256, 26, 26]       1,179,904
      BatchNorm2d-23          [-1, 256, 26, 26]             512
             ReLU-24          [-1, 256, 26, 26]               0
      SkipConnect-25          [-1, 256, 26, 26]               0
           Conv2d-26          [-1, 256, 28, 28]         590,080
      BatchNorm2d-27          [-1, 256, 28, 28]             512
             ReLU-28          [-1, 256, 28, 28]               0
      SkipConnect-29          [-1, 256, 28, 28]               0
        MaxPool2d-30          [-1, 256, 15, 15]               0
        AvgPool2d-31            [-1, 256, 8, 8]               0
           Conv2d-32           [-1, 64, 10, 10]         147,520
      BatchNorm2d-33           [-1, 64, 10, 10]             128
             ReLU-34           [-1, 64, 10, 10]               0
      SkipConnect-35           [-1, 64, 10, 10]               0
           Conv2d-36          [-1, 512, 12, 12]         295,424
      BatchNorm2d-37          [-1, 512, 12, 12]           1,024
             ReLU-38          [-1, 512, 12, 12]               0
      SkipConnect-39          [-1, 512, 12, 12]               0
           Conv2d-40          [-1, 128, 14, 14]         589,952
      BatchNorm2d-41          [-1, 128, 14, 14]             256
             ReLU-42          [-1, 128, 14, 14]               0
      SkipConnect-43          [-1, 128, 14, 14]               0
           Conv2d-44           [-1, 64, 16, 16]          73,792
      BatchNorm2d-45           [-1, 64, 16, 16]             128
             ReLU-46           [-1, 64, 16, 16]               0
      SkipConnect-47           [-1, 64, 16, 16]               0
           Conv2d-48           [-1, 64, 18, 18]          36,928
      BatchNorm2d-49           [-1, 64, 18, 18]             128
             ReLU-50           [-1, 64, 18, 18]               0
      SkipConnect-51           [-1, 64, 18, 18]               0
           Conv2d-52           [-1, 64, 20, 20]          36,928
      BatchNorm2d-53           [-1, 64, 20, 20]             128
             ReLU-54           [-1, 64, 20, 20]               0
      SkipConnect-55           [-1, 64, 20, 20]               0
           Conv2d-56          [-1, 512, 22, 22]         295,424
      BatchNorm2d-57          [-1, 512, 22, 22]           1,024
             ReLU-58          [-1, 512, 22, 22]               0
      SkipConnect-59          [-1, 512, 22, 22]               0
           Conv2d-60          [-1, 128, 24, 24]         589,952
      BatchNorm2d-61          [-1, 128, 24, 24]             256
             ReLU-62          [-1, 128, 24, 24]               0
      SkipConnect-63          [-1, 128, 24, 24]               0
           Conv2d-64          [-1, 128, 26, 26]         147,584
      BatchNorm2d-65          [-1, 128, 26, 26]             256
             ReLU-66          [-1, 128, 26, 26]               0
      SkipConnect-67          [-1, 128, 26, 26]               0
================================================================
Total params: 4,368,288
Trainable params: 4,368,288
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 45.61
Params size (MB): 16.66
Estimated Total Size (MB): 62.28
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 148.08
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.8
Epoch:  3
Epoch: 3 of 10	Acc: 29.6875	Loss: 147.55
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.36
Epoch:  5
Epoch: 5 of 10	Acc: 29.6875	Loss: 147.29
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.3
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.3
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.25
Epoch:  10
Epoch: 10 of 10	Acc: 28.125	Loss: 147.23
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 128, 12, 12]         147,584
      BatchNorm2d-17          [-1, 128, 12, 12]             256
             ReLU-18          [-1, 128, 12, 12]               0
      SkipConnect-19          [-1, 128, 12, 12]               0
           Conv2d-20          [-1, 512, 14, 14]         590,336
      BatchNorm2d-21          [-1, 512, 14, 14]           1,024
             ReLU-22          [-1, 512, 14, 14]               0
      SkipConnect-23          [-1, 512, 14, 14]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
        MaxPool2d-25            [-1, 512, 5, 5]               0
        AvgPool2d-26            [-1, 512, 3, 3]               0
        MaxPool2d-27            [-1, 512, 2, 2]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
      SkipConnect-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-33            [-1, 512, 6, 6]           1,024
             ReLU-34            [-1, 512, 6, 6]               0
      SkipConnect-35            [-1, 512, 6, 6]               0
           Conv2d-36            [-1, 128, 8, 8]         589,952
      BatchNorm2d-37            [-1, 128, 8, 8]             256
             ReLU-38            [-1, 128, 8, 8]               0
      SkipConnect-39            [-1, 128, 8, 8]               0
           Conv2d-40           [-1, 64, 10, 10]          73,792
      BatchNorm2d-41           [-1, 64, 10, 10]             128
             ReLU-42           [-1, 64, 10, 10]               0
      SkipConnect-43           [-1, 64, 10, 10]               0
================================================================
Total params: 6,458,400
Trainable params: 6,458,400
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.79
Params size (MB): 24.64
Estimated Total Size (MB): 31.44
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 147.87
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.31
Epoch:  3
Epoch: 3 of 10	Acc: 29.6875	Loss: 147.32
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.25
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.31
Epoch:  6
Epoch: 6 of 10	Acc: 37.5	Loss: 147.24
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 20.3125	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 512, 8, 8]       1,180,160
      BatchNorm2d-18            [-1, 512, 8, 8]           1,024
             ReLU-19            [-1, 512, 8, 8]               0
      SkipConnect-20            [-1, 512, 8, 8]               0
        MaxPool2d-21            [-1, 512, 5, 5]               0
        MaxPool2d-22            [-1, 512, 3, 3]               0
        AvgPool2d-23            [-1, 512, 2, 2]               0
        MaxPool2d-24            [-1, 512, 2, 2]               0
           Conv2d-25            [-1, 512, 4, 4]       2,359,808
      BatchNorm2d-26            [-1, 512, 4, 4]           1,024
             ReLU-27            [-1, 512, 4, 4]               0
      SkipConnect-28            [-1, 512, 4, 4]               0
           Conv2d-29            [-1, 512, 6, 6]       2,359,808
      BatchNorm2d-30            [-1, 512, 6, 6]           1,024
             ReLU-31            [-1, 512, 6, 6]               0
      SkipConnect-32            [-1, 512, 6, 6]               0
           Conv2d-33             [-1, 64, 8, 8]         294,976
      BatchNorm2d-34             [-1, 64, 8, 8]             128
             ReLU-35             [-1, 64, 8, 8]               0
      SkipConnect-36             [-1, 64, 8, 8]               0
           Conv2d-37          [-1, 512, 10, 10]         295,424
      BatchNorm2d-38          [-1, 512, 10, 10]           1,024
             ReLU-39          [-1, 512, 10, 10]               0
      SkipConnect-40          [-1, 512, 10, 10]               0
================================================================
Total params: 6,652,512
Trainable params: 6,652,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.87
Params size (MB): 25.38
Estimated Total Size (MB): 30.26
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.71
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 148.18
Epoch:  3
Epoch: 3 of 10	Acc: 28.125	Loss: 147.92
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.63
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.54
Epoch:  6
Epoch: 6 of 10	Acc: 28.125	Loss: 147.59
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.43
Epoch:  8
Epoch: 8 of 10	Acc: 26.5625	Loss: 147.44
Epoch:  9
Epoch: 9 of 10	Acc: 20.3125	Loss: 147.47
Epoch:  10
Epoch: 10 of 10	Acc: 28.125	Loss: 147.34
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35             [-1, 64, 7, 7]         294,976
      BatchNorm2d-36             [-1, 64, 7, 7]             128
             ReLU-37             [-1, 64, 7, 7]               0
      SkipConnect-38             [-1, 64, 7, 7]               0
           Conv2d-39            [-1, 128, 9, 9]          73,856
      BatchNorm2d-40            [-1, 128, 9, 9]             256
             ReLU-41            [-1, 128, 9, 9]               0
      SkipConnect-42            [-1, 128, 9, 9]               0
        MaxPool2d-43            [-1, 128, 5, 5]               0
================================================================
Total params: 2,263,200
Trainable params: 2,263,200
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.88
Params size (MB): 8.63
Estimated Total Size (MB): 14.53
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 37.5	Loss: 148.78
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.6
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.38
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.32
Epoch:  5
Epoch: 5 of 10	Acc: 21.875	Loss: 147.28
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 21.875	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.25
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.28
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.22
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        MaxPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
        MaxPool2d-24            [-1, 256, 2, 2]               0
           Conv2d-25            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-26            [-1, 512, 4, 4]           1,024
             ReLU-27            [-1, 512, 4, 4]               0
      SkipConnect-28            [-1, 512, 4, 4]               0
           Conv2d-29            [-1, 128, 6, 6]         589,952
      BatchNorm2d-30            [-1, 128, 6, 6]             256
             ReLU-31            [-1, 128, 6, 6]               0
      SkipConnect-32            [-1, 128, 6, 6]               0
================================================================
Total params: 2,520,096
Trainable params: 2,520,096
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.18
Params size (MB): 9.61
Estimated Total Size (MB): 11.81
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.24
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.48
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.32
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.25
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.25
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.3
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.2
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.4
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-0.5-0.4-512-128-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-1.0': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.3-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64-512-128-128': 50.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.4-512-128-64-128-64-512-128-128': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-1.0-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-512-128-0.1-0.6-512-512-64-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-512-0.6-1.0-0.1-0.6-512-512-64-512': 25.0,
 '0.6-0.1-64-0.7-0.4-256-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 37.5,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64-128-128': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-0.6-512-512-128-64': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-128-64-64-64-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
Generation: 25
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
            Conv2d-5           [-1, 64, 36, 36]           9,280
       BatchNorm2d-6           [-1, 64, 36, 36]             128
              ReLU-7           [-1, 64, 36, 36]               0
       SkipConnect-8           [-1, 64, 36, 36]               0
            Conv2d-9          [-1, 512, 38, 38]         295,424
      BatchNorm2d-10          [-1, 512, 38, 38]           1,024
             ReLU-11          [-1, 512, 38, 38]               0
      SkipConnect-12          [-1, 512, 38, 38]               0
           Conv2d-13           [-1, 64, 40, 40]         294,976
      BatchNorm2d-14           [-1, 64, 40, 40]             128
             ReLU-15           [-1, 64, 40, 40]               0
      SkipConnect-16           [-1, 64, 40, 40]               0
           Conv2d-17          [-1, 256, 42, 42]         147,712
      BatchNorm2d-18          [-1, 256, 42, 42]             512
             ReLU-19          [-1, 256, 42, 42]               0
      SkipConnect-20          [-1, 256, 42, 42]               0
        AvgPool2d-21          [-1, 256, 22, 22]               0
           Conv2d-22          [-1, 256, 24, 24]         590,080
      BatchNorm2d-23          [-1, 256, 24, 24]             512
             ReLU-24          [-1, 256, 24, 24]               0
      SkipConnect-25          [-1, 256, 24, 24]               0
        MaxPool2d-26          [-1, 256, 13, 13]               0
           Conv2d-27          [-1, 512, 15, 15]       1,180,160
      BatchNorm2d-28          [-1, 512, 15, 15]           1,024
             ReLU-29          [-1, 512, 15, 15]               0
      SkipConnect-30          [-1, 512, 15, 15]               0
           Conv2d-31          [-1, 128, 17, 17]         589,952
      BatchNorm2d-32          [-1, 128, 17, 17]             256
             ReLU-33          [-1, 128, 17, 17]               0
      SkipConnect-34          [-1, 128, 17, 17]               0
        AvgPool2d-35            [-1, 128, 9, 9]               0
        MaxPool2d-36            [-1, 128, 5, 5]               0
           Conv2d-37            [-1, 512, 7, 7]         590,336
      BatchNorm2d-38            [-1, 512, 7, 7]           1,024
             ReLU-39            [-1, 512, 7, 7]               0
      SkipConnect-40            [-1, 512, 7, 7]               0
           Conv2d-41            [-1, 512, 9, 9]       2,359,808
      BatchNorm2d-42            [-1, 512, 9, 9]           1,024
             ReLU-43            [-1, 512, 9, 9]               0
      SkipConnect-44            [-1, 512, 9, 9]               0
           Conv2d-45           [-1, 64, 11, 11]         294,976
      BatchNorm2d-46           [-1, 64, 11, 11]             128
             ReLU-47           [-1, 64, 11, 11]               0
      SkipConnect-48           [-1, 64, 11, 11]               0
           Conv2d-49          [-1, 512, 13, 13]         295,424
      BatchNorm2d-50          [-1, 512, 13, 13]           1,024
             ReLU-51          [-1, 512, 13, 13]               0
      SkipConnect-52          [-1, 512, 13, 13]               0
================================================================
Total params: 6,655,392
Trainable params: 6,655,392
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 58.00
Params size (MB): 25.39
Estimated Total Size (MB): 83.40
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 26.5625	Loss: 148.55
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 148.1
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.83
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.63
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.49
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.43
Epoch:  7
Epoch: 7 of 10	Acc: 29.6875	Loss: 147.45
Epoch:  8
Epoch: 8 of 10	Acc: 20.3125	Loss: 147.49
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.45
Epoch:  10
Epoch: 10 of 10	Acc: 37.5	Loss: 147.43
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
           Conv2d-20          [-1, 256, 14, 14]         590,080
      BatchNorm2d-21          [-1, 256, 14, 14]             512
             ReLU-22          [-1, 256, 14, 14]               0
      SkipConnect-23          [-1, 256, 14, 14]               0
        MaxPool2d-24            [-1, 256, 8, 8]               0
        AvgPool2d-25            [-1, 256, 5, 5]               0
           Conv2d-26             [-1, 64, 7, 7]         147,520
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
      SkipConnect-29             [-1, 64, 7, 7]               0
           Conv2d-30            [-1, 512, 9, 9]         295,424
      BatchNorm2d-31            [-1, 512, 9, 9]           1,024
             ReLU-32            [-1, 512, 9, 9]               0
      SkipConnect-33            [-1, 512, 9, 9]               0
           Conv2d-34          [-1, 256, 11, 11]       1,179,904
      BatchNorm2d-35          [-1, 256, 11, 11]             512
             ReLU-36          [-1, 256, 11, 11]               0
      SkipConnect-37          [-1, 256, 11, 11]               0
           Conv2d-38          [-1, 256, 13, 13]         590,080
      BatchNorm2d-39          [-1, 256, 13, 13]             512
             ReLU-40          [-1, 256, 13, 13]               0
      SkipConnect-41          [-1, 256, 13, 13]               0
           Conv2d-42          [-1, 128, 15, 15]         295,040
      BatchNorm2d-43          [-1, 128, 15, 15]             256
             ReLU-44          [-1, 128, 15, 15]               0
      SkipConnect-45          [-1, 128, 15, 15]               0
           Conv2d-46           [-1, 64, 17, 17]          73,792
      BatchNorm2d-47           [-1, 64, 17, 17]             128
             ReLU-48           [-1, 64, 17, 17]               0
      SkipConnect-49           [-1, 64, 17, 17]               0
================================================================
Total params: 4,394,208
Trainable params: 4,394,208
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 9.80
Params size (MB): 16.76
Estimated Total Size (MB): 26.58
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 29.6875	Loss: 148.16
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 147.54
Epoch:  3
Epoch: 3 of 10	Acc: 32.8125	Loss: 147.29
Epoch:  4
Epoch: 4 of 10	Acc: 25.0	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  6
Epoch: 6 of 10	Acc: 28.125	Loss: 147.21
Epoch:  7
Epoch: 7 of 10	Acc: 28.125	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 20.3125	Loss: 147.21
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.24
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
            Conv2d-7           [-1, 64, 12, 12]           9,280
       BatchNorm2d-8           [-1, 64, 12, 12]             128
              ReLU-9           [-1, 64, 12, 12]               0
      SkipConnect-10           [-1, 64, 12, 12]               0
        MaxPool2d-11             [-1, 64, 7, 7]               0
        AvgPool2d-12             [-1, 64, 4, 4]               0
           Conv2d-13            [-1, 256, 6, 6]         147,712
      BatchNorm2d-14            [-1, 256, 6, 6]             512
             ReLU-15            [-1, 256, 6, 6]               0
      SkipConnect-16            [-1, 256, 6, 6]               0
           Conv2d-17            [-1, 256, 8, 8]         590,080
      BatchNorm2d-18            [-1, 256, 8, 8]             512
             ReLU-19            [-1, 256, 8, 8]               0
      SkipConnect-20            [-1, 256, 8, 8]               0
           Conv2d-21          [-1, 512, 10, 10]       1,180,160
      BatchNorm2d-22          [-1, 512, 10, 10]           1,024
             ReLU-23          [-1, 512, 10, 10]               0
      SkipConnect-24          [-1, 512, 10, 10]               0
           Conv2d-25          [-1, 128, 12, 12]         589,952
      BatchNorm2d-26          [-1, 128, 12, 12]             256
             ReLU-27          [-1, 128, 12, 12]               0
      SkipConnect-28          [-1, 128, 12, 12]               0
        AvgPool2d-29            [-1, 128, 7, 7]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]         589,952
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 6,136,416
Trainable params: 6,136,416
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.13
Params size (MB): 23.41
Estimated Total Size (MB): 29.55
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 31.25	Loss: 147.99
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.38
Epoch:  3
Epoch: 3 of 10	Acc: 25.0	Loss: 147.25
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.23
Epoch:  5
Epoch: 5 of 10	Acc: 26.5625	Loss: 147.24
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.23
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.23
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 25.0	Loss: 147.22
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.22
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
            Conv2d-6           [-1, 64, 20, 20]           9,280
       BatchNorm2d-7           [-1, 64, 20, 20]             128
              ReLU-8           [-1, 64, 20, 20]               0
       SkipConnect-9           [-1, 64, 20, 20]               0
           Conv2d-10           [-1, 64, 22, 22]          36,928
      BatchNorm2d-11           [-1, 64, 22, 22]             128
             ReLU-12           [-1, 64, 22, 22]               0
      SkipConnect-13           [-1, 64, 22, 22]               0
        MaxPool2d-14           [-1, 64, 12, 12]               0
        AvgPool2d-15             [-1, 64, 7, 7]               0
           Conv2d-16            [-1, 128, 9, 9]          73,856
      BatchNorm2d-17            [-1, 128, 9, 9]             256
             ReLU-18            [-1, 128, 9, 9]               0
      SkipConnect-19            [-1, 128, 9, 9]               0
           Conv2d-20          [-1, 512, 11, 11]         590,336
      BatchNorm2d-21          [-1, 512, 11, 11]           1,024
             ReLU-22          [-1, 512, 11, 11]               0
      SkipConnect-23          [-1, 512, 11, 11]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 128, 8, 8]         589,952
      BatchNorm2d-26            [-1, 128, 8, 8]             256
             ReLU-27            [-1, 128, 8, 8]               0
      SkipConnect-28            [-1, 128, 8, 8]               0
        AvgPool2d-29            [-1, 128, 5, 5]               0
        MaxPool2d-30            [-1, 128, 3, 3]               0
           Conv2d-31            [-1, 512, 5, 5]         590,336
      BatchNorm2d-32            [-1, 512, 5, 5]           1,024
             ReLU-33            [-1, 512, 5, 5]               0
      SkipConnect-34            [-1, 512, 5, 5]               0
           Conv2d-35             [-1, 64, 7, 7]         294,976
      BatchNorm2d-36             [-1, 64, 7, 7]             128
             ReLU-37             [-1, 64, 7, 7]               0
      SkipConnect-38             [-1, 64, 7, 7]               0
           Conv2d-39             [-1, 64, 9, 9]          36,928
      BatchNorm2d-40             [-1, 64, 9, 9]             128
             ReLU-41             [-1, 64, 9, 9]               0
      SkipConnect-42             [-1, 64, 9, 9]               0
           Conv2d-43          [-1, 512, 11, 11]         295,424
      BatchNorm2d-44          [-1, 512, 11, 11]           1,024
             ReLU-45          [-1, 512, 11, 11]               0
      SkipConnect-46          [-1, 512, 11, 11]               0
           Conv2d-47          [-1, 512, 13, 13]       2,359,808
      BatchNorm2d-48          [-1, 512, 13, 13]           1,024
             ReLU-49          [-1, 512, 13, 13]               0
      SkipConnect-50          [-1, 512, 13, 13]               0
           Conv2d-51          [-1, 128, 15, 15]         589,952
      BatchNorm2d-52          [-1, 128, 15, 15]             256
             ReLU-53          [-1, 128, 15, 15]               0
      SkipConnect-54          [-1, 128, 15, 15]               0
           Conv2d-55          [-1, 128, 17, 17]         147,584
      BatchNorm2d-56          [-1, 128, 17, 17]             256
             ReLU-57          [-1, 128, 17, 17]               0
      SkipConnect-58          [-1, 128, 17, 17]               0
================================================================
Total params: 5,621,472
Trainable params: 5,621,472
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 12.24
Params size (MB): 21.44
Estimated Total Size (MB): 33.70
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 25.0	Loss: 148.21
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.62
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.54
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.31
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.3
Epoch:  6
Epoch: 6 of 10	Acc: 25.0	Loss: 147.26
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.22
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 28.125	Loss: 147.27
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
        AvgPool2d-12            [-1, 256, 5, 5]               0
           Conv2d-13            [-1, 256, 7, 7]         590,080
      BatchNorm2d-14            [-1, 256, 7, 7]             512
             ReLU-15            [-1, 256, 7, 7]               0
      SkipConnect-16            [-1, 256, 7, 7]               0
           Conv2d-17            [-1, 256, 9, 9]         590,080
      BatchNorm2d-18            [-1, 256, 9, 9]             512
             ReLU-19            [-1, 256, 9, 9]               0
      SkipConnect-20            [-1, 256, 9, 9]               0
        MaxPool2d-21            [-1, 256, 5, 5]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28             [-1, 64, 6, 6]         294,976
      BatchNorm2d-29             [-1, 64, 6, 6]             128
             ReLU-30             [-1, 64, 6, 6]               0
      SkipConnect-31             [-1, 64, 6, 6]               0
        MaxPool2d-32             [-1, 64, 4, 4]               0
        MaxPool2d-33             [-1, 64, 3, 3]               0
================================================================
Total params: 2,695,584
Trainable params: 2,695,584
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.59
Params size (MB): 10.28
Estimated Total Size (MB): 12.89
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 148.48
Epoch:  2
Epoch: 2 of 10	Acc: 25.0	Loss: 147.75
Epoch:  3
Epoch: 3 of 10	Acc: 26.5625	Loss: 147.49
Epoch:  4
Epoch: 4 of 10	Acc: 50.0	Loss: 147.45
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.38
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.31
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.3
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.29
Epoch:  9
Epoch: 9 of 10	Acc: 37.5	Loss: 147.23
Epoch:  10
Epoch: 10 of 10	Acc: 25.0	Loss: 147.24
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         AvgPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 256, 10, 10]         590,080
      BatchNorm2d-13          [-1, 256, 10, 10]             512
             ReLU-14          [-1, 256, 10, 10]               0
      SkipConnect-15          [-1, 256, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         590,080
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
        AvgPool2d-22            [-1, 256, 3, 3]               0
        AvgPool2d-23            [-1, 256, 2, 2]               0
           Conv2d-24            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
      SkipConnect-27            [-1, 512, 4, 4]               0
           Conv2d-28             [-1, 64, 6, 6]         294,976
      BatchNorm2d-29             [-1, 64, 6, 6]             128
             ReLU-30             [-1, 64, 6, 6]               0
      SkipConnect-31             [-1, 64, 6, 6]               0
        MaxPool2d-32             [-1, 64, 4, 4]               0
        MaxPool2d-33             [-1, 64, 3, 3]               0
================================================================
Total params: 2,695,584
Trainable params: 2,695,584
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.51
Params size (MB): 10.28
Estimated Total Size (MB): 13.81
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 29.6875	Loss: 148.63
Epoch:  2
Epoch: 2 of 10	Acc: 21.875	Loss: 147.8
Epoch:  3
Epoch: 3 of 10	Acc: 29.6875	Loss: 147.62
Epoch:  4
Epoch: 4 of 10	Acc: 26.5625	Loss: 147.46
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.47
Epoch:  6
Epoch: 6 of 10	Acc: 26.5625	Loss: 147.36
Epoch:  7
Epoch: 7 of 10	Acc: 25.0	Loss: 147.35
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.27
Epoch:  9
Epoch: 9 of 10	Acc: 26.5625	Loss: 147.26
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.22
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         AvgPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8             [-1, 64, 8, 8]           9,280
       BatchNorm2d-9             [-1, 64, 8, 8]             128
             ReLU-10             [-1, 64, 8, 8]               0
      SkipConnect-11             [-1, 64, 8, 8]               0
           Conv2d-12          [-1, 512, 10, 10]         295,424
      BatchNorm2d-13          [-1, 512, 10, 10]           1,024
             ReLU-14          [-1, 512, 10, 10]               0
      SkipConnect-15          [-1, 512, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]       1,179,904
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
           Conv2d-21            [-1, 512, 9, 9]       1,180,160
      BatchNorm2d-22            [-1, 512, 9, 9]           1,024
             ReLU-23            [-1, 512, 9, 9]               0
      SkipConnect-24            [-1, 512, 9, 9]               0
           Conv2d-25          [-1, 128, 11, 11]         589,952
      BatchNorm2d-26          [-1, 128, 11, 11]             256
             ReLU-27          [-1, 128, 11, 11]               0
      SkipConnect-28          [-1, 128, 11, 11]               0
        AvgPool2d-29            [-1, 128, 6, 6]               0
        MaxPool2d-30            [-1, 128, 4, 4]               0
           Conv2d-31            [-1, 512, 6, 6]         590,336
      BatchNorm2d-32            [-1, 512, 6, 6]           1,024
             ReLU-33            [-1, 512, 6, 6]               0
      SkipConnect-34            [-1, 512, 6, 6]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
      SkipConnect-38            [-1, 512, 8, 8]               0
           Conv2d-39          [-1, 128, 10, 10]         589,952
      BatchNorm2d-40          [-1, 128, 10, 10]             256
             ReLU-41          [-1, 128, 10, 10]               0
      SkipConnect-42          [-1, 128, 10, 10]               0
           Conv2d-43           [-1, 64, 12, 12]          73,792
      BatchNorm2d-44           [-1, 64, 12, 12]             128
             ReLU-45           [-1, 64, 12, 12]               0
      SkipConnect-46           [-1, 64, 12, 12]               0
================================================================
Total params: 6,874,464
Trainable params: 6,874,464
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.55
Params size (MB): 26.22
Estimated Total Size (MB): 33.79
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 28.125	Loss: 147.93
Epoch:  2
Epoch: 2 of 10	Acc: 26.5625	Loss: 147.37
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 147.28
Epoch:  4
Epoch: 4 of 10	Acc: 23.4375	Loss: 147.24
Epoch:  5
Epoch: 5 of 10	Acc: 25.0	Loss: 147.21
Epoch:  6
Epoch: 6 of 10	Acc: 23.4375	Loss: 147.2
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  8
Epoch: 8 of 10	Acc: 23.4375	Loss: 147.21
Epoch:  9
Epoch: 9 of 10	Acc: 23.4375	Loss: 147.26
Epoch:  10
Epoch: 10 of 10	Acc: 23.4375	Loss: 147.25
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 34, 34]             448
       BatchNorm2d-2           [-1, 16, 34, 34]              32
              ReLU-3           [-1, 16, 34, 34]               0
       SkipConnect-4           [-1, 16, 34, 34]               0
         MaxPool2d-5           [-1, 16, 18, 18]               0
         AvgPool2d-6           [-1, 16, 10, 10]               0
         MaxPool2d-7             [-1, 16, 6, 6]               0
            Conv2d-8            [-1, 256, 8, 8]          37,120
       BatchNorm2d-9            [-1, 256, 8, 8]             512
             ReLU-10            [-1, 256, 8, 8]               0
      SkipConnect-11            [-1, 256, 8, 8]               0
           Conv2d-12          [-1, 128, 10, 10]         295,040
      BatchNorm2d-13          [-1, 128, 10, 10]             256
             ReLU-14          [-1, 128, 10, 10]               0
      SkipConnect-15          [-1, 128, 10, 10]               0
           Conv2d-16          [-1, 256, 12, 12]         295,168
      BatchNorm2d-17          [-1, 256, 12, 12]             512
             ReLU-18          [-1, 256, 12, 12]               0
      SkipConnect-19          [-1, 256, 12, 12]               0
        MaxPool2d-20            [-1, 256, 7, 7]               0
        MaxPool2d-21            [-1, 256, 4, 4]               0
           Conv2d-22             [-1, 64, 6, 6]         147,520
      BatchNorm2d-23             [-1, 64, 6, 6]             128
             ReLU-24             [-1, 64, 6, 6]               0
      SkipConnect-25             [-1, 64, 6, 6]               0
        AvgPool2d-26             [-1, 64, 4, 4]               0
        MaxPool2d-27             [-1, 64, 3, 3]               0
           Conv2d-28            [-1, 512, 5, 5]         295,424
      BatchNorm2d-29            [-1, 512, 5, 5]           1,024
             ReLU-30            [-1, 512, 5, 5]               0
      SkipConnect-31            [-1, 512, 5, 5]               0
        MaxPool2d-32            [-1, 512, 3, 3]               0
        MaxPool2d-33            [-1, 512, 2, 2]               0
================================================================
Total params: 1,073,184
Trainable params: 1,073,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 3.29
Params size (MB): 4.09
Estimated Total Size (MB): 7.39
----------------------------------------------------------------
Epoch:  1
Epoch: 1 of 10	Acc: 23.4375	Loss: 151.34
Epoch:  2
Epoch: 2 of 10	Acc: 23.4375	Loss: 148.66
Epoch:  3
Epoch: 3 of 10	Acc: 23.4375	Loss: 148.01
Epoch:  4
Epoch: 4 of 10	Acc: 21.875	Loss: 147.91
Epoch:  5
Epoch: 5 of 10	Acc: 23.4375	Loss: 147.81
Epoch:  6
Epoch: 6 of 10	Acc: 21.875	Loss: 147.61
Epoch:  7
Epoch: 7 of 10	Acc: 23.4375	Loss: 147.49
Epoch:  8
Epoch: 8 of 10	Acc: 25.0	Loss: 147.47
Epoch:  9
Epoch: 9 of 10	Acc: 21.875	Loss: 147.48
Epoch:  10
Epoch: 10 of 10	Acc: 21.875	Loss: 147.39
Current Fitness:
{'0.3-0.5-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-0.1-0.6-512-512-128-64': 12.5,
 '0.3-0.5-256-512-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.4-0.1-0.8-256-256-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-0.5-0.4-512-128-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 50.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-1.0': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-128-64': 37.5,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-128-512-0.6-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-0.6-512-512-128-64': 12.5,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.4-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-0.6-512-512-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-256': 12.5,
 '0.4-64-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '0.6-0.1-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 50.0,
 '0.6-0.1-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-512-128-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-0.2-1.0': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.3-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-128-64-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-1.0-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-512-64-512': 37.5,
 '0.6-0.1-0.8-256-128-128-512-0.6-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.1-0.6-512-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-0.7-64-0.3-64-128-0.2-0.3': 37.5,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 37.5,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-0.8-256-128-256-256-0.7-0.5-0.4-512-128-64-128-64-512-128-128': 50.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64': 62.5,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-512-128-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-0.7-64-0.3-0.6-512-64-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-512-64-64': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-0.6-512-64-64-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.1-512-64-0.9-1.0-64-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.4-512-128-64-128-64-512-128-128': 37.5,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-0.8-256-256-256-0.6-512-128-128-64-128-0.2-0.3': 12.5,
 '0.6-0.1-0.8-256-256-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '0.6-0.1-256-512-128-128-0.8-0.7-64-128-64-512-512-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-1.0-0.9-256-128-64-128-64': 12.5,
 '0.6-0.1-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.6-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-0.2-0.3-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-0.8-0.7-64-0.3-64-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.6-1.0-0.1-0.6-512-512-128-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.1-0.6-512-64-128-64': 50.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512': 62.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-512-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-64-64-512-128-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-1.0-0.3-0.6-512-128': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-0.1-0.6-512-512-64-512-512-128-128': 37.5,
 '0.6-0.1-64-0.7-0.4-256-256-0.7-64-128-64-128-0.2-0.3': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-512-128-0.1-0.6-512-512-128-64': 25.0,
 '0.6-0.1-64-0.7-0.4-256-256-512-128-0.1-0.6-512-512-64-64': 37.5,
 '0.6-0.1-64-0.7-0.4-256-512-0.6-1.0-0.1-0.6-512-512-64-512': 25.0,
 '0.6-0.1-64-0.7-0.4-256-512-0.6-1.0-0.9-256-64-0.9-1.0-64': 37.5,
 '0.6-0.1-64-0.7-128-128-512-0.6-1.0-0.3-0.6-512-128': 37.5,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64': 25.0,
 '0.6-0.1-64-256-256-256-0.6-512-128-0.1-0.6-512-64-128-64-128-128': 25.0,
 '0.6-0.5-256-512-128-128-512-0.6-1.0-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.6-64-64-0.7-0.4-128-512-0.6-128-0.1-0.6-512-64-64-512-512-128-128': 25.0,
 '0.8-0.6-128-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 25.0,
 '0.8-0.6-128-256-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.1-256-128-64-128-64': 37.5,
 '0.8-0.6-128-256-256-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 12.5,
 '0.8-0.6-128-256-256-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-512-0.2-0.7-0.4-256-256-0.7-0.5-0.4-512-64-0.9-1.0': 37.5,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-128-64-128-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64': 25.0,
 '64-512-0.2-64-512-256-256-0.7-0.5-0.4-512-64-0.9-1.0-64-512-128-128': 25.0,
 '64-512-0.8-256-128-128-0.8-0.7-64-128-64-128-0.2-0.3-64-256': 12.5,
 '64-512-0.8-256-128-128-512-0.6-1.0-0.3-0.6-512-128': 12.5,
 '64-512-64-0.7-0.4-256-256-0.7-0.5-0.4-512-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-1.0-0.9-256-128-64-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-512-128-64': 12.5,
 '64-512-64-256-0.1-128-512-512-64-0.9-256-128-64-64-512-512-128-128': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-128-64': 12.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.1-0.6-512-512-64-512': 37.5,
 '64-512-64-256-0.1-256-0.6-512-128-0.9-256-128-64-64-512-512-128-128': 25.0,
 '64-64-0.2-64-128-128-0.8-0.7-64-128-64-128-0.2-0.3': 12.5,
 '64-64-0.2-64-512-256-0.6-512-128-0.1-0.6-512-512-64-512-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-0.6-512-512-128-64': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-128-64-64-64-512-128-128': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.2-1.0': 12.5,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-0.3': 25.0,
 '64-64-0.2-64-512-256-256-0.6-0.5-64-512-256-256-128-64': 25.0,
 '64-64-64-0.7-0.4-256-0.8-0.7-64-128-64-128-0.2-0.3': 12.5}
